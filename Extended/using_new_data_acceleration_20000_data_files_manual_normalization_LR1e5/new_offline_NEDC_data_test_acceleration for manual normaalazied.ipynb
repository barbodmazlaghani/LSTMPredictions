{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0o0gASdzJv3",
        "outputId": "d6213272-13e2-4620-f3c9-944cf7f35fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
            "Plot saved as: /content/NEDC_1000_slope_added_predicted_vs_real.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "\n",
        "# Load scalers\n",
        "scaler_X = joblib.load('scaler_X.pkl')\n",
        "scaler_y = joblib.load('scaler_y.pkl')\n",
        "\n",
        "SEQUENCE_LENGTH = 600\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path):\n",
        "    return load_model(model_path)\n",
        "\n",
        "# Process the file and prepare segments\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['Time'] = df['Time'] - df['Time'].iloc[0]\n",
        "    df['Trip fuel consumption'] = df['Trip fuel consumption'] - df['Trip fuel consumption'].iloc[0]\n",
        "    df['Acceleration'] = df['Speed'].diff().fillna(0)\n",
        "    features = df[['Engine speed', 'Speed', 'slope', 'Acceleration']]\n",
        "    df['Momentary fuel consumption'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "    target = df['Momentary fuel consumption']\n",
        "    return features, target\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, scaler, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = pad_sequences(data, maxlen=sequence_length, dtype='float32', padding='post', truncating='post')\n",
        "    # print(padded_data)\n",
        "    min_val_x = [0,0,-10,-150]\n",
        "    max_val_x = [8000,150,10,150]\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "      padded_data[:,:,i] = (padded_data[:,:,i] - min_val_x[i])/(max_val_x[i]-min_val_x[i])\n",
        "    # normalized_data = scaler.transform(padded_data.reshape(-1, padded_data.shape[-1])).reshape(padded_data.shape)\n",
        "    # print('\\n\\n\\n',padded_data)\n",
        "    normalized_data = padded_data\n",
        "    return normalized_data\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, scaler_X, scaler_y):\n",
        "    features, actual_values = process_file(input_file)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values], scaler_X)\n",
        "        segment_predictions = model.predict(segment_normalized)\n",
        "        # predictions.extend(scaler_y.inverse_transform(segment_predictions.reshape(-1, 1)))\n",
        "        predictions.extend((segment_predictions*22000 - 2000).reshape(-1, 1))\n",
        "        # print(predictions)\n",
        "\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], scaler_X)\n",
        "        last_segment_predictions = model.predict(last_segment_normalized)\n",
        "        # predictions.extend(scaler_y.inverse_transform(last_segment_predictions.reshape(-1, 1)))\n",
        "        predictions.extend((segment_predictions*22000 - 2000).reshape(-1, 1))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values.values, axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions[:len(actual_values)], axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title('Predicted vs Real Fuel Consumption')\n",
        "    plt.legend()\n",
        "\n",
        "    directory, filename = os.path.split(input_file)\n",
        "    plot_filename = os.path.join(directory, f'{os.path.splitext(filename)[0]}_predicted_vs_real.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Plot saved as: {plot_filename}\")\n",
        "    predictions = predictions[:len(actual_values)]\n",
        "\n",
        "    # Save predictions and actual values to CSV\n",
        "    results_df = pd.DataFrame({\n",
        "        'Speed': features[\"Speed\"],\n",
        "        'Actual': np.cumsum(actual_values.values, axis=0),\n",
        "        'Predicted': np.cumsum(predictions[:len(actual_values)], axis=0).flatten()  # flatten the cumulative predictions\n",
        "    })\n",
        "\n",
        "    directory, filename = os.path.split(input_file)\n",
        "    csv_filename = os.path.join(directory, f'{os.path.splitext(filename)[0]}_predicted_vs_real.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "\n",
        "# Paths to model and input file\n",
        "model_path = '/content/modelBLSTM_new_majid_added.h5'\n",
        "input_file_path = '/content/NEDC_1000_slope_added.csv'\n",
        "\n",
        "# Load model and predict\n",
        "model = load_trained_model(model_path)\n",
        "plot_predicted_vs_real(input_file_path, model, scaler_X, scaler_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_IkEECTJaT3E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}