{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_RQgrvEbkfv",
        "outputId": "6f68760b-d0ce-404b-eca9-4788aad33ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3PDshfYSS1BB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from multiprocessing import Pool\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import joblib\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from multiprocessing import Pool\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import joblib\n",
        "\n",
        "SEQUENCE_LENGTH = 600\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 250\n",
        "LEARNING_RATE = 1e-5\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGAb_Ct9Wx-L"
      },
      "outputs": [],
      "source": [
        "!unzip -qq '/content/gdrive/MyDrive/data_aug_new.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2VsgPt5JVSs"
      },
      "source": [
        "#Load file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/file/d/1-NY6mzsvECLS0hdl21HhtS2io17AIlrf/view?usp=drive_link"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkj4Nq_tqEXN",
        "outputId": "d6352020-d206-48be-9032-2cf603450467"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/parse_url.py:48: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=1-NY6mzsvECLS0hdl21HhtS2io17AIlrf\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/file/d/1-NY6mzsvECLS0hdl21HhtS2io17AIlrf/view?usp=drive_link\n",
            "To: /content/view?usp=drive_link\n",
            "91.7kB [00:00, 11.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#collapse-output\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/file/d/1-NY6mzsvECLS0hdl21HhtS2io17AIlrf/view?usp=drive_link'\n",
        "output_path = '513_600_2slices_shift.npz'\n",
        "gdown.download(url, output_path, quiet=False,fuzzy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "pk64Nr3Uqr3e",
        "outputId": "b9400ec2-aef9-4860-f3a0-4265727a83ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-NY6mzsvECLS0hdl21HhtS2io17AIlrf\n",
            "From (redirected): https://drive.google.com/uc?id=1-NY6mzsvECLS0hdl21HhtS2io17AIlrf&confirm=t&uuid=ea043d44-7567-4e87-ab7f-4be5373b03df\n",
            "To: /content/513_600_2slices_shift.npz\n",
            "100%|██████████| 1.23G/1.23G [00:09<00:00, 135MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'513_600_2slices_shift.npz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('513_600_2slices_shift.npz')\n"
      ],
      "metadata": {
        "id": "iv7DTePGq52-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrcojkYyE8mT"
      },
      "outputs": [],
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_600_2slices_shift.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80JpuFUAQrEW"
      },
      "outputs": [],
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_600_3slices_shift.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KqRZA4CfrT-"
      },
      "outputs": [],
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_600_2slices_shift_rate.npz')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__1KRiMDGL8B"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU0xH4605meq"
      },
      "outputs": [],
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_600_3slices_shift_rate.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_600_3slices_shift_rate.npz')\n"
      ],
      "metadata": {
        "id": "8McR-xKQI0go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_600_3slices_rate_farda.npz')\n"
      ],
      "metadata": {
        "id": "RP1TAG-uJAST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_600_3slices_cons_shift_farda.npz')\n"
      ],
      "metadata": {
        "id": "OD6jYBXQLNrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_600_3slices_rate_farda+trip115.npz')\n"
      ],
      "metadata": {
        "id": "ERBQiYfQSRME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_200_3slices_rate_farda+trip115.npz')\n"
      ],
      "metadata": {
        "id": "2f8rat2iVcvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_200_3slices_rate_farda.npz')\n"
      ],
      "metadata": {
        "id": "-i4drjH3uswD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/gdrive/MyDrive/513_200_3slices_rate_farda_newacc.npz')\n"
      ],
      "metadata": {
        "id": "MtgZtOcYzLid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MCYDVO9rdUBw"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "X_original = data['X_original']\n",
        "y_original = data['y_original']\n",
        "X_augmented = data['X_augmented']\n",
        "y_augmented = data['y_augmented']\n",
        "\n",
        "\n",
        "# X_original1 = data1['X_original']\n",
        "# y_original1 = data1['y_original']\n",
        "# X_augmented1 = data1['X_augmented']\n",
        "# y_augmented1 = data1['y_augmented']\n",
        "\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "try:\n",
        "    X_original = torch.tensor(np.array(X_original), dtype=torch.float32).to(DEVICE)\n",
        "    y_original = torch.tensor(np.array(y_original), dtype=torch.float32).to(DEVICE)\n",
        "    X_augmented = torch.tensor(np.array(X_augmented), dtype=torch.float32).to(DEVICE)\n",
        "    y_augmented = torch.tensor(np.array(y_augmented), dtype=torch.float32).to(DEVICE)\n",
        "except Exception as e:\n",
        "    print(f\"Error during tensor conversion: {e}\")\n",
        "    print(f\"Shapes: X_original - {np.array(X_original).shape}, y_original - {np.array(y_original).shape}\")\n",
        "    print(f\"Shapes: X_augmented - {np.array(X_augmented).shape}, y_augmented - {np.array(y_augmented).shape}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# # Convert data to PyTorch tensors\n",
        "# try:\n",
        "#     X_original1 = torch.tensor(np.array(X_original1), dtype=torch.float32).to(DEVICE)\n",
        "#     y_original1 = torch.tensor(np.array(y_original1), dtype=torch.float32).to(DEVICE)\n",
        "#     X_augmented1 = torch.tensor(np.array(X_augmented1), dtype=torch.float32).to(DEVICE)\n",
        "#     y_augmented1 = torch.tensor(np.array(y_augmented1), dtype=torch.float32).to(DEVICE)\n",
        "# except Exception as e:\n",
        "#     print(f\"Error during tensor conversion: {e}\")\n",
        "#     print(f\"Shapes: X_original1 - {np.array(X_original1).shape}, y_original1 - {np.array(y_original1).shape}\")\n",
        "#     print(f\"Shapes: X_augmented1 - {np.array(X_augmented1).shape}, y_augmented1 - {np.array(y_augmented1).shape}\")\n",
        "#     raise\n",
        "\n",
        "\n",
        "X_train = torch.cat([X_original, X_augmented])\n",
        "y_train = torch.cat([y_original, y_augmented])\n",
        "\n",
        "\n",
        "# X_train1 = torch.cat([X_original1, X_augmented1])\n",
        "# y_train1 = torch.cat([y_original1, y_augmented1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-DJcR1fPDJz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97abfcb2-59ae-4d91-c06f-a1577f2984ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [-1.0000,  2.0000,  4.0000,  1.0000,  3.3704],\n",
            "        [ 2.0000,  6.0000,  6.0000,  1.0000,  3.3704],\n",
            "        [ 6.0000,  0.0000, 12.0000,  1.0000,  3.3704]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "selected_columns = X_train[:,:, [0, 1, 5, 7, 9]]\n",
        "X_train = X_train[:,:, [0, 1, 5, 7, 9]]\n",
        "\n",
        "\n",
        "print(selected_columns[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[:,:, [0, 1,5, 9, 10,11]]\n"
      ],
      "metadata": {
        "id": "TEZAWe1DE0Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7M2r7PuQASF"
      },
      "source": [
        "# **without two acc**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE7Na8plQB_b",
        "outputId": "cbabccae-f9c8-400a-919b-f5e60a6c3c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000, -1.0000, 37.0000,  2.0000, -1.2100],\n",
            "        [-1.0000,  0.0000, 36.0000,  2.0000, -1.2100],\n",
            "        [ 0.0000,  0.0000, 36.0000,  2.0000, -1.2100],\n",
            "        ...,\n",
            "        [-1.0000, -1.0000, 27.0000,  2.0000, -0.1749],\n",
            "        [-1.0000, -2.0000, 26.0000,  2.0000, -0.1749],\n",
            "        [-2.0000, -1.0000, 24.0000,  2.0000, -0.1749]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "selected_columns = X_train[:,:, [0, 1, 5, 7, 9]]\n",
        "X_train = X_train[:,:, [0, 5, 7, 9]]\n",
        "\n",
        "print(selected_columns[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pADzYzqQCz7"
      },
      "source": [
        "# **a**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrf-xPp4Dl2m",
        "outputId": "35d87ea7-a079-4462-8828-e854ec854034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min values: tensor([-121.0000, -121.0000,    0.0000,    0.0000, -224.3478],\n",
            "       device='cuda:0')\n",
            "Max values: tensor([120., 120., 184.,   5., 240.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Compute the minimum and maximum across dimensions (0, 1)\n",
        "min_x = torch.min(X_train, dim=0)[0]  # Min across the first dimension\n",
        "min_x = torch.min(min_x, dim=0)[0].to(DEVICE)  # Min across the second dimension\n",
        "\n",
        "max_x = torch.max(X_train, dim=0)[0]  # Max across the first dimension\n",
        "max_x = torch.max(max_x, dim=0)[0].to(DEVICE)  # Max across the second dimension\n",
        "\n",
        "print(\"Min values:\", min_x)\n",
        "print(\"Max values:\", max_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwIv-XB9QehO",
        "outputId": "8b0ce3db-813b-4bac-b556-f808fe62cf8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min values: tensor([-10653140.])\n",
            "Max values: tensor([29378.])\n"
          ]
        }
      ],
      "source": [
        "# Compute the minimum and maximum across dimensions (0, 1)\n",
        "min_x = torch.min(y_train, dim=0)[0]  # Min across the first dimension\n",
        "min_x = torch.min(min_x, dim=0)[0].to(DEVICE)  # Min across the second dimension\n",
        "\n",
        "max_x = torch.max(y_train, dim=0)[0]  # Max across the first dimension\n",
        "max_x = torch.max(max_x, dim=0)[0].to(DEVICE)  # Max across the second dimension\n",
        "\n",
        "print(\"Min values:\", min_x)\n",
        "print(\"Max values:\", max_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DzowlYwSQyT",
        "outputId": "81a97478-fd1b-449f-fbf1-7d6f97f42f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([23274, 600, 5])\n"
          ]
        }
      ],
      "source": [
        "print(\"Original shape:\", X_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfOZi2agRSnD",
        "outputId": "b0af9223-9948-4940-8c20-095f607223ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original x shape: torch.Size([23254, 600, 5])\n",
            "Original y shape: torch.Size([23254, 600, 1])\n"
          ]
        }
      ],
      "source": [
        "# Create a mask for rows in y where all values are >= 0\n",
        "mask = (y_train >= 0).all(dim=(1, 2))  # True for sequences with no negative values in y\n",
        "\n",
        "# Apply the mask to x\n",
        "X_train = X_train[mask]\n",
        "y_train = y_train[mask]  # Optionally filter y as well for consistency\n",
        "\n",
        "print(\"Original x shape:\", X_train.shape)\n",
        "# print(\"Filtered x shape:\", x_train_filtered.shape)\n",
        "print(\"Original y shape:\", y_train.shape)\n",
        "# print(\"Filtered y shape:\", y_train_filtered.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "66smKKDQRCa1",
        "outputId": "16936120-32bb-4e87-8697-6f3489a63c39"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-05ba561ac489>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Plot violin plot for the column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create a new figure for each plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviolinplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Violin Plot for Column {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mviolinplot\u001b[0;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, inner, split, width, dodge, gap, linewidth, linecolor, cut, gridsize, bw_method, bw_adjust, density_norm, common_norm, hue_norm, formatter, log_scale, native_scale, legend, scale, scale_hue, bw, inner_kws, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1723\u001b[0m ):\n\u001b[1;32m   1724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m     p = _CategoricalPlotter(\n\u001b[0m\u001b[1;32m   1726\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m         \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[0m\n\u001b[1;32m     65\u001b[0m     ):\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# This method takes care of some bookkeeping that is necessary because the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# information for numeric axes would be information about log scales.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_ordered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# alt., used DefaultDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# TODO Lots of tests assume that these are called to initialize the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_base.py\u001b[0m in \u001b[0;36massign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"wide\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_variables_wideform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;31m# When dealing with long-form input, use the newer PlotData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_base.py\u001b[0m in \u001b[0;36m_assign_variables_wideform\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         flat = not any(\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_base.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         flat = not any(\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Save processed data for later use\n",
        "for i in range(y_train.shape[2]):  # Iterate over columns (third dimension)\n",
        "    col_data = y_train[:, :, i].flatten().cpu().numpy()  # Flatten, move to CPU, convert to numpy\n",
        "    np.save(f\"column_{i}.npy\", col_data)  # Save each column to a .npy file\n",
        "\n",
        "# Create separate plots for each column\n",
        "for i in range(y_train.shape[2]):\n",
        "    # Load column data\n",
        "    col_data = np.load(f\"column_{i}.npy\")\n",
        "\n",
        "    # Plot violin plot for the column\n",
        "    plt.figure(figsize=(6, 4))  # Create a new figure for each plot\n",
        "    sns.violinplot(data=col_data)\n",
        "    plt.title(f\"Violin Plot for Column {i}\")\n",
        "    plt.xlabel(f\"Column {i}\")\n",
        "    plt.ylabel(\"Values\")\n",
        "\n",
        "    # Save or show the plot\n",
        "    plt.savefig(f\"violin_plot_column_{i}.png\")  # Save plot to file\n",
        "    plt.show()  # Show the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK0RUHw7f_6a",
        "outputId": "2da4f32d-90a1-40b6-9549-1519d6a24917"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1.3182], device='cuda:0'), tensor([1.9448], device='cuda:0'))"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_x = torch.mean(y_train, dim=(0, 1)).to(DEVICE)\n",
        "std_x = torch.std(y_train, dim=(0, 1)).to(DEVICE)\n",
        "mean_x , std_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JnWdpstFHsq9",
        "outputId": "09e7edf7-73fa-4a11-8a71-845b6159e43f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAF7CAYAAACZ51IDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWtUlEQVR4nO3dd3wUZf4H8M/Mtuwmm94hQEKXJicSUWmCCBYsqAeH0hT0BBVQz8O7n4B6InZFBRuCIgoWBOQOBaSDjSJSTSIQIIUSkk12k20zvz82WbLpZTez2Xzer9e8dtrOfjeQ3U+eeeYZQZZlGUREREQ+JCpdABEREQU+Bg4iIiLyOQYOIiIi8jkGDiIiIvI5Bg4iIiLyOQYOIiIi8jkGDiIiIvI5Bg4iIiLyOQYOIiIi8jkGDiIvW7JkCQRBwIkTJ+r93AkTJqBdu3Ye6wRBwJw5c7xSW33MmTMHgiA0yWsVFRXh/vvvR3x8PARBwPTp05vkdb1py5YtEAQBW7ZsUboUIr/EwEFUi5EjR8JgMKCwsLDafcaOHQutVosLFy40YWUNM2HCBAiC4J5CQ0PRq1cvvPLKK7BarV55jXfeeQdLliyp8/7PP/88lixZgr///e/45JNPcO+993qljpo4nU589NFHGDRoECIjI6HT6dCuXTtMnDgRv/76q89f35+cOnUKc+fORd++fREREYHo6GgMGjQIGzduVLo0CiBqpQsg8ndjx47F2rVrsWrVKowbN67SdovFgtWrV2P48OGIiorCvffei9GjR0On03nl9YuLi6FWe/dXVafT4YMPPgAA5Ofn46uvvsLjjz+OX375BZ9//nmjj//OO+8gOjoaEyZMqNP+P/zwA6666irMnj270a9dF8XFxbjjjjuwfv16DBgwAE899RQiIyNx4sQJrFy5EkuXLkVmZiZat27dJPUobfXq1Zg/fz5uu+02jB8/Hg6HAx9//DGuv/56LF68GBMnTlS6RAoADBxEtRg5ciSMRiOWL19eZeBYvXo1zGYzxo4dCwBQqVRQqVRee/2goCCvHauMWq3GPffc415+6KGHkJqaihUrVuDVV19FYmKi11+zJmfPnsVll13mteM5HA5IkgStVlvl9ieeeALr16/Ha6+9Vun0zezZs/Haa695rZbmYPDgwcjMzER0dLR73YMPPojLL78cTz/9NAMHeQVPqRDVQq/X44477sCmTZtw9uzZStuXL18Oo9GIkSNHAqi+D8c777yDbt26QafTITExEVOnTkV+fn6tr1+xD0dZ34r09HRMmDAB4eHhCAsLw8SJE2GxWBr0HkVRxKBBgwCgxr4nDocDzz77LNq3b+8+BfHUU095nIpp164dDh06hK1bt7pP25Qdu6Kyfg/Hjx/HunXr3PuX1XD27Fncd999iIuLQ1BQEHr16oWlS5d6HOPEiRMQBAEvv/wyXn/9dXdthw8frvI1T58+jXfffRfXX399lX1FVCoVHn/8cY/WjX379mHEiBEIDQ1FSEgIhgwZgh9//LHan1P5n0VVrTyDBg3y+JmU/RxWrlyJuXPnolWrVjAajbjzzjtRUFAAq9WK6dOnIzY2FiEhIZg4cWKl01+CIGDatGn45ptv0L17d+h0OnTr1g3r16+vtc5u3bp5hA3A1Qp244034vTp0zWeTiSqK7ZwENXB2LFjsXTpUqxcuRLTpk1zr8/Ly8N3332HMWPGQK/XV/v8OXPmYO7cuRg6dCj+/ve/49ixY1i4cCF++eUX7Ny5ExqNpt413X333UhOTsa8efOwd+9efPDBB4iNjcX8+fMb9B4zMjIAAFFRUdXuc//992Pp0qW488478dhjj+Gnn37CvHnzcOTIEaxatQoA8Prrr+Phhx9GSEgI/vWvfwEA4uLiqjxe165d8cknn2DGjBlo3bo1HnvsMQBATEwMiouLMWjQIKSnp2PatGlITk7GF198gQkTJiA/Px+PPvqox7E++ugjlJSUYMqUKdDpdIiMjKzyNf/3v//B4XDUuZ/IoUOH0L9/f4SGhuIf//gHNBoN3n33XQwaNAhbt25FampqnY5TF/PmzYNer8c///lPpKenY8GCBdBoNBBFERcvXsScOXPw448/YsmSJUhOTsbTTz/t8fwdO3bg66+/xkMPPQSj0Yg333wTo0aNQmZmZo3/rtXJycmBwWCAwWDw1luklkwmolo5HA45ISFB7tevn8f6RYsWyQDk7777zr3uo48+kgHIx48fl2VZls+ePStrtVp52LBhstPpdO/31ltvyQDkxYsXu9eNHz9ebtu2rcdrAJBnz57tXp49e7YMQJ40aZLHfrfffrscFRVV63sZP368HBwcLJ87d04+d+6cnJ6eLj///POyIAhyz549K71Omf3798sA5Pvvv9/jeI8//rgMQP7hhx/c67p16yYPHDiw1lrKtG3bVr7ppps81r3++usyAHnZsmXudTabTe7Xr58cEhIim0wmWZZl+fjx4zIAOTQ0VD579mytrzVjxgwZgLxv37461XbbbbfJWq1WzsjIcK/LysqSjUajPGDAAPe6zZs3ywDkzZs3e7yv8ePHVzrmwIEDPX4+Zc/t3r27bLPZ3OvHjBkjC4IgjxgxwuP5/fr1q/L/iVarldPT093rfvvtNxmAvGDBgjq91/LS0tLkoKAg+d577633c4mqwlMqRHWgUqkwevRo7N692+OUw/LlyxEXF4chQ4ZU+9yNGzfCZrNh+vTpEMVLv3KTJ09GaGgo1q1b16CaHnzwQY/l/v3748KFCzCZTLU+12w2IyYmBjExMejQoQOeeuop9OvXz91KUZX//ve/AICZM2d6rC9rlWjo+6jp9eLj4zFmzBj3Oo1Gg0ceeQRFRUXYunWrx/6jRo1CTExMrcct+/kYjcZa93U6nfj+++9x2223ISUlxb0+ISEBf/vb37Bjx446/bzraty4cR6tXampqZBlGZMmTfLYLzU1FadOnYLD4fBYP3ToULRv39693LNnT4SGhuLPP/+sVx0WiwV33XUX9Ho9XnjhhQa8E6LKGDiI6qisU+jy5csBuPoCbN++HaNHj66xk+jJkycBAJ07d/ZYr9VqkZKS4t5eX23atPFYjoiIAABcvHix1ucGBQVhw4YN2LBhA7Zt24ZTp05h586dHl+qFZ08eRKiKKJDhw4e6+Pj4xEeHt7g91HT63Xs2NEjpAGu0zBl28tLTk6u03FDQ0MBoE79Es6dOweLxVLp366sDkmScOrUqTq9bl1U/DcNCwsDACQlJVVaL0kSCgoKanw+4Pp/UZf/E2WcTidGjx6Nw4cP48svv2zyDsQUuBg4iOroiiuuQJcuXfDZZ58BAD777DPIsuwOIk2tupAjy3Kdnjt06FAMHToU/fv3r9fln001GFh91dSHprwuXboAAH7//XdflgOg+p+V0+mscn11/6Z1/bduzP+JMpMnT8a3336LJUuW4Lrrrqvz84hqw8BBVA9jx47FwYMHceDAASxfvhwdO3bElVdeWeNz2rZtCwA4duyYx3qbzYbjx4+7t/u7tm3bQpIkpKWleazPzc1Ffn6+x/vwRihp27Yt0tLSIEmSx/qjR4+6tzfEiBEjoFKpsGzZslr3jYmJgcFgqPRvV1aHKIqVWh/Ki4iIqPJKJG+3BnnLE088gY8++givvfaax6ksIm9g4CCqh7LWjKeffhr79++vU+vG0KFDodVq8eabb3r8pfnhhx+ioKAAN910k8/q9aYbb7wRgOsqlPJeffVVAPB4H8HBwXW65Le218vJycGKFSvc6xwOBxYsWICQkBAMHDiwQcdNSkrC5MmT8f3332PBggWVtkuShFdeeQWnT5+GSqXCsGHDsHr1ao++O7m5uVi+fDmuvfZa9ymaqrRv3x4//vgjbDabe923337r1dMw3vLSSy/h5ZdfxlNPPVXpCiAib+BlsUT1kJycjKuvvhqrV68GgDoFjpiYGMyaNQtz587F8OHDMXLkSBw7dgzvvPMOrrzySo8BuPxZr169MH78eLz33nvIz8/HwIED8fPPP2Pp0qW47bbbMHjwYPe+V1xxBRYuXIjnnnsOHTp0QGxsbL2b56dMmYJ3330XEyZMwJ49e9CuXTt8+eWX2LlzJ15//fU6dfqsziuvvIKMjAw88sgj+Prrr3HzzTcjIiICmZmZ+OKLL3D06FGMHj0aAPDcc89hw4YNuPbaa/HQQw9BrVbj3XffhdVqxYsvvljj69x///348ssvMXz4cNx9993IyMjAsmXLPDp2+oNVq1bhH//4Bzp27IiuXbtWav25/vrrq720maiuGDiI6mns2LHYtWsX+vbtW6kDZXXmzJmDmJgYvPXWW5gxYwYiIyMxZcoUPP/88w0ag0MpH3zwAVJSUrBkyRKsWrUK8fHxmDVrVqUhyZ9++mmcPHkSL774IgoLCzFw4MB6Bw69Xo8tW7bgn//8J5YuXQqTyYTOnTvjo48+qvOQ6dUxGAz43//+hyVLlmDp0qV49tlnYbFYkJiYiOuuuw6ffvopWrVqBcA1KNb27dsxa9YszJs3D5IkITU1FcuWLat1DI4bbrgBr7zyCl599VVMnz4dffr0wbfffuu+ssdf/PbbbwCAtLS0Kscn2bx5MwMHNZog16c3EREREVEDsA8HERER+RwDBxEREfkcAwcRERH5HAMHERER+RwDBxEREfkcAwcRERH5HMfhgGtkwaysLBiNRr+9TwQREZE/kmUZhYWFSExMrHSzxfIYOABkZWXVeD8EIiIiqtmpU6dqvBEkAwfgHiL51KlTNd4XgYiIiDyZTCYkJSXVersBBg5curNlaGgoAwcREVED1NYlgZ1GiYiIyOcYOIiIiMjnGDiIiIjI5xg4iIiIyOcYOIiIiMjnGDiIiIjI5xg4iIiIyOcYOIiIiMjnGDiIiIjI5xg4iIiIyOcYOIjIr9ntdrz77rs4efKk0qUQUSMwcBCRX9uyZQs+++wzvPDCC0qXQkSNwMBBRH4tPz8fAHDkyBFlCyGiRmHgICIiIp9j4CAiv1bbLa+JqHlg4CAiv/b9998rXQIReQEDBxH5tYsXLypdAhF5AQMHERER+RwDBxEREfkcAwcRERH5HAMHERER+RwDBxEREfkcAwcRERH5HAMHEfk1WZaVLoGIvICBg4iIiHxO0cCxbds23HLLLUhMTIQgCPjmm288tguCUOX00ksvufdp165dpe28qyRR4GALB1FgUDRwmM1m9OrVC2+//XaV27Ozsz2mxYsXQxAEjBo1ymO/Z555xmO/hx9+uCnKJ6ImIEmS0iUQkReolXzxESNGYMSIEdVuj4+P91hevXo1Bg8ejJSUFI/1RqOx0r5EFBjYwkEUGJpNH47c3FysW7cO9913X6VtL7zwAqKiotC7d2+89NJLcDgcNR7LarXCZDJ5TETknxg4iAKDoi0c9bF06VIYjUbccccdHusfeeQR/OUvf0FkZCR27dqFWbNmITs7G6+++mq1x5o3bx7mzp3r65KJiIioVLMJHIsXL8bYsWMRFBTksX7mzJnu+Z49e0Kr1eKBBx7AvHnzoNPpqjzWrFmzPJ5nMpmQlJTkm8KJiIioeQSO7du349ixY1ixYkWt+6ampsLhcODEiRPo3LlzlfvodLpqwwgRERF5X7Pow/Hhhx/iiiuuQK9evWrdd//+/RBFEbGxsU1QGRH5mig2i48pIqqFoi0cRUVFSE9Pdy8fP34c+/fvR2RkJNq0aQPAdbrjiy++wCuvvFLp+bt378ZPP/2EwYMHw2g0Yvfu3ZgxYwbuueceRERENNn7ICLfEQRB6RKIyAsUDRy//vorBg8e7F4u61cxfvx4LFmyBADw+eefQ5ZljBkzptLzdTodPv/8c8yZMwdWqxXJycmYMWOGR/8MIiIiUp4g85ozmEwmhIWFoaCgAKGhoUqXQ0TljBo1ChcuXAAAbNmyRdliiKiSun6H8uQoEfk1nlIhCgwMHERERORzDBxERETkcwwcROTX2M2MKDAwcBAREZHPMXAQkV9jCwdRYGDgICIiIp9j4CAiv8YWDqLAwMBBREREPsfAQURERD7HwEFEREQ+x8BBRH6NfTiIAgMDBxEREfkcAwcR+TW2cBAFBgYOIiIi8jkGDiLya2zhIAoMDBxERETkcwwcRERE5HMMHETk13hKhSgwMHAQkV9j4CAKDAwcRERE5HMMHETk18q3cEiSpGAlRNQYDBxE5NfKhwy73a5gJUTUGAwcROTXyrdwlJSUKFgJETUGAwcR+bXyLRwMHETNFwMHEfm18i0cxcXFClZCRI2haODYtm0bbrnlFiQmJkIQBHzzzTce2ydMmABBEDym4cOHe+yTl5eHsWPHIjQ0FOHh4bjvvvtQVFTUhO+CiHzJ6bzUwmE2mxWshIgaQ9HAYTab0atXL7z99tvV7jN8+HBkZ2e7p88++8xj+9ixY3Ho0CFs2LAB3377LbZt24YpU6b4unQiaiKS5HTPWywWBSshosZQK/niI0aMwIgRI2rcR6fTIT4+vsptR44cwfr16/HLL7+gT58+AIAFCxbgxhtvxMsvv4zExESv10xETcdqtXoss4WDqPny+z4cW7ZsQWxsLDp37oy///3vuHDhgnvb7t27ER4e7g4bADB06FCIooiffvqp2mNarVaYTCaPiYj8T8U+G2zhIGq+/DpwDB8+HB9//DE2bdqE+fPnY+vWrRgxYgScTlcTa05ODmJjYz2eo1arERkZiZycnGqPO2/ePISFhbmnpKQkn74PImqYioGDnUaJmi9FT6nUZvTo0e75Hj16oGfPnmjfvj22bNmCIUOGNPi4s2bNwsyZM93LJpOJoYPID1U8hcJTKkTNl1+3cFSUkpKC6OhopKenAwDi4+Nx9uxZj30cDgfy8vKq7fcBuPqFhIaGekxE5H+ys7M9lmtquSQi/9asAsfp06dx4cIFJCQkAAD69euH/Px87Nmzx73PDz/8AEmSkJqaqlSZROQlp06d8ljOzMxUqBIiaixFT6kUFRW5WysA4Pjx49i/fz8iIyMRGRmJuXPnYtSoUYiPj0dGRgb+8Y9/oEOHDrjhhhsAAF27dsXw4cMxefJkLFq0CHa7HdOmTcPo0aN5hQpRAEhLS3PPy4IKf/75J+x2OzQajYJVEVFDKNrC8euvv6J3797o3bs3AGDmzJno3bs3nn76aahUKhw4cAAjR45Ep06dcN999+GKK67A9u3bodPp3Mf49NNP0aVLFwwZMgQ33ngjrr32Wrz33ntKvSUi8hKLxYJdu3ZBFlwfU7JKA4vFgl9++UXhyoioIRRt4Rg0aJDHsMUVfffdd7UeIzIyEsuXL/dmWUTkB3bs2AGr1QpZo4dgL4as1gGOEmzYsAFXX3210uURUT01qz4cRNRy7NixAwAgq0pbNEU1nPpw7Ny5Cw6HQ8HKiKghGDiIyO/IsowDBw5A0oYAosq93mlMgM1m9ejbQUTNAwMHEfmdM2fOID8/H84Qz4H9nCFxAICDBw8qURYRNQIDBxH5nbLxNyR9uMf6suUzZ840cUVE1FgMHETkd4xGIwBAcNo91gtOGwAgLCysyWsiosZh4CAiv1MWKARHicf6smWODkzU/DBwEJHfKRsQ0H2FSilZHQQAyMjIaPKaiKhxGDiIyO+sWbMGAGCP6eSx3hkSBykoDBs3bkJhYaESpRFRAzFwEJFfOXXqFH755Rc4jAmVOo1CEGCL6QKbzYr//e9/itRHRA3DwEFEfuXzzz8HANjjula53R7dAVBpsPKLL2C326vch4j8DwMHEfmNc+fOYf1330EKCoMjvG3VO6l1sMV0xvlz57Bx48amLZCIGoyBg4j8xvfffw+nwwFbfHdAEKrdzxbn2r527domrI6IGoOBg4j8RkhISN12FARAlt3jdRCR/2PgICK/8Ze//AUAoDJl1bhf2fay/YnI/zFwEJHfaN26NaKioqAqOlvjfmXbe/fu3RRlEZEXMHAQkd8QBAExMTEQHdaa9ysdcTQ6OropyiIiL2DgICK/YjAYAMkByHK1+whOx6V9iahZYOAgIr9RUlLiuhOsINYYOOTSK1g4xDlR88HAQUR+Y8mSJcjNzYU1vjsgVv/xZIvvAQB46eWXOfgXUTPBwEFEfmH37t1YuXIlpKBQ2BIvr3FfyRgHW2wXnDh+HIsWLYLNZmuaIomowdRKF0BELVtaWhreffdd/Prrr4AgoKTtNYBY+0eTtXUfaApO46uvvsLOnbswefL9GDx4MMQaWkaISDkMHESkiJycHHz44YfYuHEjZFmGI6w1rK37QDJE1u0AKi2KLrsVuqzfkJN7GM8++yxWrlyJBx98kJfLEvkhBg4ialJOpxOffvopPv74YzgcDjgNUbAmXQlnaGL9D6bWwdqmL2xxXaE7sxfHjh3DjBkzcM011+CJJ55AeHi41+snooZh4CCiJnPx4kU899xz2LNnD2RtCEpSroAjMqXG+6bUhawzoiRlIGxx3aE79TN27tyJo8eOYe6cOejevbuXqieixuDJTiJqEgcOHMD999+PPXv2wB7eBkXdboUjqn2jw0Z5UnAUijsPR0nrK3HhwgU8+uijWLFiBeQaLrEloqahaODYtm0bbrnlFiQmJkIQBHzzzTfubXa7HU8++SR69OiB4OBgJCYmYty4ccjK8rzHQrt27SAIgsf0wgsvNPE7IaKaHD58GNOnT8eFvIsoSeqLkg5DALXONy8mCLAn9ICl8wg4VDosXLgQS5Ys8c1rEVGdKRo4zGYzevXqhbfffrvSNovFgr179+L//u//sHfvXnz99dc4duwYRo4cWWnfZ555BtnZ2e7p4YcfboryiaiO1Go1JEmCwxgHey23nvcWpzEe1rgePn8dIqobRftwjBgxAiNGjKhyW1hYGDZs2OCx7q233kLfvn2RmZmJNm3auNcbjUbEx8f7tFYiarhOnTqhd+/e2LdvH0RLXt2vRGkMWYL27GFotTrcfvvtvn89IqpRs+rDUVBQAEEQKvU8f+GFFxAVFYXevXvjpZdegsPhqPE4VqsVJpPJYyIi3yrrvKk590eTvJ7KlA3RWoiUlGTec4XIDzSbwFFSUoInn3wSY8aMQWhoqHv9I488gs8//xybN2/GAw88gOeffx7/+Mc/ajzWvHnzEBYW5p6SkpJ8XT5Ri+VwOPDWW2/hk08+AdRaOCLbNcnrOoOj4TRE4ejRo5g+fTrOnz/fJK9LRFUTZD/pvi0IAlatWoXbbrut0ja73Y5Ro0bh9OnT2LJli0fgqGjx4sV44IEHUFRUBJ2u6k5pVqsVVuul21+bTCYkJSWhoKCgxmMTUd05HA4cP34cb7/9Nvbv3w9JHwFLhyGQg+r3O2Y4tBoqywU4DVGwdLu1fkVIDgSd2AXNhXRERETiiSceR69evRAcHFy/4xBRtUwmE8LCwmr9DvX7cTjsdjvuvvtunDx5Ej/88EOtgSA1NRUOhwMnTpxA586dq9xHp9NVG0aIqP6sViuOHz+OP/74A2lpafjjjz+QkZHhPr1pj0hGSfK1gErTtIWJapQk94czOBoXT/2Mp556CgDQqnVrdOrYEZ06dULHjh3RsWNHhIWFNW1tRC2MXweOsrCRlpaGzZs3Iyoqqtbn7N+/H6IoIjY2tgkqJGp5iouLkZGR4Q4Xx44dw8mTJ+F0Oi/tJKrg1EfCGRkFpzEejojkJrkypUqCAHvcZXCGxEJ98QRU5gs4nXMeZ06fxubNm927xcXFoVOnTu6pY8eOiIxsgs6tRC2EooGjqKgI6enp7uXjx49j//79iIyMREJCAu68807s3bsX3377LZxOJ3JycgAAkZGR0Gq12L17N3766ScMHjwYRqMRu3fvxowZM3DPPfcgIiJCqbdF1Ow4nU5YLBaYzWb3VFRU5DF/4sQJpKWlITMz03MgLZUGDn00pOAoOA1RkAzRkPRhgOBfXcSk4GjYgqNdC7IMwW6BynweouUCVOYLyMm7gNzt27F9+3b3c6KiotCpUye0b98e4eHhCA4ORkhICIKDg91T2bJG08StN0TNjKJ9OLZs2YLBgwdXWj9+/HjMmTMHycnJVT5v8+bNGDRoEPbu3YuHHnoIR48ehdVqRXJyMu69917MnDmzXqdM6nr+icgfORyOSkGhLDyUDw3VLReZzSgpLq7Ta8kqrStUBEfBaYiGMzgKsi7Up60XjerDUU+C3QLRfAEqy4VLj7aiOj1Xo9UipIpAUlU4qW6Zp3qpOarrd6jfdBpVEgMHKcVut9cYDCwWS7XbisxmmIuKPDpA15mogqzSQhY1kFUa17xKC6i1nsuqS8tSUChkbUiTnxppysBRJUcJVMX5EBxWwGmD4LRBcNohOG2uZYe9dJ0NKF0vOm2AVPPl+VVRq9UIDg5BcLCh1nBS1bLBYEBQUBAEpU5fUYsUMJ1GiZQgyzIcDgesVitsNpv7sWy+vutLSkqqDA02m63+xYlqyCoNJJUWUBsh66JKA4KmNCBoPZfV2krbIaq8/0MLVOogOI0NGFhQltwBRHDaIDhsgGSH4LgUWi4FGNey02mD1WbDxeICiLnnAKe93i+rUqlgMHgGlpCQEOj1emi1Wuh0Ovdj2XxD1jPUUH0xcJDfkyTJ40u8qseKX/CNXW+12SBLkvffjKh2tRaotIAmDHJQaRhQlw8LmnKtCxWXNQwLzYUgAmodZLUODW5GliXA6SgXSmyeIcZpAxx2j9DicNpgc9hQcKEQwrkLEBx2oOEVVEuj1UKn1UGr0yKoQkApH1Iasr66kKNW8yurOeO/HtVZ2V/99f0yb0grgdVmg610vraRYxtOcJ1aEFWQRTUguOahCoEcXG5ZVLv3g6AuXVf6HFEFWaiwj6guXVduH1HtuiTUzzpSkp8TRNdpLrW2EaFFBiSHq0VFdkKQHIDkhCA5Xad95EvzrkcnBNm1T/n9BMnp8Xyn5ESJ5ADMDgiFVgjltkH2QViHq/WmLOjodLUHlJrW1ycUsTXHOxg4WjhJknD+/HlkZ2cjKyvLYyosLGyav/oB1wer6Poyl4WyL+ogICi46i/6qsJAVV/0VYUBUQUIKtdr8oOEAp0gACpXXx3AF20dVZClWkKNA4LsGWhcQadi8Cm3TXLCITlgk5ww2xwQSoohSEUex/aViq05er0e8fHxSExM9Jji4+N5tVINGDhaAKvVipycHJw5c8YdLNzz2dmwV9WPQFRBUgfV8Fe/55e3x1/ydf6r3xUkIIr8y58okAgioBLdIQdogqAjy0CFEHMp1JS1vFRs4bnUmuMRfCQnIF8KPk7JgRLJWdqaUwLBeR4ZGRmV37YgICYmBq1atfIIIgkJCWjVqhWMRqOvfwp+jYEjAMiyjIKCAmRlZSE7OxtnzpzxmK/uHhKyOgiSLgxSiBGSzui6CkHnmpc1Bv71T0TNhyCU/gGjdocbn4YchxWitRCi1QSxpBCCtRCitRA5+SacPbsP+/btq/SUkBAjEhMT3IGkLIgkJiYiOjoaKlVg989i4AgAL7/8MtatW1frfrJK4xpDQR8JpyESsja43JULpR0TRTWDBhFRbdQ6SCotJH14uSuO7K7JUQKx+GLpeC55EO1mAEBRUSH++KMQf/xR+Y7JcXFxWLp0KYKCgpr6nTQZBo4A0KVLF2RmZnqMFGmxWDyHmgYgOO1QF+YAhTk1H1ClhaTSQBY17nO/rqskyo3Z4N5WdrmlxvOKClHjOlVC1ACGg6sg2EsAAILD9Sha8hC87zPImiBYut+uZHnU3Mmy6xJl93gqVc8LTnvpfmWXMV+aF0qf35AOsoIgQK/Xuy9bNhgMaNeuXcBfhRPY766FuOWWW3DLLbd4rJNlGTabzR0+ysJIXR+Li4tRZDbDYjbBam7AwFJAFYNLVQguorb6QKPSQlbrAJWWLS4tkGAvgejwHP1UgAzBUQwfdVum5qDsihuHFYLTWikEVAwE8BikzQ6xLCQ0YHwTAFCp1Qg2GBAcboTBYHCHheoeq9sWFBQEsQX+QcbAEaAEQXBf4tXYG1A5HA4UFxfXGlSq22a2WGAxm2EpykO9B7YVBMhqHSRV6XgG6qBLYxuULns+6iCrgti6QuTvZLl0pNYSV4BwWMvNl1/nWhZLQwYkZ+3HriAoKAiG4GAEG0LrHAqqetRqtT74QbQcDBxUK7VaDaPR2Oge1rIso7i42KMVpcqAUjoSp8lkQkFBAQoKClzzpjw46zomh0oLSa2FrAqqIpxUPc/+K0QNJDlrDg3OqtbbUJdunYIgICQkBOHRUQgNDfWYyp+SqC486PX6gD9V0VzwX4GajCAI7g+F6Ojoej+/LLC4A0jpY/n5iusKTCaUmKq+SqcSUQVZpYNUQyhxGhMg60LqXTtRs+S0Q11wGoK9uMpWB8Fhhei01vkUhVqtRmhYGMJCoxAWFobQ0FD3Y9kUFhbmsS4kJCTgr95oKRg4qNkoH1gSEhLq/DybzVYpmHiEkgrr8vPzUVSUX/XpH0GELaYTbAmXQ9YavPjuiPyI5ITm3DHosn+DYK/6TsJ6vQFhkaEIDU2sMjxUNa/X6zlqZwvGwEEBT6vVIjo6ul6tKk6n031apyyY5Obm4ssvv8KZM0ehPZ8OW2xXWBN6AOrAvYyNWhhZgvp8OoKy9kOwFUGv12PUX+9Bp06dKoUHjqhJ9cXAQVQFlUrlbtot75ZbbsH333+PDz74EHk5v0N77ihKEi6HPaGHQpUSeYfKlI2gk7sglhRApVLhzr/+FWPGjEF4eLjSpVGAYOAgqkFhYSFOnDjhno4fP44TJ04gLy/PtYPTDt2ZPbDHdXV1OiVqprQ5ByGWFABwtfCtXrMGBw4cQLt27dxTcnIyYmJieFqEGoSfkEQAioqKPIJFWbi4cOFCpX0lnRFSeBKcQRGQ9OFwhsQybFCzV9x+INSmbIjF+RCLL8JZnI8jx/7AkSNHPPYrG6SqLICUzUdHRzOIUI34KUktVlZWFt58802kp6dXeb8ZSWeEFJYEpz4ckj4ckj4CUlA4oOKvDQUglRaOiLZARNtL62QJgrUQquKLpUEkH4XFF3H4yFEcPnzY4+nBwcFo164dRo8ejf79+zdx8dQc8JOTWqysrCz8/PPPkKTKY1c6g6PhDI6GFBQOKSgMkj6cN7SjlkcQIQeFwaEOgqgxuCZtMGRtMFSF2a67qZYym804dOgQfvvtNwYOqhIDB7VYffr0wapVq5CZmYmTJ08iMzPTPZ+TkwOVuUKrh0oDpy7U1doRFOYKI/owSLpQQOQ4AdTMyTIEmxliSYGrNaOkAGJJPlQlBVVeGhseHo62bduiTZs27qlt27aIi4tToHhqDhg4qEULCwtDjx490KOH51UmVqsVZ86cqRxGMjNhq9ivQxAgaUMgq/WQNEGXBgxzz5dOpcsc0ZSajOQsHaCrBIK9xHO0T/eya1JZiwDJcyRfQRSRmJiIthVCRVJSEkJDQxV6U9RcMXAQVUGn0yElJQUpKSke6yVJwtmzZ90BpCyQZGVl4eLFPDjMdRh6XVRB8rgHjGcgqRxYdIDAe8O0eLLsujlZuZDguslduSBhL4HgKHaNAOooqdMIoIIoItQYirikFHegKAsXrVq14v1DyGvqHThOnToFQRDQunVrAMDPP/+M5cuX47LLLsOUKVO8XiCRPxFFEfHx8YiPj0ffvn09tpUfej0/Px/5+fnu+bIRTcuvyy8ogNmUV6fXldW60pBSc+tJ2TyvmmkGZKlyS4O9/P1GLm0TS9fV5VboWq0O4eFhCA9PQFhYGMLDw92PZfNlU3h4OIxGY4u8cyk1vXp/Kv3tb3/DlClTcO+99yInJwfXX389unXrhk8//RQ5OTl4+umnfVEnkd9ryNDrDoejyjBSVVDJzy9AQcF5OJ213y1T0oZAMkTAqY+EZIiApI+EFBTKlhIlyDIEezHE4jyoLHkQLRdd8yUFdQoQRqMR4dFRHsGh/GPFdUFBHPmW/FO9A8fBgwfdf9mtXLkS3bt3x86dO/H999/jwQcfZOAgqge1Wo2oqChERUXVaX9ZllFUVOQOIpVaTfLzkZeXh+PHj+P8+VNQ55+69GRRBWdQOCRDJJz6CEiGSEj6CMgavY/eXQvkdEAsvui6jNSSVzqfB8Fh9dhNrzegfbfLEBcXV2WrQ9k6o9HIO51SwKj3/2S73Q6dTgcA2LhxI0aOHAkA6NKlC7Kzs71bHRF5EAQBRqMRRqPRfVqzOgUFBfjzzz89poyMP2E7fwHl74Iha/TulhCnPhLOkFjIQewQWCuHDerCbIil4UJVnAexxOSxiyCKSGrdGu3bt0dKSor7MS4ujoNkUYtT78DRrVs3LFq0CDfddBM2bNiAZ599FoBrTIO6/pVWZtu2bXjppZewZ88eZGdnY9WqVbjtttvc22VZxuzZs/H+++8jPz8f11xzDRYuXIiOHTu698nLy8PDDz+MtWvXQhRFjBo1Cm+88QZCQngLcWrZwsLC0Lt3b/Tu3du9zul0Ijs7GxkZGaUBJAMZGRnIzj4DmM64dhJUMHe9GVJw/X6fWxRJQvDRtRCLC9yrQkND0eGyv3gEi3bt2rn/QCNq6eodOObPn4/bb78dL730EsaPH49evXoBANasWVOpE11tzGYzevXqhUmTJuGOO+6otP3FF1/Em2++iaVLlyI5ORn/93//hxtuuAGHDx92n6ccO3YssrOzsWHDBtjtdkycOBFTpkzB8uXL6/vWiAKeSqVC69at0bp1awwcONC93mKx4Pjx49izZw8WL14Mbc7vKGk/SLlC/Zz64gmIxQW49tprMXLkSLRv3x6RkZFstSCqgSDLslzfJzmdTphMJkRERLjXnThxAgaDAbGxsQ0rRBA8WjhkWUZiYiIee+wxPP744wBcTcRxcXFYsmQJRo8ejSNHjuCyyy7DL7/8gj59+gAA1q9fjxtvvBGnT59GYmJinV7bZDIhLCwMBQUFvLacWjRZljF58mSkZ2SgqMddkHXKtBQG7/sMoqPyYFMAIKn1MPce08QVlSPLMBxeC3VxHpYv/7TOHYSJAlVdv0Mb1GVdlmXs2bMH7777LgoLCwEAWq0WBoOhYdVW4fjx48jJycHQoUPd68LCwpCamordu3cDAHbv3o3w8HB32ACAoUOHQhRF/PTTT9Ue22q1wmQyeUxELV12djYWLlyIrKwsQJahKmSfrCo5bVBZzgOQ8c4772D//v1owN9tRC1OvU+pnDx5EsOHD0dmZiasViuuv/56GI1GzJ8/H1arFYsWLfJKYTk5OQBQaZjcuLg497acnJxKLSpqtRqRkZHufaoyb948zJ071yt1EjVnsizjt99+w1dffYUdO3ZCliXIGgNsrf4CR2RK7QdoidQ6FHcYAm32b9i+fTu2b9+O9u3b484778R1113HPhtE1ah3C8ejjz6KPn364OLFi9DrL11Od/vtt2PTpk1eLc5XZs2a5XFZ4alTp2p/ElGAOXDgACZPnozp06dj+/btcBgiUZwyEEU974It8XLeH6YGjoi2sFw2EuauN8MemYyMP49j/vz5uPvuv+KLL75Qujwiv1TvFo7t27dj165dlYa7bdeuHc6cOeO1wuLj4wEAubm5HudIc3Nzcfnll7v3OXv2rMfzHA4H8vLy3M+vik6n418h1OJ99dVXSE9PhzM4GiVtroIU0rD+Vy2ZFBKLkpBYWG1maLP2o+DcMbz//vu4/fbbOX4GUQX1buGQJKnKkQ5Pnz4No9HolaIAIDk5GfHx8R6tJiaTCT/99BP69esHAOjXrx/y8/OxZ88e9z4//PADJElCamqq12ohCkTjx4+HRquFaC2CrOVl5I0hawwQbWYAwOTJkxk2iKpQ78AxbNgwvP766+5lQRBQVFSE2bNn48Ybb6zXsYqKirB//37s378fgKuj6P79+5GZmQlBEDB9+nQ899xzWLNmDX7//XeMGzcOiYmJ7itZunbtiuHDh2Py5Mn4+eefsXPnTkybNg2jR4+u8xUqRC1VSkoKpk2dCsFRAn36JohFZ103CKN6EWxm6E7uhrrgNK666irceeedSpdE5JfqfVns6dOnccMNN0CWZaSlpaFPnz5IS0tDdHQ0tm3bVq/LYrds2YLBgwdXWj9+/HgsWbLEPfDXe++9h/z8fFx77bV455130KlTJ/e+eXl5mDZtmsfAX2+++Wa9Bv7iZbHUUsmyjP/85z/YuHEjAMBpiIYt7jI4IpMV7cPh15fFAq6reIpyock9DE3+SUCWER8fj0WLFiE8PFzZ2oiaWF2/Qxs0DofD4cDnn3+OAwcOoKioCH/5y18wduxYj06kzQkDB7VkZVeqfP3119i+fUfplSp62KI7wR7bBbI2uMlr8tvAITmgvvAntGcPQ2Vx3em3Q4eOGDXqDl6hQi2WTwNHoGHgIHLJzc3F6tWrsXbtWtcYO4KI4rZXwxHTqfYne5E/Bg6huADBx/7ruvOrKGLgwIG444470L17d44wSi1aXb9D692z6eOPP65x+7hx4+p7SCLyE3FxcZgyZQrGjx+PTZs2YcGCtyBn7UdRdEeghX+panMPQbAXY9SoURg9ejRiYmKULomoWal34Hj00Uc9lu12OywWi3ukUQYOouZPp9PhxhtvxJEjR7B27VqoCnPgDG3BQ3hLTmguHkd0dDQeeughqFQco4Sovup9lcrFixc9pqKiIhw7dgzXXnstPvvsM1/USEQKueGGGwAA2uwDgCwpXI1yNOeOQXC4RlZm2CBqmAbdS6Wijh074oUXXqjU+kFEzVu3bt3Qt29fqE1noMv8uUVeNqvKP4WgUz8hPDwct99+u9LlEDVbXgkcgOseJllZWd46HBH5AUEQMHv2bKSkpEB79jA0uYeULqlJieYLMPy5GVqNFi+88EKD74ZNRA3ow7FmzRqPZVmWkZ2djbfeegvXXHON1wojIv8QHByM+fPnY9KkScCpn2GP7gioW8bln7pTPwFOB/75r6fQpUsXpcshatbqHTjKRvksIwgCYmJicN111+GVV17xVl1E5EfMZjOKisxwGqIAlbb2JwQIpzEe6sKcSvdsIqL6q3fgkKSW23GMqKVavHgxZFmCtdVfWtTlsba47tCdPYJPP/0Ut9xyC4KDm34QNKJA4bU+HEQUmA4dOoRt27bBERILZ1hrpctpWmotrPE9UFhYiOXLlytdDVGzVqcWjpkzZ9b5gK+++mqDiyEi/yJJEhYsWAAAsCb1bVGtG2VscZdBe/YoVq5ciZtvvhkJCS14PBKiRqhT4Ni3b1+dDsbhfYkCy6ZNm3D06FHYI1MghTTtFRrvvPNOlesffOSxJq0DoholrftA+HML3nvvPcyePbtpX58oQNQpcGzevNnXdRCRH0pPTwcAqAuzoDl7FPaYToDQss7EqgpzoM35HcClnwcR1V+9O40SUcsxadIkhIeH4+OPP4Zwche0Zw+jJKlvk/TleOihh6reoG6au1ILJSboTv8CzcWTAIBhw4bh/vvvb5LXJgpEDQocv/76K1auXInMzEzYbDaPbV9//bVXCiMi5el0OowZMwbDhw/HkiVLsGbNWhj++B6OsNYoSe4PWdM0X/5NSpagzdoPXelw7j179sRDDz3EcTiIGqnebaOff/45rr76ahw5cgSrVq2C3W7HoUOH8MMPPyAsLMwXNRKRwiIiIjBjxgwsXvwhrrzySqgLTiP48BqI5vNKl+ZdDiv0aRugy9qP+Lg4PPPMM3jjjTcYNoi8oN6B4/nnn8drr72GtWvXQqvV4o033sDRo0dx9913o02bNr6okYj8RHJyMl588UU88MADEO3FCD66DurzaUqX5RWi5SKCD6+FuuAMrr76anzwwfsYMGAAO8MTeUm9A0dGRgZuuukmAIBWq4XZbIYgCJgxYwbee+89rxdIRP5FEASMGTMGL744HyEGPfTHt0Nz9qjSZTWKUFKA4KNrIVpNGD9+PJ577jmEhIQoXRZRQKl34IiIiEBhYSEAoFWrVjh48CAAID8/HxaLxbvVEZHfuvLKK/Huu+9CFEWoL2QoXU6jqC9mAk4HHnnkEUycOBGi2LKuxCFqCnX+rSoLFgMGDMCGDRsAAHfddRceffRRTJ48GWPGjMGQIUN8UyUR+aVWrVohJSUFassFQG6+tz1Qmc8BAK699lqFKyEKXHUOHD179kRqaip69OiBu+66CwDwr3/9CzNnzkRubi5GjRqFDz/80GeFEpF/SkpKAiQHBGuh0qU0mKo4D3q9HlFRUUqXQhSw6hw4tm7dim7dumHevHno2rUrxo8fj507d+Kf//wn1qxZg1deeQURERG+rJWI/MyZM2ewY8cOyNpgyNrme2MzR0gciouL8e233ypdClHAqnPg6N+/PxYvXozs7GwsWLAAJ06cwMCBA9GpUyfMnz8fOTk5vqyTiPyMLMtYsGAB7HY7SpJSAbH5jiNoa90HUGvx/vvvIz8/X+lyiAJSvXtGBQcHY+LEidi6dSv++OMP3HXXXXj77bfRpk0bjBw50hc1EpEfWrFiBX788Uc4QlvBEdFW6XIaRdboUdLqChQVFeGZZ56B1WpVuiSigNOortgdOnTAU089hX//+98wGo1Yt26dt+oiIj/2zTffYNGiRZB1IShJvjYg7iJrj+kMe0Q77N27F3PnzoXD4VC6JKKA0uDAsW3bNkyYMAHx8fF44okncMcdd2Dnzp3erI2I/ND333+P119/HbLGAHOn4c2674YHQURJykA4wlpj165d+M9//gNJar5X3hD5m3oFjqysLDz//PPo1KkTBg0ahPT0dLz55pvIysrC+++/j6uuusrrBbZr1w6CIFSapk6dCgAYNGhQpW0PPvig1+sgIkCSJLzx5puAWgdL5xsgB4UqXZJ3iSoUd7gOjpA4bN68Gb///rvSFREFjDr38hoxYgQ2btyI6OhojBs3DpMmTULnzp19WRsA4JdffoHT6XQvHzx4ENdff7370lwAmDx5Mp555hn3ssFg8HldRC1RVlYWzEVFsEd1gKQP0KvSRDXscd2gLsrFsWPH0KtXL6UrIgoIdQ4cGo0GX375JW6++WaoVCpf1uQhJibGY/mFF15A+/btMXDgQPc6g8GA+Pj4JquJqKX6448/AADO4MAer6Ls/ZW9XyJqvDqfUlmzZg1uvfXWJg0bFdlsNixbtgyTJk3yuKHSp59+iujoaHTv3h2zZs2qdYh1q9UKk8nkMRFR7cr6NKiKzgGyrHA1vqMqOgsAHq2rRNQ4zeqGAd988w3y8/MxYcIE97q//e1vWLZsGTZv3oxZs2bhk08+wT333FPjcebNm4ewsDD3lJSU5OPKiQLDoEGD0KNHD2jy/gyYu8RWJJSYoD+5C3q9Hvfff7/S5RAFDEGWm8+fKTfccAO0Wi3Wrl1b7T4//PADhgwZgvT0dLRv377KfaxWq8d19iaTCUlJSSgoKEBoaIB1giPysrNnz2LSpEkospSg6LJbIevDvP4awfs+g+gornKbpNbD3HuM118TACBLMBz5Firzefzf//0f7w9FVAcmkwlhYWG1foc2mxaOkydPYuPGjbX+xZGamgoASE9Pr3YfnU6H0NBQj4mI6iY2NhZPPvkkIDkQdGJHQJ1a0eYchMp8HsOHD2fYIPKyZhM4PvroI8TGxuKmm26qcb/9+/cDABISEpqgKqKWqX///hg8eDDURbnQnDumdDleIZSYoMvah4iISPdl90TkPc0icEiShI8++gjjx4+HWn3pwpqMjAw8++yz2LNnD06cOIE1a9Zg3LhxGDBgAHr27KlgxUSBb9q0aQgODkHQ6V8BR/MfCjwo8ydAcmL69EdhNBqVLoco4DSLwLFx40ZkZmZi0qRJHuu1Wi02btyIYcOGoUuXLnjssccwatSoGvt4EJF3REVF4a9/vRtw2qA2ZSldTuM47VCbzqBLly4YMGCA0tUQBaRmcXvHYcOGoaq+rUlJSdi6dasCFRERAPTt2xeLFy+GypQNR2Sy0uU0mKowB5AlpKamelxyT0Te0yxaOIjIP3Xs2BF6vQGqohylS2kUVVEuAHBUUSIfYuAgogYrKipCcbEFsqZ5306grP5z584pXAlR4GLgIKIG27dvHwDAGdq8rworq3/v3r0KV0IUuBg4iKjBfv31VwCAw5iocCWNIwWFQ9bo8csvv/KW9EQ+wsBBRA3idDqxffsOyBoDpOBopctpHEGAPTwJeXkXcPjwYaWrIQpIDBxE1CAHDhxAQUE+7BFtgQC4ssMR4brKZtu2bQpXQhSYGDiIqEHKRvV1hLdRthAvcRoTAJWG/TiIfISBg4gaJC8vDwAg6UIUrsRLRBFOjQF5eReVroQoIDFwEFGD5OfnAwBktV7ZQrxIVgehoCCfHUeJfICBg4gaxG63u2YCoP+GmyBCkiQGDiIfYOAgogaJj48HAIjWIoUr8R7RWojomBiPm0QSkXcwcBBRgyQmusbeEK0mhSvxEkmCaDMjMaF5D2JG5K8YOIioQVq3bg0AEEsKFK7EO1zBSXa/LyLyLgYOImqQtm3bAgDE4nxlC/ESsdh1dUq7du2ULYQoQDFwEFGDJCQkQKvTQSzOU7oUrygLHMnJyQpXQhSYGDiIqEFEUUTPHj2gsuRBCICOo+qLmVCr1ejSpYvSpRAFJAYOImqwIUOGAAA0eX8qXEnjiMUXoSrOQ79+/RASEiADmRH5GQYOImqw/v37Q6PRQHM+DZCb79gVmnN/ALgUoIjI+xg4iKjBQkJCMHz4cIglBVBfyFC6nAYRbGZozx1FXFwcrr76aqXLIQpYDBxE1Cjjx4+HRqtF0Jl9gORUupx602a56p40aRK0Wq3S5RAFLAYOImqU6Oho3DlqFARbETRnjypdTr0IJQXQnk9Du3btMHToUKXLIQpoDBxE1GhjxoyBwWCALucA4LQrXU6d6c7sA2QZ9913H1QqldLlEAU0Bg4iarTQ0FCMHj0agr0Y2rOHlS6nTkRLHjR5f6Jz5y649tprlS6HKOAxcBCRV4waNQpBej3UF5rHJbLq0kt5x427F0Ig3fGWyE8xcBCRVwQHB6N1q1ZQ2cxKl1InotVVZ8eOHRWuhKhl8OvAMWfOHAiC4DGVHwWwpKQEU6dORVRUFEJCQjBq1Cjk5uYqWDFRyxYTEwM4ba7Jzwl2MwRRRGRkpNKlELUIfh04AKBbt27Izs52Tzt27HBvmzFjBtauXYsvvvgCW7duRVZWFu644w4FqyVq2USx9COlGQwCJsjSpXqJyOfUShdQG7Vajfj4+ErrCwoK8OGHH2L58uW47rrrAAAfffQRunbtih9//BFXXXVVU5dK1OL98UcaJG0woA5SupRaOfWRcBadxYkTJ9ChQwelyyEKeH4f79PS0pCYmIiUlBSMHTsWmZmZAIA9e/bAbrd7XDvfpUsXtGnTBrt3767xmFarFSaTyWMiosbJz8/HuXNn4TREKV1KnUjB0QCAP/74Q+FKiFoGvw4cqampWLJkCdavX4+FCxfi+PHj6N+/PwoLC5GTkwOtVovw8HCP58TFxSEnJ6fG486bNw9hYWHuKSkpyYfvgqhlsNtLx98Q/b7hFAAgi65xN9x1E5FP+fUnw4gRI9zzPXv2RGpqKtq2bYuVK1dCr9c3+LizZs3CzJkz3csmk4mhg6iRoqKioNPp4CxpHi2GYmmdrVu3VrgSopbBr1s4KgoPD0enTp2Qnp6O+Ph42Gw25Ofne+yTm5tbZZ+P8nQ6HUJDQz0mImocURTRunVrqKwFzWK0UdFyAQADB1FTaVaBo6ioCBkZGUhISMAVV1wBjUaDTZs2ubcfO3YMmZmZ6Nevn4JVErVcAwYMAJx26M7sVbqUGqlM2dDkZ6Jz586IjY1VuhyiFsGvA8fjjz+OrVu34sSJE9i1axduv/12qFQqjBkzBmFhYbjvvvswc+ZMbN68GXv27MHEiRPRr18/XqFCpJDRo0cjKSkJ2tzDEM3nlS6napIDQSd3QhRFPP744xxllKiJ+HXgOH36NMaMGYPOnTvj7rvvRlRUFH788UfX4EIAXnvtNdx8880YNWoUBgwYgPj4eHz99dcKV03Ucul0Ojz22GMAZASd2AnIstIlVaLN/h1iiQl33303RxklakKCLPvhJ0ITM5lMCAsLQ0FBAftzEHnB888/j++//x7Fyf3hiK7/l3rwvs8gOoqr3Cap9TD3HtOgugSbGSG/f4WoiDAsW7asUZ3Picilrt+hft3CQUTN0/333w+dToegM3v8qgOp7vSvgOTAAw88wLBB1MQYOIjI62JjY123q7dZoLmQrnQ5AADBWgTNhQx06tTJY8BAImoaDBxE5BM333wzAECdn6lwJS7qglMAXHXxHipETY+/dUTkEzExMejYsSPUpmy/OK2izncFDl42T6QMBg4i8pk+ffoAsgRV6SBbSlKZz6Ft27buq9yIqGkxcBCRz4SFhblmlG7hkGUIDluley8RUdNh4CAinzEYDAAAQenAITkByLwyhUhBDBxE5DOXOmcqPdyP6/XZWZRIOfztIyKfKSwsBADIKq2yhYhqQBDd9RBR02PgICKfMZlct4CX1TplCxEEyGqdux4ianoMHETkM2fOnAEAyLoQhSsBJE0wsrOz4XA4lC6FqEVi4CAin/kjLQ2yRg9ZY1C6FDiDI2Gz2XDq1CmlSyFqkRg4iMgnzGYzcrKz4TREKV0KAEAqrSM93T+GWidqaRg4iMgnLl68CACQtMq3bgCApA0GAOTn5ytbCFELxcBBRD5RXFx6e3lR4StUyogaAK6WFyJqegwcROQTZYFDFlUKV+Iii2oAQElJicKVELVMDBxE5BNl9ywRbUUKV+JSVgfvpUKkDAYOIvKJuLg4aHU6iMUFSpcCABCL8wEAbdu2VbYQohaKgYOIfEIURbRu1QqizT9G9xStrjpatWqlcCVELRMDBxH5TFBQEATJqXQZLrKrDt7AjUgZDBxE5DMqlQqQJaXLcJFdN3BTqfyjEytRS8PAQUQ+IUkScnNz3VeHKK60juzsbIULIWqZGDiIyCf27NmDs2fPwh6ZonQpAAB7ZDIA4L///a/ClRC1TAwcROQT69atAwDYYzopXImLM6wVZK0BGzZs4FgcRApg4CAir8vJycG2bdvgNES572GiOEGELboTzGYzvvvuO6WrIWpxGDiIyOu++OILSJIEW3x3QBCULsfNHtsVEFVYsWIFnE4/uXqGqIXw68Axb948XHnllTAajYiNjcVtt92GY8eOeewzaNAgCILgMT344IMKVUxERUVF+PbbbyFrQ+Ao7TfhL2SNHraojsjKysKuXbuULoeoRfHrwLF161ZMnToVP/74IzZs2AC73Y5hw4ZVuvnS5MmTkZ2d7Z5efPFFhSomoqNHj8JqtcIW3QEQ/O8jxh7dEQCwb98+hSshaln85Hq1qq1fv95jecmSJYiNjcWePXswYMAA93qDwYD4+PimLo+IqpCWlgYA/tN3owLJEAEIortOImoa/vfnRw0KClz3ZIiMjPRY/+mnnyI6Ohrdu3fHrFmzYLFYajyO1WqFyWTymIjIOzIyMgAATkNkLXsqRFTDGRSG9PQMpSshalH8uoWjPEmSMH36dFxzzTXo3r27e/3f/vY3tG3bFomJiThw4ACefPJJHDt2DF9//XW1x5o3bx7mzp3bFGUTtTju29KrgxSupHqyWocSs3/cVI6opWg2gWPq1Kk4ePAgduzY4bF+ypQp7vkePXogISEBQ4YMQUZGBtq3b1/lsWbNmoWZM2e6l00mE5KSknxTOBERETWPwDFt2jR8++232LZtG1q3bl3jvqmpqQCA9PT0agOHTqeDTqfzep1E5B2yJghld2ARHCUQIEOGAFkdBFnjvy0nRFQ9vw4csizj4YcfxqpVq7BlyxYkJ9d+id3+/fsBAAkJCT6ujoiqYrfbXTONuELF0v1297zh0GqoLBcgGSJh6XZrY8tzEVSQJQkOhwNqtV9/DBIFDL/+TZs6dSqWL1+O1atXw2g0IicnBwAQFhYGvV6PjIwMLF++HDfeeCOioqJw4MABzJgxAwMGDEDPnj0Vrp6oZbJarQAEv7wktowsuu4Ya7VaGTiImoj/fiIAWLhwIQoKCjBo0CAkJCS4pxUrVgAAtFotNm7ciGHDhqFLly547LHHMGrUKKxdu1bhyolarosXL0JWafxqhNFKVFoArlqJqGn4dbSXZbnG7UlJSdi6dWsTVUNEtcnLy0NmZiacYTX3tVKaMyQWmgvp+O2332rtF0ZE3uHXLRxE1LyU9aFyGP27D5Uj1FUfRxslajoMHETkNWUtjs6wRIUrqZmsC4WsDcGu3bt5q3qiJsLAQUReceHCBezYscO/bklfHUGALbojLGYzNm/erHQ1RC0CAwcRecV///tfOJ1O2GO7KF1KndhjOgGCgNWrVytdClGLwMBBRI3mcDiwZs0aQKWFPTJF6XLqRNYGwx6WhKNHj+Lo0aNKl0MU8Bg4iKjRdu/ejXPnzsEW1QFQaZQup87ssV0BAN98842yhRC1AAwcRNRoq1atAgDYSr/AmwtnaCKkoDBs2rSJd40m8jEGDiJqlAsXLmDfvn1wGOMh68OULqd+BAG2mE6w2+3Yvn270tUQBTQGDiJqlO3bt0OWZTgi2ildSoM4Ilz3aOIggkS+xcBBRI2yY8cOAGi2gUPWhcAZHI09e/bAYrEoXQ5RwGLgIKJGOXHiBCSdEbLWoHQpDeYMiYPT6cSZM2eULoUoYDFwEFGDWa1WnD9/HpLOqHQpjSLpQgAAWVlZCldCFLgYOIiowdLT0wEgAAJHKAAgLS1N4UqIAhcDBxE1WNnlsI7IZIUraRynMQGyOghr166F1WpVuhyigMTAQUQNcvbsWWzevBlOfQScfn532Fqp1LDFdEZBQQE2bNigdDVEAYmBg4jqzWKxYM6cuXA6nbDFdwcEQemSGs0e2xUQVVi4cBFPrRD5AAMHEdWL1WrFv/71Lxw+fAj26I5wRHVQuiSvkLUGFLfrD7PZjMceexwnTpxQuiSigMLAQUR15nA48PTTT2Pfvn2wRySjpN01AdG6UcYRlYLi5GthMhVg5syZyM7OVrokooDBwEFEdbZs2TL89NNPcIQloSRlACAE3keII7ojStpchby8PDzzzDNwOBxKl0QUEALv04KIfOLgwYNYuvRjyLoQFKcMBESV0iX5jD3uMtijOuDIkSNYunSp0uUQBQQGDiKqVVpaGp559lnIsozi5IGAWqt0ST5X0rYfJJ0Ry5Z9iv/973+QZVnpkoiaNQYOIqpWcXExFi5ciAceeABnc3NhbX0FnMY4pctqGioNilMGQRZVmD9/Ph5//HGcPn1a6aqImi0GDiKq0k8//YQJEyZgxYoVcGhDYOk8HLaEnkqX1aSkkBgUdbsd9vA22LNnDyZOmoRPP/2U/TqIGkCtdAFE5D2yLMNqtcJsNqO4uBgWi6Xa+Zoms9mMwsJCQBBhTegFW2IvQGyZHxeyLgQlHYbAcfEk5Mwf8f777+OTTz6B0WiEwWCocdLr9QgODq52Xq/XQxT5dx+1DC3zE4TIj0iShJKSEpjNZlgsFhQXF9d/3mKBxWyGpbgYsiQ1rBBBhKzSQBY1kFUaSOFtYGt9BSR9hHffcHMkCHBEtkNRaCJ0WfvgLMyBxWSFkF8EwWkHpIa3eAQFBcFgCEZwsCuIGAwGdxip77xazY908l/830lUD5IkwW63w2azwWazwW6316nFoMpWhNLHkuLihhckqsuFhCDIwUagNDDIKo3nfOmjLJbNaz32CeSrTrxGrYW1TWrl9bIEOO0QnHYIkv3SvNMOSOXmnTYIUtm869Es2WG22HG+8ALE0uc2lFarhV5vQHBwzS0vNbXI6HQ6aDQaaLVaaDQahhjymoD5n/T222/jpZdeQk5ODnr16oUFCxagb9++SpdFXlLxi77sy76qx7pur+sxrDYb7DY7bHYbnN44d1/6pS+pNIAYDNkYfikQiBXCgUpbOTSU2ycQx8FolgQRUOsgq3Vo9LUssgxIjnKhpEJIqRBYLgUcG5xOO4ptdlwsLoAgnXft18ira0RRvBRAtFrotFp3GCn/qK1mfXXb63sMBp/mLyD+BVesWIGZM2di0aJFSE1Nxeuvv44bbrgBx44dQ2xsrNLlNWsB9UVfF6IKEFSQRRVkQXTPQzBADjICoggIasiiaxtEVWkAUJcLA9oqWhPKwoM6oEbmJB8QBPf/GQCNCzCyDMhOz4DitFVodakQYmQnIDlLHyVAdsIuOWFxOAG7A0Kh1bVNliBIzkadTqqPqoJPVeGlvsGnvsdg8Gk4QQ6Ai8tTU1Nx5ZVX4q233gLg+pJMSkrCww8/jH/+85+1Pt9kMiEsLAwFBQUIDQ31dbledejQIZw7dy6Av+hLH6v6oq/wCFGELKhLH1Uex3TNi5BFdemjqlxgKJ0XRIYBP2Q4tBoqywU4DVGwdLtV6XKoIlm+FGwkJ+ARWMoFk7Lt5efdj5KrVac04JR/fvngU/H5/hZ8KgaW+gYfg8GA3r17Q6fTNcl78Za6foc2+6hms9mwZ88ezJo1y71OFEUMHToUu3fvrvI5VqsVVqvVvWwymXxepy/k5uZi6tSpPju+LIiQNXrI6qDSSef6y4tf9ERURhBKf39Fd6sM0MiWmYbwVfCRHBAcVgiOEggOK2RHCaQK3yHe9Oijj+L222/3ybGV1uwDx/nz5+F0OhEX5zkYUVxcHI4ePVrlc+bNm4e5c+c2RXk+FRsbi3//+9/IyclBcXGxx1R29ULF5ZKSkjofX5AlCPZiwF6uU6P7SgZ1uQ6HatepA3ffAvWl0wzipc6LKF2GSuP6MCoLGgwbRNRYZZ8jMi4FB6cdguQod9ro0jycjkunktz7lp1icrimRl6BBAAajQZ6gwEGvR760qmsg27F5ZCQEAwZMqTxPws/1ewDR0PMmjULM2fOdC+bTCYkJSUpWFHDCIKAoUOH1us5ZZdg1jWg1L6PCVZzI5O+qHIFmAohRRYv9YtAWcgR1aWnV8paSCrMu1teqjgtU7qdHS2bFykozOORmpHSFgdXS4NUoVVBqtASUW57xX2rCA+uPimlocFL4UCtVpd++RtqDQfVLVec2Ofjkmb/k4iOjoZKpUJubq7H+tzcXMTHx1f5HJ1O1+zOkXmLKIruS+C8xel0wmq1Nii0eG67FGJsjQ0xNRJKQ05pKKk2tJRuc4eW0v4j5efLBZxLp5MqnDoqfwyP45UFJp5SqklJ+0FKl9B8uL+oy3+ZS579IUr3qdQ3otK+1QWAyv0syl5PkCXP0xNyA8eEqQO1Wl3rl359wkJQUBA0Gk3tL0wN1uwDh1arxRVXXIFNmzbhtttuA+D6K37Tpk2YNm2assW1ECqVyichpqwlpiykWCwWd8fWsqn8csXOsFXtU92yzWaDzW6H3WaFvcTW9ENXV9lptnLAqa0lp1I/mmr39QxWHiGJAahuyvUZKP9FXO1f7R5f1FI1AaD6fT1eo3w4cHeadKIpe06oVCpoNBrXpNVCq9FXuuKjbKrrcvn15eerCgsMB81Psw8cADBz5kyMHz8effr0Qd++ffH666/DbDZj4sSJSpdGDaRSqRAcHIzg4GBFXl+W5TqHlsYGnar2cYUfG+z2Etjsdjjs9qa9W2m5QFJ9aCkXcALhNFVZh8MKf+l7ftF7ngZoSmq1GhqNFhqtBlpNzV/qVX2B13W5rs/hkOxUXwEROP7617/i3LlzePrpp5GTk4PLL78c69evr9SRlKiuBEFwf/j6A1mW4XQ6fR50anyO3e66XNpmht1hb/gQ6s2E+wtWp4VGGwRtPf9a9/YXv8BWJ2rmAmIcjsZqzuNwECnF4XC4A0kg3D1VFEWPwZ34BU9UNy1mHA4iUoZarXZ33CMiqg1PwhEREZHPMXAQERGRzzFwEBERkc8xcBAREZHPMXAQERGRzzFwEBERkc8xcBAREZHPMXAQERGRzzFwEBERkc8xcBAREZHPcWhzwH0XTpPJpHAlREREzUvZd2dtt2Zj4ABQWFgIAEhKSlK4EiIiouapsLAQYWFh1W7n3WIBSJKErKwsGI1G3iGSyM+YTCYkJSXh1KlTvJszkR+SZRmFhYVITEyEKFbfU4OBg4j8Wl1vfU1E/o2dRomIiMjnGDiIiIjI5xg4iMiv6XQ6zJ49GzqdTulSiKgR2IeDiIiIfI4tHERERORzDBxERETkcwwcRERE5HMMHERERORzDBxERETkcwwcRERE5HMMHERERORzDBxERETkcwwcRERE5HMMHETUZObMmYPLL79c6TKISAEMHERUJzk5OXj44YeRkpICnU6HpKQk3HLLLdi0aZPSpXnFb7/9hjFjxiApKQl6vR5du3bFG2+8oXRZRAFDrXQBROT/Tpw4gWuuuQbh4eF46aWX0KNHD9jtdnz33XeYOnUqjh49qnSJjbZnzx7ExsZi2bJlSEpKwq5duzBlyhSoVCpMmzZN6fKImj22cBBRrR566CEIgoCff/4Zo0aNQqdOndCtWzfMnDkTP/74o3u/zMxM3HrrrQgJCUFoaCjuvvtu5ObmVnvcQYMGYfr06R7rbrvtNkyYMMG93K5dOzz33HMYN24cQkJC0LZtW6xZswbnzp1zv1bPnj3x66+/up+zZMkShIeH47vvvkPXrl0REhKC4cOHIzs7u9paJk2ahDfeeAMDBw5ESkoK7rnnHkycOBFff/11/X9gRFQJAwcR1SgvLw/r16/H1KlTERwcXGl7eHg4AECSJNx6663Iy8vD1q1bsWHDBvz555/461//2ugaXnvtNVxzzTXYt28fbrrpJtx7770YN24c7rnnHuzduxft27fHuHHjUP7m1xaLBS+//DI++eQTbNu2DZmZmXj88cfr9boFBQWIjIxsdP1ExFMqRFSL9PR0yLKMLl261Ljfpk2b8Pvvv+P48eNISkoCAHz88cfo1q0bfvnlF1x55ZUNruHGG2/EAw88AAB4+umnsXDhQlx55ZW46667AABPPvkk+vXrh9zcXMTHxwMA7HY7Fi1ahPbt2wMApk2bhmeeeabOr7lr1y6sWLEC69ata3DdRHQJWziIqEblWw1qcuTIESQlJbnDBgBcdtllCA8Px5EjRxpVQ8+ePd3zcXFxAIAePXpUWnf27Fn3OoPB4A4bAJCQkOCxvSYHDx7ErbfeitmzZ2PYsGGNqp2IXBg4iKhGHTt2hCAIPukYKopipUBjt9sr7afRaNzzgiBUu06SpCqfU7ZPXcLT4cOHMWTIEEyZMgX//ve/6/AuiKguGDiIqEaRkZG44YYb8Pbbb8NsNlfanp+fDwDo2rUrTp06hVOnTrm3HT58GPn5+bjsssuqPHZMTIxHR06n04mDBw969w3Uw6FDhzB48GCMHz8e//nPfxSrgygQMXAQUa3efvttOJ1O9O3bF1999RXS0tJw5MgRvPnmm+jXrx8AYOjQoejRowfGjh2LvXv34ueff8a4ceMwcOBA9OnTp8rjXnfddVi3bh3WrVuHo0eP4u9//7s7wDS1gwcPYvDgwRg2bBhmzpyJnJwc5OTk4Ny5c4rUQxRoGDiIqFYpKSnYu3cvBg8ejMceewzdu3fH9ddfj02bNmHhwoUAXKcsVq9ejYiICAwYMABDhw5FSkoKVqxYUe1xJ02ahPHjx7uDSUpKCgYPHtxUb8vDl19+iXPnzmHZsmVISEhwT43p7EpElwhyXXuEERERETUQWziIiIjI5xg4iIiIyOcYOIiIiMjnGDiIiIjI5xg4iIiIyOcYOIiIiMjnGDiIiIjI5xg4iIiIyOcYOIiIiMjnGDiIiIjI5xg4iIiIyOf+HzMn/4aalyIzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Save processed data for later use\n",
        "for i in range(selected_columns.shape[2]):  # Iterate over columns (third dimension)\n",
        "    col_data = selected_columns[:, :, i].flatten().cpu().numpy()  # Flatten, move to CPU, convert to numpy\n",
        "    np.save(f\"column_{i}.npy\", col_data)  # Save each column to a .npy file\n",
        "\n",
        "# Create separate plots for each column\n",
        "for i in range(selected_columns.shape[2]):\n",
        "    # Load column data\n",
        "    col_data = np.load(f\"column_{i}.npy\")\n",
        "\n",
        "    # Plot violin plot for the column\n",
        "    plt.figure(figsize=(6, 4))  # Create a new figure for each plot\n",
        "    sns.violinplot(data=col_data)\n",
        "    plt.title(f\"Violin Plot for Column {i}\")\n",
        "    plt.xlabel(f\"Column {i}\")\n",
        "    plt.ylabel(\"Values\")\n",
        "\n",
        "    # Save or show the plot\n",
        "    plt.savefig(f\"violin_plot_column_{i}.png\")  # Save plot to file\n",
        "    plt.show()  # Show the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9egpbQy6dEtA"
      },
      "outputs": [],
      "source": [
        "# # this cell for delete coolant temp from data\n",
        "# X_train = X_train[:, :, :-1]  # Slicing to exclude the last column\n",
        "# X_train1 = X_train1[:, :, :-1]  # Slicing to exclude the last column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "k2Lf8ZRETunZ",
        "outputId": "299bb0a8-9866-418d-ac38-d170479c0eee"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'torch.Size' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-0f4d6b0aeb46>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'torch.Size' object is not callable"
          ]
        }
      ],
      "source": [
        "X_train.shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crMYN8qDTDQ8",
        "outputId": "24983b3f-42c2-437f-ffa0-66fe54c1ae31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23254"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5t58s8DT6iE",
        "outputId": "d4d6fe90-a2bc-409a-a003-7e3aec7c781d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5.2632e-01, 5.2632e-01, 3.5313e-10, 1.2800e-03, 5.2632e-01],\n",
              "        [5.2632e-01, 5.2632e-01, 3.4688e-10, 1.2800e-03, 5.2632e-01],\n",
              "        [5.2632e-01, 5.2632e-01, 3.4062e-10, 1.2800e-03, 5.2632e-01],\n",
              "        ...,\n",
              "        [5.2632e-01, 5.2632e-01, 3.5000e-10, 1.6000e-03, 5.2631e-01],\n",
              "        [5.2632e-01, 5.2632e-01, 3.5313e-10, 1.6000e-03, 5.2631e-01],\n",
              "        [5.2632e-01, 5.2632e-01, 3.5313e-10, 1.6000e-03, 5.2631e-01]],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[55000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTt1HLi24WQo"
      },
      "source": [
        "# **Normalize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YSaA3VdOes7k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert the min and max values to tensors\n",
        "min_val_x = torch.tensor([-10,-10, 0,0, -10], dtype=torch.float32).to(DEVICE)\n",
        "max_val_x = torch.tensor([10,10,200, 5, 10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "#for without two acc\n",
        "# min_val_x = torch.tensor([-10, 0,0, -10], dtype=torch.float32).to(DEVICE)\n",
        "# max_val_x = torch.tensor([10, 200, 5, 10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "min_val_y = torch.tensor([0], dtype=torch.float32).to(DEVICE)\n",
        "max_val_y = torch.tensor([30000], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "# Custom normalization function for X\n",
        "def custom_normalize_X(data, min_vals, max_vals):\n",
        "    feature_count = 4\n",
        "    for i in range(feature_count):\n",
        "        data[:, :, i] = (data[:, :, i] - min_vals[i]) / (max_vals[i] - min_vals[i])\n",
        "    return data\n",
        "\n",
        "# Custom normalization function for y\n",
        "def custom_normalize_y(data, min_val, max_val):\n",
        "    return (data - min_val) / (max_val - min_val)\n",
        "\n",
        "# Normalize X_train and X_test\n",
        "X_train_normalized = custom_normalize_X(X_train, min_val_x, max_val_x)\n",
        "# X_test_normalized = custom_normalize_X(X_test, min_val_x, max_val_x)\n",
        "\n",
        "# Normalize y_train and y_test\n",
        "y_train_normalized = custom_normalize_y(y_train, min_val_y, max_val_y)\n",
        "# y_test_normalized = custom_normalize_y(y_test, min_val_y, max_val_y)\n",
        "\n",
        "\n",
        "# # Normalize X_train and X_test\n",
        "# X_train_normalized1 = custom_normalize_X(X_train1, min_val_x, max_val_x)\n",
        "# # X_test_normalized = custom_normalize_X(X_test, min_val_x, max_val_x)\n",
        "\n",
        "# # Normalize y_train and y_test\n",
        "# y_train_normalized1 = custom_normalize_y(y_train1, min_val_y, max_val_y)\n",
        "# y_test_normalized = custom_normalize_y(y_test, min_val_y, max_val_y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDXO7F157Fn4"
      },
      "source": [
        "# **Normla for rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VJmRMlC7Hbj"
      },
      "outputs": [],
      "source": [
        "min_val_x = torch.tensor([-10,-10, 0,0, -10], dtype=torch.float32).to(DEVICE)\n",
        "max_val_x = torch.tensor([10,10,200, 5, 10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "# min_val_y = torch.tensor([0], dtype=torch.float32).to(DEVICE)\n",
        "# max_val_y = torch.tensor([10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "#for without two acc\n",
        "# min_val_x = torch.tensor([-10, 0,0, -10], dtype=torch.float32).to(DEVICE)\n",
        "# max_val_x = torch.tensor([10, 200, 5, 10], dtype=torch.float32).to(DEVICE)\n",
        "# Custom normalization function for X\n",
        "def custom_normalize_X(data, min_vals, max_vals):\n",
        "    feature_count = 5\n",
        "    for i in range(feature_count):\n",
        "        data[:, :, i] = (data[:, :, i] - min_vals[i]) / (max_vals[i] - min_vals[i])\n",
        "    return data\n",
        "\n",
        "# def custom_normalize_y(data, min_val, max_val):\n",
        "#     return (data - min_val) / (max_val - min_val)\n",
        "\n",
        "\n",
        "X_train_normalized = custom_normalize_X(X_train, min_val_x, max_val_x)\n",
        "\n",
        "y_train_normalized = y_train\n",
        "# y_train_normalized = custom_normalize_y(y_train, min_val_y, max_val_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalize rate new 9 acc"
      ],
      "metadata": {
        "id": "iKJkinnW482N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_val_x = torch.tensor([-10,-10,-10,-10,-10,-10,-10,-10,-10, 0,   0 , -10], dtype=torch.float32).to(DEVICE)\n",
        "max_val_x = torch.tensor([ 10, 10, 10, 10, 10, 10, 10, 10, 10, 200, 5 , 10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "# min_val_y = torch.tensor([0], dtype=torch.float32).to(DEVICE)\n",
        "# max_val_y = torch.tensor([10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "#for without two acc\n",
        "# min_val_x = torch.tensor([-10, 0,0, -10], dtype=torch.float32).to(DEVICE)\n",
        "# max_val_x = torch.tensor([10, 200, 5, 10], dtype=torch.float32).to(DEVICE)\n",
        "# Custom normalization function for X\n",
        "def custom_normalize_X(data, min_vals, max_vals):\n",
        "    feature_count = 12\n",
        "    for i in range(feature_count):\n",
        "        data[:, :, i] = (data[:, :, i] - min_vals[i]) / (max_vals[i] - min_vals[i])\n",
        "    return data\n",
        "\n",
        "# def custom_normalize_y(data, min_val, max_val):\n",
        "#     return (data - min_val) / (max_val - min_val)\n",
        "\n",
        "\n",
        "X_train_normalized = custom_normalize_X(X_train, min_val_x, max_val_x)\n",
        "\n",
        "y_train_normalized = y_train\n",
        "# y_train_normalized = custom_normalize_y(y_train, min_val_y, max_val_y)"
      ],
      "metadata": {
        "id": "3THdH-qP48r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_val_x = torch.tensor([-10,-10,-10, 0,   0 , -10], dtype=torch.float32).to(DEVICE)\n",
        "max_val_x = torch.tensor([ 10, 10, 10, 200, 5 , 10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "# min_val_y = torch.tensor([0], dtype=torch.float32).to(DEVICE)\n",
        "# max_val_y = torch.tensor([10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "#for without two acc\n",
        "# min_val_x = torch.tensor([-10, 0,0, -10], dtype=torch.float32).to(DEVICE)\n",
        "# max_val_x = torch.tensor([10, 200, 5, 10], dtype=torch.float32).to(DEVICE)\n",
        "# Custom normalization function for X\n",
        "def custom_normalize_X(data, min_vals, max_vals):\n",
        "    feature_count = 6\n",
        "    for i in range(feature_count):\n",
        "        data[:, :, i] = (data[:, :, i] - min_vals[i]) / (max_vals[i] - min_vals[i])\n",
        "    return data\n",
        "\n",
        "# def custom_normalize_y(data, min_val, max_val):\n",
        "#     return (data - min_val) / (max_val - min_val)\n",
        "\n",
        "\n",
        "X_train_normalized = custom_normalize_X(X_train, min_val_x, max_val_x)\n",
        "\n",
        "y_train_normalized = y_train\n",
        "# y_train_normalized = custom_normalize_y(y_train, min_val_y, max_val_y)"
      ],
      "metadata": {
        "id": "RGk7YTwTFYsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the minimum and maximum across dimensions (0, 1)\n",
        "min_x = torch.min(X_train_normalized, dim=0)[0]  # Min across the first dimension\n",
        "min_x = torch.min(min_x, dim=0)[0].to(DEVICE)  # Min across the second dimension\n",
        "\n",
        "max_x = torch.max(X_train_normalized, dim=0)[0]  # Max across the first dimension\n",
        "max_x = torch.max(max_x, dim=0)[0].to(DEVICE)  # Max across the second dimension\n",
        "\n",
        "print(\"Min values:\", min_x)\n",
        "print(\"Max values:\", max_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFPJpA_HW7fU",
        "outputId": "89ae1f1a-42fe-4c59-f34c-c6cabfe75128"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min values: tensor([  -5.5500,   -5.5500,    0.0000,    0.0000, -224.3478],\n",
            "       device='cuda:0')\n",
            "Max values: tensor([  6.5000,   6.5000,   0.9200,   1.0000, 240.0000], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRdMwCh7UjBa",
        "outputId": "f4927025-b8a5-4c3a-d365-6c21b0fa335b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1728, 600, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train_normalized.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQUxG9UeUleC",
        "outputId": "01f77d7a-397a-48fe-c048-b69748583d51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([55850, 600, 1])"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_normalized1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGvLDIFEo3yV"
      },
      "source": [
        "# **Standard**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_j7q5t85DUH"
      },
      "outputs": [],
      "source": [
        "# Compute the mean and standard deviation for X and y from the training set\n",
        "mean_x = torch.mean(X_train, dim=(0, 1)).to(DEVICE)\n",
        "std_x = torch.std(X_train, dim=(0, 1)).to(DEVICE)\n",
        "\n",
        "mean_y = torch.mean(y_train).to(DEVICE)\n",
        "std_y = torch.std(y_train).to(DEVICE)\n",
        "\n",
        "# Custom standardization function for X\n",
        "def custom_standardize_X(data, mean_vals, std_vals):\n",
        "    for i in range(data.shape[-1]):\n",
        "        data[:, :, i] = (data[:, :, i] - mean_vals[i]) / std_vals[i]\n",
        "    return data\n",
        "\n",
        "# Custom standardization function for y\n",
        "def custom_standardize_y(data, mean_val, std_val):\n",
        "    return (data - mean_val) / std_val\n",
        "\n",
        "# Standardize X_train and y_train\n",
        "X_train_normalized = custom_standardize_X(X_train, mean_x, std_x)\n",
        "y_train_normalized = custom_standardize_y(y_train, mean_y, std_y)\n",
        "\n",
        "# # Standardize X_test and y_test using the same mean and std as training data\n",
        "# X_test_standardized = custom_standardize_X(X_test, mean_x, std_x)\n",
        "# y_test_standardized = custom_standardize_y(y_test, mean_y, std_y)\n",
        "\n",
        "\n",
        "X_train_normalized1 = custom_standardize_X(X_train1, mean_x, std_x)\n",
        "y_train_normalized1 = custom_standardize_y(y_train1, mean_y, std_y)\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "# Convert tensors to lists to make them serializable\n",
        "mean_x_list = mean_x.cpu().tolist()\n",
        "std_x_list = std_x.cpu().tolist()\n",
        "mean_y_list = mean_y.cpu().tolist()\n",
        "std_y_list = std_y.cpu().tolist()\n",
        "\n",
        "# Save the mean and std values in a JSON file\n",
        "normalization_params = {\n",
        "    'mean_x': mean_x_list,\n",
        "    'std_x': std_x_list,\n",
        "    'mean_y': mean_y_list,\n",
        "    'std_y': std_y_list\n",
        "}\n",
        "\n",
        "# Write the normalization parameters to a JSON file\n",
        "with open('normalization_params.json', 'w') as f:\n",
        "    json.dump(normalization_params, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ1tv5iCo54o"
      },
      "source": [
        "# **model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwYKbOq_Zcr7"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class FuelConsumptionModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(FuelConsumptionModel, self).__init__()\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size, 32, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Layer Normalization after each LSTM\n",
        "        self.layer_norm1 = nn.LayerNorm(64)\n",
        "        self.layer_norm2 = nn.LayerNorm(64)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        # Dense output layer\n",
        "        self.dense = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM 1 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.layer_norm1(x)  # Apply layer normalization after LSTM1\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # LSTM 2 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.layer_norm2(x)  # Apply layer normalization after LSTM2\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Dense layer for final output\n",
        "        x = self.dense(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention model**"
      ],
      "metadata": {
        "id": "FprUMuyUnSJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FuelConsumptionModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(FuelConsumptionModel, self).__init__()\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size, 32, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Layer Normalization after each LSTM\n",
        "        self.layer_norm1 = nn.LayerNorm(64)\n",
        "        self.layer_norm2 = nn.LayerNorm(64)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Linear(64, 64)  # Maps LSTM outputs to attention scores\n",
        "        self.softmax = nn.Softmax(dim=1)  # Applies softmax over the sequence dimension\n",
        "\n",
        "        # Dense output layer for per-timestep prediction\n",
        "        self.dense = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM 1 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm1(x)\n",
        "        # print(f\"Shape after LSTM1: {x.shape}\")\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # LSTM 2 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm2(x)\n",
        "        # print(f\"Shape after LSTM2: {x.shape}\")\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Attention mechanism for each timestep\n",
        "        attention_scores = self.attention(x)  # Shape: (batch_size, seq_len, 64)\n",
        "        # print(f\"Shape after attention scores: {attention_scores.shape}\")\n",
        "        attention_weights = self.softmax(attention_scores)  # Shape: (batch_size, seq_len, 64)\n",
        "        # print(f\"Shape after attention weights: {attention_weights.shape}\")\n",
        "        x = attention_weights * x  # Apply attention weights (element-wise)\n",
        "\n",
        "        # Dense layer for per-timestep prediction\n",
        "        output = self.dense(x)  # Shape: (batch_size, seq_len, 1)\n",
        "        # print(f\"Final output shape: {output.shape}\")\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "fQTkMZDOnRf4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **multihead att**"
      ],
      "metadata": {
        "id": "3AQolr92D7NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FuelConsumptionModel(nn.Module):\n",
        "    def __init__(self, input_size, num_heads=4):\n",
        "        super(FuelConsumptionModel, self).__init__()\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size, 32, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Layer Normalization after each LSTM\n",
        "        self.layer_norm1 = nn.LayerNorm(64)\n",
        "        self.layer_norm2 = nn.LayerNorm(64)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        # Multi-Head Attention\n",
        "        self.multihead_attention = nn.MultiheadAttention(embed_dim=64, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        # Dense output layer for per-timestep prediction\n",
        "        self.dense = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM 1 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # LSTM 2 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Multi-Head Attention\n",
        "        # The input to multihead_attention is expected to be of shape (batch_size, seq_len, embedding_dim),\n",
        "        # while it needs (seq_len, batch_size, embedding_dim), so we permute it accordingly.\n",
        "        attn_output, _ = self.multihead_attention(x, x, x)\n",
        "\n",
        "        # Apply the output of attention to the dense layer\n",
        "        output = self.dense(attn_output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "Jwg_4IWLD9y8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **self att**"
      ],
      "metadata": {
        "id": "rLfyu0YQKBHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FuelConsumptionModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(FuelConsumptionModel, self).__init__()\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size, 32, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Layer Normalization after each LSTM\n",
        "        self.layer_norm1 = nn.LayerNorm(64)\n",
        "        self.layer_norm2 = nn.LayerNorm(64)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        # Self-attention mechanism\n",
        "        self.query_layer = nn.Linear(64, 64)  # Query layer\n",
        "        self.key_layer = nn.Linear(64, 64)    # Key layer\n",
        "        self.value_layer = nn.Linear(64, 64)  # Value layer\n",
        "\n",
        "        # Dense output layer for per-timestep prediction\n",
        "        self.dense = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM 1 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # LSTM 2 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Self-Attention mechanism\n",
        "        query = self.query_layer(x)  # Shape: (batch_size, seq_len, 64)\n",
        "        key = self.key_layer(x)      # Shape: (batch_size, seq_len, 64)\n",
        "        value = self.value_layer(x)  # Shape: (batch_size, seq_len, 64)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        attention_scores = torch.bmm(query, key.transpose(1, 2))  # Shape: (batch_size, seq_len, seq_len)\n",
        "        attention_scores = attention_scores / (64 ** 0.5)  # Scaling the scores by sqrt(d_k)\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)  # Softmax over the sequence length\n",
        "        attention_output = torch.bmm(attention_weights, value)  # Shape: (batch_size, seq_len, 64)\n",
        "\n",
        "        # Apply the output of attention to the dense layer\n",
        "        output = self.dense(attention_output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "Tg01xBAiKAwh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **split train and val**"
      ],
      "metadata": {
        "id": "VSyqHzsgwXqx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrURTgcFgyYL",
        "outputId": "a9162c94-777a-4498-bb54-6b93686024d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_normalized shape: torch.Size([23254, 600, 5])\n",
            "y_train_normalized shape: torch.Size([23254, 600, 1])\n",
            "Train size: 18603, Validation size: 4651\n"
          ]
        }
      ],
      "source": [
        "# Check if X_train_normalized and y_train_normalized have the same number of samples\n",
        "print(f\"X_train_normalized shape: {X_train_normalized.shape}\")\n",
        "print(f\"y_train_normalized shape: {y_train_normalized.shape}\")\n",
        "\n",
        "# Ensure they have the same length in the first dimension\n",
        "if len(X_train_normalized) != len(y_train_normalized):\n",
        "    raise ValueError(f\"Mismatch in number of samples: {len(X_train_normalized)} in X vs {len(y_train_normalized)} in y\")\n",
        "\n",
        "# Calculate train size\n",
        "train_size = int(0.8 * len(X_train_normalized))\n",
        "\n",
        "# Split the data while preserving the order\n",
        "X_train_split = X_train_normalized[:train_size]\n",
        "y_train_split = y_train_normalized[:train_size]\n",
        "\n",
        "X_val_split = X_train_normalized[train_size:]\n",
        "y_val_split = y_train_normalized[train_size:]\n",
        "\n",
        "\n",
        "# X_train_split = X_train_normalized\n",
        "# y_train_split = y_train_normalized\n",
        "\n",
        "# X_val_split = X_train_normalized\n",
        "# y_val_split = y_train_normalized\n",
        "\n",
        "print(f\"Train size: {train_size}, Validation size: {len(X_val_split)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6TiBUVyUx_z",
        "outputId": "765c40ed-2ceb-48a2-f837-b630e9dbc081"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18603, 600, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train_split.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keE2KWC8U06S",
        "outputId": "0fdf8c24-b889-4646-8ac8-03b0fe2cb4f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18603, 600, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_train_split.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "csLAJyD43kt8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9D0YvUOqw2D"
      },
      "source": [
        "# **train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "_z0wpMf9gK-h",
        "outputId": "cf0a595c-332e-4460-c04e-06c6c9723a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([64, 600, 5])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-fcf1aefbc031>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output shape: {outputs.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR  # Importing StepLR for learning rate decay\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# Assuming `FuelConsumptionModel`, `X_train_normalized`, `train_loader`, `val_loader`, `DEVICE`, and `EPOCHS` are defined\n",
        "\n",
        "# Choose a single loss function to use for all experiments\n",
        "criterion = nn.L1Loss()  # You can change this to your preferred loss function\n",
        "\n",
        "EPOCHS = 250\n",
        "# Define weight decay values and initial learning rates for decay schedules\n",
        "weight_decay_values = 1e-5\n",
        "initial_learning_rates = [1e-4]  # Two starting learning rates\n",
        "\n",
        "# Initialize variables to track the best parameters\n",
        "best_weight_decay = None\n",
        "best_initial_lr = None\n",
        "best_model_weights = None\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "ini_batches = [64]\n",
        "# Loop over all combinations of initial learning rates and weight decay values\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "# Create DataLoader for training and validation sets\n",
        "train_loader = DataLoader(TensorDataset(X_train_split, y_train_split), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_split, y_val_split), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "for init_lr in initial_learning_rates:\n",
        "    # Initialize model, criterion, and optimizer for each combination\n",
        "    model = FuelConsumptionModel(input_size=X_train_split.shape[-1]).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=init_lr, weight_decay=weight_decay_values)\n",
        "    # scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "    scheduler = StepLR(optimizer, step_size=50, gamma=0.5)  # Decay LR by 0.5 every 50 epochs\n",
        "\n",
        "    # Early stopping parameters\n",
        "    patience = 12  # Number of epochs to wait before stopping if no improvement\n",
        "    best_loss = float('inf')  # Initialize best loss to infinity\n",
        "    epochs_without_improvement = 0  # Counter for epochs without improvement\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        model.train()  # Ensure model is in training mode\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, targets in train_loader:\n",
        "            print(f\"Input shape: {inputs.shape}\")\n",
        "\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            print(f\"Output shape: {outputs.shape}\")\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_training_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()  # Switch to evaluation mode\n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:  # Assume you have a validation DataLoader `val_loader`\n",
        "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "                # print(inputs.shape)\n",
        "                # print(targets.shape)\n",
        "                outputs = model(inputs)\n",
        "                # print(outputs.shape)\n",
        "                val_loss = criterion(outputs, targets)\n",
        "                val_running_loss += val_loss.item()\n",
        "\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.6f} ------{current_lr}\")\n",
        "\n",
        "        # print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.4f}    Init LR: {init_lr:.0e}  WD: {wd:.0e}\")\n",
        "\n",
        "        # Adjust the learning rate\n",
        "        # scheduler.step(avg_val_loss)\n",
        "        scheduler.step()\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                # break\n",
        "\n",
        "        # Save the model for the current combination\n",
        "        model_filename = f'best_fuel_consumption_model.pth'\n",
        "        torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "\n",
        "print(f\"Saved model: {model_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o2xWWKvmT67"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train model with attention**"
      ],
      "metadata": {
        "id": "uVsTxiOtnxip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR  # Importing StepLR for learning rate decay\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# Assuming `FuelConsumptionModel`, `X_train_normalized`, `train_loader`, `val_loader`, `DEVICE`, and `EPOCHS` are defined\n",
        "\n",
        "# Choose a single loss function to use for all experiments\n",
        "criterion = nn.L1Loss()  # You can change this to your preferred loss function\n",
        "\n",
        "EPOCHS = 250\n",
        "# Define weight decay values and initial learning rates for decay schedules\n",
        "weight_decay_values = 1e-5\n",
        "initial_learning_rates = [1e-4]  # Two starting learning rates\n",
        "\n",
        "# Initialize variables to track the best parameters\n",
        "best_weight_decay = None\n",
        "best_initial_lr = None\n",
        "best_model_weights = None\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "ini_batches = [64]\n",
        "# Loop over all combinations of initial learning rates and weight decay values\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "# Create DataLoader for training and validation sets\n",
        "train_loader = DataLoader(TensorDataset(X_train_split, y_train_split), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_split, y_val_split), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "for init_lr in initial_learning_rates:\n",
        "    # Initialize model, criterion, and optimizer for each combination\n",
        "    model = FuelConsumptionModel(input_size=X_train_split.shape[-1]).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=init_lr, weight_decay=weight_decay_values)\n",
        "    # scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "    scheduler = StepLR(optimizer, step_size=50, gamma=0.5)  # Decay LR by 0.5 every 50 epochs\n",
        "\n",
        "    # Early stopping parameters\n",
        "    patience = 12  # Number of epochs to wait before stopping if no improvement\n",
        "    best_loss = float('inf')  # Initialize best loss to infinity\n",
        "    epochs_without_improvement = 0  # Counter for epochs without improvement\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        model.train()  # Ensure model is in training mode\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # print(f\"inputs: {inputs.shape}, targets: {targets.shape}, outputs: {outputs.shape}\")\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_training_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()  # Switch to evaluation mode\n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:  # Assume you have a validation DataLoader `val_loader`\n",
        "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "                # print(inputs.shape)\n",
        "                # print(targets.shape)\n",
        "                outputs  = model(inputs)\n",
        "                # print(outputs.shape)\n",
        "                val_loss = criterion(outputs, targets)\n",
        "                val_running_loss += val_loss.item()\n",
        "\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.6f} ------{current_lr}\")\n",
        "\n",
        "        # print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.4f}    Init LR: {init_lr:.0e}  WD: {wd:.0e}\")\n",
        "\n",
        "        # Adjust the learning rate\n",
        "        # scheduler.step(avg_val_loss)\n",
        "        scheduler.step()\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Save the model for the current combination\n",
        "        model_filename = f'best_consatt.pth'\n",
        "        torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "\n",
        "print(f\"Saved model: {model_filename}\")"
      ],
      "metadata": {
        "id": "0DtVE70KnxWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e989712-1c32-4e15-ba06-7560c8959ab5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/250] ---- Training Loss: 0.0396 ---- Validation Loss: 0.032604 ------0.0001\n",
            "Epoch [2/250] ---- Training Loss: 0.0275 ---- Validation Loss: 0.039741 ------0.0001\n",
            "Epoch [3/250] ---- Training Loss: 0.0269 ---- Validation Loss: 0.031981 ------0.0001\n",
            "Epoch [4/250] ---- Training Loss: 0.0265 ---- Validation Loss: 0.033965 ------0.0001\n",
            "Epoch [5/250] ---- Training Loss: 0.0260 ---- Validation Loss: 0.031419 ------0.0001\n",
            "Epoch [6/250] ---- Training Loss: 0.0258 ---- Validation Loss: 0.030419 ------0.0001\n",
            "Epoch [7/250] ---- Training Loss: 0.0255 ---- Validation Loss: 0.030110 ------0.0001\n",
            "Epoch [8/250] ---- Training Loss: 0.0252 ---- Validation Loss: 0.028409 ------0.0001\n",
            "Epoch [9/250] ---- Training Loss: 0.0249 ---- Validation Loss: 0.029858 ------0.0001\n",
            "Epoch [10/250] ---- Training Loss: 0.0246 ---- Validation Loss: 0.027623 ------0.0001\n",
            "Epoch [11/250] ---- Training Loss: 0.0243 ---- Validation Loss: 0.027039 ------0.0001\n",
            "Epoch [12/250] ---- Training Loss: 0.0240 ---- Validation Loss: 0.028301 ------0.0001\n",
            "Epoch [13/250] ---- Training Loss: 0.0236 ---- Validation Loss: 0.028092 ------0.0001\n",
            "Epoch [14/250] ---- Training Loss: 0.0234 ---- Validation Loss: 0.028008 ------0.0001\n",
            "Epoch [15/250] ---- Training Loss: 0.0230 ---- Validation Loss: 0.026875 ------0.0001\n",
            "Epoch [16/250] ---- Training Loss: 0.0225 ---- Validation Loss: 0.026790 ------0.0001\n",
            "Epoch [17/250] ---- Training Loss: 0.0220 ---- Validation Loss: 0.026493 ------0.0001\n",
            "Epoch [18/250] ---- Training Loss: 0.0214 ---- Validation Loss: 0.026464 ------0.0001\n",
            "Epoch [19/250] ---- Training Loss: 0.0209 ---- Validation Loss: 0.023923 ------0.0001\n",
            "Epoch [20/250] ---- Training Loss: 0.0203 ---- Validation Loss: 0.022543 ------0.0001\n",
            "Epoch [21/250] ---- Training Loss: 0.0196 ---- Validation Loss: 0.023225 ------0.0001\n",
            "Epoch [22/250] ---- Training Loss: 0.0190 ---- Validation Loss: 0.021621 ------0.0001\n",
            "Epoch [23/250] ---- Training Loss: 0.0184 ---- Validation Loss: 0.022071 ------0.0001\n",
            "Epoch [24/250] ---- Training Loss: 0.0179 ---- Validation Loss: 0.020833 ------0.0001\n",
            "Epoch [25/250] ---- Training Loss: 0.0175 ---- Validation Loss: 0.020290 ------0.0001\n",
            "Epoch [26/250] ---- Training Loss: 0.0171 ---- Validation Loss: 0.019659 ------0.0001\n",
            "Epoch [27/250] ---- Training Loss: 0.0167 ---- Validation Loss: 0.018171 ------0.0001\n",
            "Epoch [28/250] ---- Training Loss: 0.0163 ---- Validation Loss: 0.018065 ------0.0001\n",
            "Epoch [29/250] ---- Training Loss: 0.0161 ---- Validation Loss: 0.019031 ------0.0001\n",
            "Epoch [30/250] ---- Training Loss: 0.0157 ---- Validation Loss: 0.016858 ------0.0001\n",
            "Epoch [31/250] ---- Training Loss: 0.0155 ---- Validation Loss: 0.017928 ------0.0001\n",
            "Epoch [32/250] ---- Training Loss: 0.0152 ---- Validation Loss: 0.017400 ------0.0001\n",
            "Epoch [33/250] ---- Training Loss: 0.0150 ---- Validation Loss: 0.016610 ------0.0001\n",
            "Epoch [34/250] ---- Training Loss: 0.0148 ---- Validation Loss: 0.016780 ------0.0001\n",
            "Epoch [35/250] ---- Training Loss: 0.0146 ---- Validation Loss: 0.016183 ------0.0001\n",
            "Epoch [36/250] ---- Training Loss: 0.0144 ---- Validation Loss: 0.015895 ------0.0001\n",
            "Epoch [37/250] ---- Training Loss: 0.0143 ---- Validation Loss: 0.014835 ------0.0001\n",
            "Epoch [38/250] ---- Training Loss: 0.0142 ---- Validation Loss: 0.015311 ------0.0001\n",
            "Epoch [39/250] ---- Training Loss: 0.0140 ---- Validation Loss: 0.014507 ------0.0001\n",
            "Epoch [40/250] ---- Training Loss: 0.0140 ---- Validation Loss: 0.014305 ------0.0001\n",
            "Epoch [41/250] ---- Training Loss: 0.0138 ---- Validation Loss: 0.013982 ------0.0001\n",
            "Epoch [42/250] ---- Training Loss: 0.0138 ---- Validation Loss: 0.014694 ------0.0001\n",
            "Epoch [43/250] ---- Training Loss: 0.0136 ---- Validation Loss: 0.013628 ------0.0001\n",
            "Epoch [44/250] ---- Training Loss: 0.0136 ---- Validation Loss: 0.013702 ------0.0001\n",
            "Epoch [45/250] ---- Training Loss: 0.0135 ---- Validation Loss: 0.013258 ------0.0001\n",
            "Epoch [46/250] ---- Training Loss: 0.0134 ---- Validation Loss: 0.013579 ------0.0001\n",
            "Epoch [47/250] ---- Training Loss: 0.0133 ---- Validation Loss: 0.013986 ------0.0001\n",
            "Epoch [48/250] ---- Training Loss: 0.0132 ---- Validation Loss: 0.013556 ------0.0001\n",
            "Epoch [49/250] ---- Training Loss: 0.0132 ---- Validation Loss: 0.013298 ------0.0001\n",
            "Epoch [50/250] ---- Training Loss: 0.0131 ---- Validation Loss: 0.013066 ------0.0001\n",
            "Epoch [51/250] ---- Training Loss: 0.0130 ---- Validation Loss: 0.013102 ------5e-05\n",
            "Epoch [52/250] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012974 ------5e-05\n",
            "Epoch [53/250] ---- Training Loss: 0.0129 ---- Validation Loss: 0.013023 ------5e-05\n",
            "Epoch [54/250] ---- Training Loss: 0.0129 ---- Validation Loss: 0.013210 ------5e-05\n",
            "Epoch [55/250] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012921 ------5e-05\n",
            "Epoch [56/250] ---- Training Loss: 0.0129 ---- Validation Loss: 0.013069 ------5e-05\n",
            "Epoch [57/250] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012791 ------5e-05\n",
            "Epoch [58/250] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012988 ------5e-05\n",
            "Epoch [59/250] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012765 ------5e-05\n",
            "Epoch [60/250] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012686 ------5e-05\n",
            "Epoch [61/250] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012965 ------5e-05\n",
            "Epoch [62/250] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012964 ------5e-05\n",
            "Epoch [63/250] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012598 ------5e-05\n",
            "Epoch [64/250] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012739 ------5e-05\n",
            "Epoch [65/250] ---- Training Loss: 0.0126 ---- Validation Loss: 0.013141 ------5e-05\n",
            "Epoch [66/250] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012880 ------5e-05\n",
            "Epoch [67/250] ---- Training Loss: 0.0125 ---- Validation Loss: 0.012587 ------5e-05\n",
            "Epoch [68/250] ---- Training Loss: 0.0125 ---- Validation Loss: 0.012725 ------5e-05\n",
            "Epoch [69/250] ---- Training Loss: 0.0125 ---- Validation Loss: 0.012593 ------5e-05\n",
            "Epoch [70/250] ---- Training Loss: 0.0125 ---- Validation Loss: 0.012808 ------5e-05\n",
            "Epoch [71/250] ---- Training Loss: 0.0124 ---- Validation Loss: 0.012619 ------5e-05\n",
            "Epoch [72/250] ---- Training Loss: 0.0124 ---- Validation Loss: 0.012509 ------5e-05\n",
            "Epoch [73/250] ---- Training Loss: 0.0124 ---- Validation Loss: 0.012436 ------5e-05\n",
            "Epoch [74/250] ---- Training Loss: 0.0124 ---- Validation Loss: 0.012732 ------5e-05\n",
            "Epoch [75/250] ---- Training Loss: 0.0124 ---- Validation Loss: 0.012401 ------5e-05\n",
            "Epoch [76/250] ---- Training Loss: 0.0123 ---- Validation Loss: 0.012463 ------5e-05\n",
            "Epoch [77/250] ---- Training Loss: 0.0123 ---- Validation Loss: 0.012514 ------5e-05\n",
            "Epoch [78/250] ---- Training Loss: 0.0123 ---- Validation Loss: 0.012683 ------5e-05\n",
            "Epoch [79/250] ---- Training Loss: 0.0123 ---- Validation Loss: 0.012335 ------5e-05\n",
            "Epoch [80/250] ---- Training Loss: 0.0123 ---- Validation Loss: 0.012504 ------5e-05\n",
            "Epoch [81/250] ---- Training Loss: 0.0122 ---- Validation Loss: 0.012290 ------5e-05\n",
            "Epoch [82/250] ---- Training Loss: 0.0122 ---- Validation Loss: 0.012182 ------5e-05\n",
            "Epoch [83/250] ---- Training Loss: 0.0122 ---- Validation Loss: 0.012407 ------5e-05\n",
            "Epoch [84/250] ---- Training Loss: 0.0122 ---- Validation Loss: 0.012341 ------5e-05\n",
            "Epoch [85/250] ---- Training Loss: 0.0122 ---- Validation Loss: 0.012173 ------5e-05\n",
            "Epoch [86/250] ---- Training Loss: 0.0122 ---- Validation Loss: 0.012379 ------5e-05\n",
            "Epoch [87/250] ---- Training Loss: 0.0121 ---- Validation Loss: 0.012212 ------5e-05\n",
            "Epoch [88/250] ---- Training Loss: 0.0121 ---- Validation Loss: 0.012303 ------5e-05\n",
            "Epoch [89/250] ---- Training Loss: 0.0121 ---- Validation Loss: 0.012289 ------5e-05\n",
            "Epoch [90/250] ---- Training Loss: 0.0121 ---- Validation Loss: 0.012126 ------5e-05\n",
            "Epoch [91/250] ---- Training Loss: 0.0121 ---- Validation Loss: 0.012105 ------5e-05\n",
            "Epoch [92/250] ---- Training Loss: 0.0121 ---- Validation Loss: 0.012061 ------5e-05\n",
            "Epoch [93/250] ---- Training Loss: 0.0121 ---- Validation Loss: 0.012421 ------5e-05\n",
            "Epoch [94/250] ---- Training Loss: 0.0120 ---- Validation Loss: 0.012059 ------5e-05\n",
            "Epoch [95/250] ---- Training Loss: 0.0120 ---- Validation Loss: 0.012089 ------5e-05\n",
            "Epoch [96/250] ---- Training Loss: 0.0120 ---- Validation Loss: 0.012053 ------5e-05\n",
            "Epoch [97/250] ---- Training Loss: 0.0120 ---- Validation Loss: 0.012145 ------5e-05\n",
            "Epoch [98/250] ---- Training Loss: 0.0120 ---- Validation Loss: 0.012353 ------5e-05\n",
            "Epoch [99/250] ---- Training Loss: 0.0120 ---- Validation Loss: 0.012231 ------5e-05\n",
            "Epoch [100/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.012091 ------5e-05\n",
            "Epoch [101/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011947 ------2.5e-05\n",
            "Epoch [102/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.012126 ------2.5e-05\n",
            "Epoch [103/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011953 ------2.5e-05\n",
            "Epoch [104/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.012044 ------2.5e-05\n",
            "Epoch [105/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.012122 ------2.5e-05\n",
            "Epoch [106/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011994 ------2.5e-05\n",
            "Epoch [107/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.012016 ------2.5e-05\n",
            "Epoch [108/250] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011984 ------2.5e-05\n",
            "Epoch [109/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.012127 ------2.5e-05\n",
            "Epoch [110/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.012090 ------2.5e-05\n",
            "Epoch [111/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011882 ------2.5e-05\n",
            "Epoch [112/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.012105 ------2.5e-05\n",
            "Epoch [113/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011903 ------2.5e-05\n",
            "Epoch [114/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011967 ------2.5e-05\n",
            "Epoch [115/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011899 ------2.5e-05\n",
            "Epoch [116/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011847 ------2.5e-05\n",
            "Epoch [117/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.012050 ------2.5e-05\n",
            "Epoch [118/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011912 ------2.5e-05\n",
            "Epoch [119/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.012059 ------2.5e-05\n",
            "Epoch [120/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.012007 ------2.5e-05\n",
            "Epoch [121/250] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011966 ------2.5e-05\n",
            "Epoch [122/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011870 ------2.5e-05\n",
            "Epoch [123/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011953 ------2.5e-05\n",
            "Epoch [124/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011764 ------2.5e-05\n",
            "Epoch [125/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011848 ------2.5e-05\n",
            "Epoch [126/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011978 ------2.5e-05\n",
            "Epoch [127/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011815 ------2.5e-05\n",
            "Epoch [128/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011857 ------2.5e-05\n",
            "Epoch [129/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011880 ------2.5e-05\n",
            "Epoch [130/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011881 ------2.5e-05\n",
            "Epoch [131/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011839 ------2.5e-05\n",
            "Epoch [132/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011786 ------2.5e-05\n",
            "Epoch [133/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011897 ------2.5e-05\n",
            "Epoch [134/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011829 ------2.5e-05\n",
            "Epoch [135/250] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011704 ------2.5e-05\n",
            "Epoch [136/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011784 ------2.5e-05\n",
            "Epoch [137/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011754 ------2.5e-05\n",
            "Epoch [138/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011884 ------2.5e-05\n",
            "Epoch [139/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011763 ------2.5e-05\n",
            "Epoch [140/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011692 ------2.5e-05\n",
            "Epoch [141/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011810 ------2.5e-05\n",
            "Epoch [142/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011780 ------2.5e-05\n",
            "Epoch [143/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011681 ------2.5e-05\n",
            "Epoch [144/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011955 ------2.5e-05\n",
            "Epoch [145/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011574 ------2.5e-05\n",
            "Epoch [146/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011580 ------2.5e-05\n",
            "Epoch [147/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011755 ------2.5e-05\n",
            "Epoch [148/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011885 ------2.5e-05\n",
            "Epoch [149/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011700 ------2.5e-05\n",
            "Epoch [150/250] ---- Training Loss: 0.0116 ---- Validation Loss: 0.011796 ------2.5e-05\n",
            "Epoch [151/250] ---- Training Loss: 0.0115 ---- Validation Loss: 0.011700 ------1.25e-05\n",
            "Epoch [152/250] ---- Training Loss: 0.0115 ---- Validation Loss: 0.011628 ------1.25e-05\n",
            "Epoch [153/250] ---- Training Loss: 0.0115 ---- Validation Loss: 0.011736 ------1.25e-05\n",
            "Epoch [154/250] ---- Training Loss: 0.0115 ---- Validation Loss: 0.011720 ------1.25e-05\n",
            "Epoch [155/250] ---- Training Loss: 0.0115 ---- Validation Loss: 0.011758 ------1.25e-05\n",
            "Epoch [156/250] ---- Training Loss: 0.0115 ---- Validation Loss: 0.011633 ------1.25e-05\n",
            "Epoch [157/250] ---- Training Loss: 0.0115 ---- Validation Loss: 0.011678 ------1.25e-05\n",
            "Early stopping at epoch 157\n",
            "Saved model: best_consatt.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1P_IJRN1eql"
      },
      "source": [
        "# **fine tuning model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nSQ1RKLHOt_"
      },
      "outputs": [],
      "source": [
        "data = np.load('/content/gdrive/MyDrive/fine_tune600.npz')\n",
        "data1 = np.load('/content/gdrive/MyDrive/fine_tune600.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGJYzvG3HOt_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "X_original = data['X_original']\n",
        "y_original = data['y_original']\n",
        "X_augmented = data['X_augmented']\n",
        "y_augmented = data['y_augmented']\n",
        "\n",
        "\n",
        "X_original1 = data1['X_original']\n",
        "y_original1 = data1['y_original']\n",
        "X_augmented1 = data1['X_augmented']\n",
        "y_augmented1 = data1['y_augmented']\n",
        "\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "try:\n",
        "    X_original = torch.tensor(np.array(X_original), dtype=torch.float32).to(DEVICE)\n",
        "    y_original = torch.tensor(np.array(y_original), dtype=torch.float32).to(DEVICE)\n",
        "    X_augmented = torch.tensor(np.array(X_augmented), dtype=torch.float32).to(DEVICE)\n",
        "    y_augmented = torch.tensor(np.array(y_augmented), dtype=torch.float32).to(DEVICE)\n",
        "except Exception as e:\n",
        "    print(f\"Error during tensor conversion: {e}\")\n",
        "    print(f\"Shapes: X_original - {np.array(X_original).shape}, y_original - {np.array(y_original).shape}\")\n",
        "    print(f\"Shapes: X_augmented - {np.array(X_augmented).shape}, y_augmented - {np.array(y_augmented).shape}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "try:\n",
        "    X_original1 = torch.tensor(np.array(X_original1), dtype=torch.float32).to(DEVICE)\n",
        "    y_original1 = torch.tensor(np.array(y_original1), dtype=torch.float32).to(DEVICE)\n",
        "    X_augmented1 = torch.tensor(np.array(X_augmented1), dtype=torch.float32).to(DEVICE)\n",
        "    y_augmented1 = torch.tensor(np.array(y_augmented1), dtype=torch.float32).to(DEVICE)\n",
        "except Exception as e:\n",
        "    print(f\"Error during tensor conversion: {e}\")\n",
        "    print(f\"Shapes: X_original1 - {np.array(X_original1).shape}, y_original1 - {np.array(y_original1).shape}\")\n",
        "    print(f\"Shapes: X_augmented1 - {np.array(X_augmented1).shape}, y_augmented1 - {np.array(y_augmented1).shape}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "X_train = torch.cat([X_original, X_augmented])\n",
        "y_train = torch.cat([y_original, y_augmented])\n",
        "\n",
        "X_train1 = torch.cat([X_original1, X_augmented1])\n",
        "y_train1 = torch.cat([y_original1, y_augmented1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OtUM9LhH6BR"
      },
      "outputs": [],
      "source": [
        "# this cell for delete coolant temp from data\n",
        "X_train = X_train[:, :, :-1]  # Slicing to exclude the last column\n",
        "X_train1 = X_train1[:, :, :-1]  # Slicing to exclude the last column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K30XCIyEJ0lQ"
      },
      "outputs": [],
      "source": [
        "X_train = torch.nan_to_num(X_train, nan=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obfO6lqvHOt_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert the min and max values to tensors\n",
        "min_val_x = torch.tensor([0, 0, -10, -10,0], dtype=torch.float32).to(DEVICE)\n",
        "max_val_x = torch.tensor([6, 150, 10, 10,130], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "#for without coolant\n",
        "min_val_x = torch.tensor([0, 0, -10, -10], dtype=torch.float32).to(DEVICE)\n",
        "max_val_x = torch.tensor([6, 150, 10, 10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "min_val_y = torch.tensor([0], dtype=torch.float32).to(DEVICE)\n",
        "max_val_y = torch.tensor([10000], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "# Custom normalization function for X\n",
        "def custom_normalize_X(data, min_vals, max_vals):\n",
        "    for i in range(data.shape[-1]):\n",
        "        data[:, :, i] = (data[:, :, i] - min_vals[i]) / (max_vals[i] - min_vals[i])\n",
        "    return data\n",
        "\n",
        "# Custom normalization function for y\n",
        "def custom_normalize_y(data, min_val, max_val):\n",
        "    return (data - min_val) / (max_val - min_val)\n",
        "\n",
        "# Normalize X_train and X_test\n",
        "X_train_normalized = custom_normalize_X(X_train, min_val_x, max_val_x)\n",
        "# X_test_normalized = custom_normalize_X(X_test, min_val_x, max_val_x)\n",
        "\n",
        "# Normalize y_train and y_test\n",
        "y_train_normalized = custom_normalize_y(y_train, min_val_y, max_val_y)\n",
        "# y_test_normalized = custom_normalize_y(y_test, min_val_y, max_val_y)\n",
        "\n",
        "\n",
        "# Normalize X_train and X_test\n",
        "X_train_normalized1 = custom_normalize_X(X_train1, min_val_x, max_val_x)\n",
        "# X_test_normalized = custom_normalize_X(X_test, min_val_x, max_val_x)\n",
        "\n",
        "# Normalize y_train and y_test\n",
        "y_train_normalized1 = custom_normalize_y(y_train1, min_val_y, max_val_y)\n",
        "# y_test_normalized = custom_normalize_y(y_test, min_val_y, max_val_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SIX2BFyIqyn",
        "outputId": "1b918554-b2f4-4ac7-9b82-a35072cec78f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.8333, 0.6067, 0.5355, 0.5000],\n",
              "         [0.8333, 0.6133, 0.5355, 0.5500],\n",
              "         [0.8333, 0.6200, 0.5355, 0.5500],\n",
              "         ...,\n",
              "         [0.8333, 0.7200, 0.5846, 0.3000],\n",
              "         [0.8333, 0.7000, 0.5846, 0.3500],\n",
              "         [0.8333, 0.6733, 0.5846, 0.3000]],\n",
              "\n",
              "        [[0.8333, 0.8733, 0.5363, 0.5000],\n",
              "         [0.8333, 0.8800, 0.5363, 0.5500],\n",
              "         [0.8333, 0.8867, 0.5363, 0.5500],\n",
              "         ...,\n",
              "         [0.1667, 0.0533, 0.5648, 0.5500],\n",
              "         [0.1667, 0.0533, 0.5648, 0.5000],\n",
              "         [0.1667, 0.0533, 0.5000, 0.5000]],\n",
              "\n",
              "        [[0.8333, 0.7800, 0.4805, 0.5000],\n",
              "         [0.8333, 0.7867, 0.4805, 0.5500],\n",
              "         [0.8333, 0.7933, 0.4805, 0.5500],\n",
              "         ...,\n",
              "         [0.8333, 0.7200, 0.5904, 0.5000],\n",
              "         [0.8333, 0.7133, 0.5904, 0.4500],\n",
              "         [0.8333, 0.7133, 0.5904, 0.5000]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.8333, 0.6733, 0.5455, 0.4500],\n",
              "         [0.8333, 0.6733, 0.5455, 0.5000],\n",
              "         [0.8333, 0.6733, 0.5455, 0.5000],\n",
              "         ...,\n",
              "         [0.6667, 0.4000, 0.6727, 0.6500],\n",
              "         [0.6667, 0.4133, 0.6727, 0.6000],\n",
              "         [0.6667, 0.4267, 0.5000, 0.6000]],\n",
              "\n",
              "        [[0.6667, 0.4467, 0.6496, 0.6500],\n",
              "         [0.6667, 0.4667, 0.6496, 0.6500],\n",
              "         [0.6667, 0.4800, 0.6496, 0.6000],\n",
              "         ...,\n",
              "         [0.6667, 0.7933, 0.5417, 0.4000],\n",
              "         [0.6667, 0.7800, 0.5417, 0.4000],\n",
              "         [0.6667, 0.7800, 0.5000, 0.5000]],\n",
              "\n",
              "        [[0.6667, 0.7667, 0.4890, 0.4000],\n",
              "         [0.6667, 0.7467, 0.4890, 0.3500],\n",
              "         [0.6667, 0.7200, 0.4890, 0.3000],\n",
              "         ...,\n",
              "         [0.6667, 0.8867, 0.4464, 0.6000],\n",
              "         [0.6667, 0.9067, 0.4464, 0.6500],\n",
              "         [0.6667, 0.9267, 0.3698, 0.6500]]], device='cuda:0')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMglnLKkKiXL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt8BDh0YJWVQ",
        "outputId": "05150e73-f4e2-474f-86dc-1306657b1967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The tensor does not contain any NaN values.\n"
          ]
        }
      ],
      "source": [
        "has_nan = torch.isnan(X_train).any()\n",
        "\n",
        "if has_nan:\n",
        "    print(\"The tensor contains NaN values.\")\n",
        "else:\n",
        "    print(\"The tensor does not contain any NaN values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfGjH8V9H0Up",
        "outputId": "d5c7f742-b9ff-40d2-91ef-078f32a6bd75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-114-d35190ccdb36>:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FuelConsumptionModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(FuelConsumptionModel, self).__init__()\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size, 32, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Layer Normalization after each LSTM\n",
        "        self.layer_norm1 = nn.LayerNorm(64)\n",
        "        self.layer_norm2 = nn.LayerNorm(64)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        # Dense output layer\n",
        "        self.dense = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM 1 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # LSTM 2 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Dense layer for final output\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "\n",
        "# Function to load the pre-trained model and freeze the first layer\n",
        "def load_and_freeze_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # Freeze the first LSTM layer\n",
        "    for param in model.lstm1.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "model_path = '/content/sample_data/normal_old_without.pth'  # Replace with the actual path\n",
        "input_size = 4  # Update this according to your input size\n",
        "\n",
        "# Load the model with the first layer frozen\n",
        "model = load_and_freeze_model(model_path, input_size)\n",
        "\n",
        "# Now, the model is ready for fine-tuning on new data.\n",
        "# Only the parameters of the layers after lstm1 will be updated during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N90XLI9v1hxd",
        "outputId": "868168ed-e8c5-41b3-bb8c-94905332723e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-105-397ac4701523>:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FuelConsumptionModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(FuelConsumptionModel, self).__init__()\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size, 32, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Layer Normalization after each LSTM\n",
        "        self.layer_norm1 = nn.LayerNorm(64)\n",
        "        self.layer_norm2 = nn.LayerNorm(64)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        # Dense output layer\n",
        "        self.dense = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM 1 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # LSTM 2 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Dense layer for final output\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "\n",
        "# Function to load the pre-trained model and freeze all except the dense layer\n",
        "def load_and_freeze_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # Freeze all parameters except the dense (linear) layer\n",
        "    # for name, param in model.named_parameters():\n",
        "    #     if 'dense' not in name:\n",
        "    #         param.requires_grad = False\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "model_path = '/content/sample_data/normal_old_without.pth'  # Replace with the actual path\n",
        "input_size = 4  # Update this according to your input size\n",
        "\n",
        "# Load the model with only the dense layer unfrozen\n",
        "model = load_and_freeze_model(model_path, input_size)\n",
        "\n",
        "# Now, only the dense layer parameters will be updated during fine-tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-CT_KKMIcDg",
        "outputId": "e933632a-e6cf-4239-a1fc-2ad66153b0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_normalized shape: torch.Size([20718, 600, 4])\n",
            "y_train_normalized shape: torch.Size([20718, 600, 1])\n",
            "Train size: 16574, Validation size: 4144\n"
          ]
        }
      ],
      "source": [
        "# Check if X_train_normalized and y_train_normalized have the same number of samples\n",
        "print(f\"X_train_normalized shape: {X_train_normalized.shape}\")\n",
        "print(f\"y_train_normalized shape: {y_train_normalized.shape}\")\n",
        "\n",
        "# Ensure they have the same length in the first dimension\n",
        "if len(X_train_normalized) != len(y_train_normalized):\n",
        "    raise ValueError(f\"Mismatch in number of samples: {len(X_train_normalized)} in X vs {len(y_train_normalized)} in y\")\n",
        "\n",
        "# Calculate train size\n",
        "train_size = int(0.8 * len(X_train_normalized))\n",
        "\n",
        "# Split the data while preserving the order\n",
        "X_train_split = X_train_normalized[:train_size]\n",
        "y_train_split = y_train_normalized[:train_size]\n",
        "\n",
        "X_val_split = X_train_normalized[train_size:]\n",
        "y_val_split = y_train_normalized[train_size:]\n",
        "\n",
        "\n",
        "# X_train_split = X_train_normalized\n",
        "# y_train_split = y_train_normalized\n",
        "\n",
        "# X_val_split = X_train_normalized1\n",
        "# y_val_split = y_train_normalized1\n",
        "\n",
        "print(f\"Train size: {train_size}, Validation size: {len(X_val_split)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CwEy-LmI5mQ",
        "outputId": "2fd60469-d202-41a6-be6b-edbc1aefe7e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FuelConsumptionModel(\n",
              "  (lstm1): LSTM(4, 32, batch_first=True, bidirectional=True)\n",
              "  (lstm2): LSTM(64, 32, batch_first=True, bidirectional=True)\n",
              "  (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "  (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout1): Dropout(p=0.2, inplace=False)\n",
              "  (dropout2): Dropout(p=0.2, inplace=False)\n",
              "  (dense): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYccHvJmIMgY",
        "outputId": "cb05d985-7473-419c-b375-8c4d57bde7a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-114-d35190ccdb36>:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/250] ---- Training Loss: 0.0682 ---- Validation Loss: 0.052601 ------0.0001\n",
            "Epoch [2/250] ---- Training Loss: 0.0539 ---- Validation Loss: 0.047317 ------0.0001\n",
            "Epoch [3/250] ---- Training Loss: 0.0511 ---- Validation Loss: 0.045535 ------0.0001\n",
            "Epoch [4/250] ---- Training Loss: 0.0498 ---- Validation Loss: 0.044335 ------0.0001\n",
            "Epoch [5/250] ---- Training Loss: 0.0489 ---- Validation Loss: 0.043548 ------0.0001\n",
            "Epoch [6/250] ---- Training Loss: 0.0482 ---- Validation Loss: 0.042861 ------0.0001\n",
            "Epoch [7/250] ---- Training Loss: 0.0476 ---- Validation Loss: 0.042284 ------0.0001\n",
            "Epoch [8/250] ---- Training Loss: 0.0471 ---- Validation Loss: 0.041677 ------0.0001\n",
            "Epoch [9/250] ---- Training Loss: 0.0466 ---- Validation Loss: 0.041319 ------0.0001\n",
            "Epoch [10/250] ---- Training Loss: 0.0462 ---- Validation Loss: 0.040846 ------0.0001\n",
            "Epoch [11/250] ---- Training Loss: 0.0459 ---- Validation Loss: 0.040398 ------0.0001\n",
            "Epoch [12/250] ---- Training Loss: 0.0455 ---- Validation Loss: 0.040073 ------0.0001\n",
            "Epoch [13/250] ---- Training Loss: 0.0453 ---- Validation Loss: 0.039798 ------0.0001\n",
            "Epoch [14/250] ---- Training Loss: 0.0450 ---- Validation Loss: 0.039525 ------0.0001\n",
            "Epoch [15/250] ---- Training Loss: 0.0448 ---- Validation Loss: 0.039265 ------0.0001\n",
            "Epoch [16/250] ---- Training Loss: 0.0446 ---- Validation Loss: 0.039210 ------0.0001\n",
            "Epoch [17/250] ---- Training Loss: 0.0444 ---- Validation Loss: 0.038909 ------0.0001\n",
            "Epoch [18/250] ---- Training Loss: 0.0443 ---- Validation Loss: 0.038784 ------0.0001\n",
            "Epoch [19/250] ---- Training Loss: 0.0441 ---- Validation Loss: 0.038533 ------0.0001\n",
            "Epoch [20/250] ---- Training Loss: 0.0439 ---- Validation Loss: 0.038291 ------0.0001\n",
            "Epoch [21/250] ---- Training Loss: 0.0438 ---- Validation Loss: 0.038108 ------0.0001\n",
            "Epoch [22/250] ---- Training Loss: 0.0436 ---- Validation Loss: 0.037925 ------0.0001\n",
            "Epoch [23/250] ---- Training Loss: 0.0435 ---- Validation Loss: 0.037726 ------0.0001\n",
            "Epoch [24/250] ---- Training Loss: 0.0433 ---- Validation Loss: 0.037569 ------0.0001\n",
            "Epoch [25/250] ---- Training Loss: 0.0432 ---- Validation Loss: 0.037406 ------0.0001\n",
            "Epoch [26/250] ---- Training Loss: 0.0431 ---- Validation Loss: 0.037294 ------0.0001\n",
            "Epoch [27/250] ---- Training Loss: 0.0429 ---- Validation Loss: 0.037135 ------0.0001\n",
            "Epoch [28/250] ---- Training Loss: 0.0428 ---- Validation Loss: 0.036982 ------0.0001\n",
            "Epoch [29/250] ---- Training Loss: 0.0427 ---- Validation Loss: 0.036860 ------0.0001\n",
            "Epoch [30/250] ---- Training Loss: 0.0426 ---- Validation Loss: 0.036770 ------0.0001\n",
            "Epoch [31/250] ---- Training Loss: 0.0425 ---- Validation Loss: 0.036588 ------0.0001\n",
            "Epoch [32/250] ---- Training Loss: 0.0423 ---- Validation Loss: 0.036400 ------0.0001\n",
            "Epoch [33/250] ---- Training Loss: 0.0422 ---- Validation Loss: 0.036327 ------0.0001\n",
            "Epoch [34/250] ---- Training Loss: 0.0421 ---- Validation Loss: 0.036259 ------0.0001\n",
            "Epoch [35/250] ---- Training Loss: 0.0420 ---- Validation Loss: 0.036187 ------0.0001\n",
            "Epoch [36/250] ---- Training Loss: 0.0419 ---- Validation Loss: 0.036036 ------0.0001\n",
            "Epoch [37/250] ---- Training Loss: 0.0419 ---- Validation Loss: 0.035903 ------0.0001\n",
            "Epoch [38/250] ---- Training Loss: 0.0418 ---- Validation Loss: 0.035808 ------0.0001\n",
            "Epoch [39/250] ---- Training Loss: 0.0417 ---- Validation Loss: 0.035730 ------0.0001\n",
            "Epoch [40/250] ---- Training Loss: 0.0416 ---- Validation Loss: 0.035668 ------0.0001\n",
            "Epoch [41/250] ---- Training Loss: 0.0415 ---- Validation Loss: 0.035552 ------0.0001\n",
            "Epoch [42/250] ---- Training Loss: 0.0414 ---- Validation Loss: 0.035478 ------0.0001\n",
            "Epoch [43/250] ---- Training Loss: 0.0414 ---- Validation Loss: 0.035374 ------0.0001\n",
            "Epoch [44/250] ---- Training Loss: 0.0413 ---- Validation Loss: 0.035435 ------0.0001\n",
            "Epoch [45/250] ---- Training Loss: 0.0412 ---- Validation Loss: 0.035196 ------0.0001\n",
            "Epoch [46/250] ---- Training Loss: 0.0411 ---- Validation Loss: 0.035282 ------0.0001\n",
            "Epoch [47/250] ---- Training Loss: 0.0411 ---- Validation Loss: 0.035106 ------0.0001\n",
            "Epoch [48/250] ---- Training Loss: 0.0410 ---- Validation Loss: 0.035081 ------0.0001\n",
            "Epoch [49/250] ---- Training Loss: 0.0410 ---- Validation Loss: 0.034948 ------0.0001\n",
            "Epoch [50/250] ---- Training Loss: 0.0409 ---- Validation Loss: 0.034878 ------0.0001\n",
            "Epoch [51/250] ---- Training Loss: 0.0408 ---- Validation Loss: 0.034771 ------0.0001\n",
            "Epoch [52/250] ---- Training Loss: 0.0408 ---- Validation Loss: 0.034706 ------0.0001\n",
            "Epoch [53/250] ---- Training Loss: 0.0407 ---- Validation Loss: 0.034727 ------0.0001\n",
            "Epoch [54/250] ---- Training Loss: 0.0406 ---- Validation Loss: 0.034676 ------0.0001\n",
            "Epoch [55/250] ---- Training Loss: 0.0406 ---- Validation Loss: 0.034536 ------0.0001\n",
            "Epoch [56/250] ---- Training Loss: 0.0405 ---- Validation Loss: 0.034470 ------0.0001\n",
            "Epoch [57/250] ---- Training Loss: 0.0405 ---- Validation Loss: 0.034433 ------0.0001\n",
            "Epoch [58/250] ---- Training Loss: 0.0404 ---- Validation Loss: 0.034357 ------0.0001\n",
            "Epoch [59/250] ---- Training Loss: 0.0403 ---- Validation Loss: 0.034322 ------0.0001\n",
            "Epoch [60/250] ---- Training Loss: 0.0403 ---- Validation Loss: 0.034221 ------0.0001\n",
            "Epoch [61/250] ---- Training Loss: 0.0402 ---- Validation Loss: 0.034234 ------0.0001\n",
            "Epoch [62/250] ---- Training Loss: 0.0402 ---- Validation Loss: 0.034151 ------0.0001\n",
            "Epoch [63/250] ---- Training Loss: 0.0401 ---- Validation Loss: 0.034127 ------0.0001\n",
            "Epoch [64/250] ---- Training Loss: 0.0401 ---- Validation Loss: 0.034148 ------0.0001\n",
            "Epoch [65/250] ---- Training Loss: 0.0400 ---- Validation Loss: 0.034008 ------0.0001\n",
            "Epoch [66/250] ---- Training Loss: 0.0400 ---- Validation Loss: 0.033910 ------0.0001\n",
            "Epoch [67/250] ---- Training Loss: 0.0399 ---- Validation Loss: 0.033832 ------0.0001\n",
            "Epoch [68/250] ---- Training Loss: 0.0399 ---- Validation Loss: 0.033831 ------0.0001\n",
            "Epoch [69/250] ---- Training Loss: 0.0398 ---- Validation Loss: 0.033689 ------0.0001\n",
            "Epoch [70/250] ---- Training Loss: 0.0398 ---- Validation Loss: 0.033928 ------0.0001\n",
            "Epoch [71/250] ---- Training Loss: 0.0397 ---- Validation Loss: 0.033599 ------0.0001\n",
            "Epoch [72/250] ---- Training Loss: 0.0396 ---- Validation Loss: 0.033522 ------0.0001\n",
            "Epoch [73/250] ---- Training Loss: 0.0396 ---- Validation Loss: 0.033451 ------0.0001\n",
            "Epoch [74/250] ---- Training Loss: 0.0395 ---- Validation Loss: 0.033431 ------0.0001\n",
            "Epoch [75/250] ---- Training Loss: 0.0395 ---- Validation Loss: 0.033370 ------0.0001\n",
            "Epoch [76/250] ---- Training Loss: 0.0394 ---- Validation Loss: 0.033351 ------0.0001\n",
            "Epoch [77/250] ---- Training Loss: 0.0394 ---- Validation Loss: 0.033210 ------0.0001\n",
            "Epoch [78/250] ---- Training Loss: 0.0393 ---- Validation Loss: 0.033187 ------0.0001\n",
            "Epoch [79/250] ---- Training Loss: 0.0392 ---- Validation Loss: 0.033185 ------0.0001\n",
            "Epoch [80/250] ---- Training Loss: 0.0392 ---- Validation Loss: 0.033083 ------0.0001\n",
            "Epoch [81/250] ---- Training Loss: 0.0392 ---- Validation Loss: 0.033094 ------0.0001\n",
            "Epoch [82/250] ---- Training Loss: 0.0391 ---- Validation Loss: 0.033088 ------0.0001\n",
            "Epoch [83/250] ---- Training Loss: 0.0391 ---- Validation Loss: 0.032994 ------0.0001\n",
            "Epoch [84/250] ---- Training Loss: 0.0390 ---- Validation Loss: 0.032874 ------0.0001\n",
            "Epoch [85/250] ---- Training Loss: 0.0390 ---- Validation Loss: 0.032861 ------0.0001\n",
            "Epoch [86/250] ---- Training Loss: 0.0390 ---- Validation Loss: 0.032793 ------0.0001\n",
            "Epoch [87/250] ---- Training Loss: 0.0389 ---- Validation Loss: 0.032825 ------0.0001\n",
            "Epoch [88/250] ---- Training Loss: 0.0388 ---- Validation Loss: 0.032708 ------0.0001\n",
            "Epoch [89/250] ---- Training Loss: 0.0388 ---- Validation Loss: 0.032720 ------0.0001\n",
            "Epoch [90/250] ---- Training Loss: 0.0388 ---- Validation Loss: 0.032709 ------0.0001\n",
            "Epoch [91/250] ---- Training Loss: 0.0388 ---- Validation Loss: 0.032554 ------0.0001\n",
            "Epoch [92/250] ---- Training Loss: 0.0387 ---- Validation Loss: 0.032548 ------0.0001\n",
            "Epoch [93/250] ---- Training Loss: 0.0387 ---- Validation Loss: 0.032505 ------0.0001\n",
            "Epoch [94/250] ---- Training Loss: 0.0386 ---- Validation Loss: 0.032451 ------0.0001\n",
            "Epoch [95/250] ---- Training Loss: 0.0386 ---- Validation Loss: 0.032484 ------0.0001\n",
            "Epoch [96/250] ---- Training Loss: 0.0386 ---- Validation Loss: 0.032386 ------0.0001\n",
            "Epoch [97/250] ---- Training Loss: 0.0385 ---- Validation Loss: 0.032340 ------0.0001\n",
            "Epoch [98/250] ---- Training Loss: 0.0385 ---- Validation Loss: 0.032246 ------0.0001\n",
            "Epoch [99/250] ---- Training Loss: 0.0384 ---- Validation Loss: 0.032347 ------0.0001\n",
            "Epoch [100/250] ---- Training Loss: 0.0384 ---- Validation Loss: 0.032189 ------0.0001\n",
            "Epoch [101/250] ---- Training Loss: 0.0384 ---- Validation Loss: 0.032211 ------0.0001\n",
            "Epoch [102/250] ---- Training Loss: 0.0383 ---- Validation Loss: 0.032096 ------0.0001\n",
            "Epoch [103/250] ---- Training Loss: 0.0383 ---- Validation Loss: 0.032323 ------0.0001\n",
            "Epoch [104/250] ---- Training Loss: 0.0383 ---- Validation Loss: 0.032116 ------0.0001\n",
            "Epoch [105/250] ---- Training Loss: 0.0382 ---- Validation Loss: 0.032001 ------0.0001\n",
            "Epoch [106/250] ---- Training Loss: 0.0382 ---- Validation Loss: 0.031972 ------0.0001\n",
            "Epoch [107/250] ---- Training Loss: 0.0381 ---- Validation Loss: 0.031933 ------0.0001\n",
            "Epoch [108/250] ---- Training Loss: 0.0381 ---- Validation Loss: 0.031867 ------0.0001\n",
            "Epoch [109/250] ---- Training Loss: 0.0381 ---- Validation Loss: 0.031833 ------0.0001\n",
            "Epoch [110/250] ---- Training Loss: 0.0380 ---- Validation Loss: 0.031766 ------0.0001\n",
            "Epoch [111/250] ---- Training Loss: 0.0380 ---- Validation Loss: 0.031746 ------0.0001\n",
            "Epoch [112/250] ---- Training Loss: 0.0380 ---- Validation Loss: 0.031731 ------0.0001\n",
            "Epoch [113/250] ---- Training Loss: 0.0379 ---- Validation Loss: 0.031648 ------0.0001\n",
            "Epoch [114/250] ---- Training Loss: 0.0379 ---- Validation Loss: 0.031619 ------0.0001\n",
            "Epoch [115/250] ---- Training Loss: 0.0379 ---- Validation Loss: 0.031584 ------0.0001\n",
            "Epoch [116/250] ---- Training Loss: 0.0379 ---- Validation Loss: 0.031618 ------0.0001\n",
            "Epoch [117/250] ---- Training Loss: 0.0378 ---- Validation Loss: 0.031510 ------0.0001\n",
            "Epoch [118/250] ---- Training Loss: 0.0378 ---- Validation Loss: 0.031495 ------0.0001\n",
            "Epoch [119/250] ---- Training Loss: 0.0377 ---- Validation Loss: 0.031633 ------0.0001\n",
            "Epoch [120/250] ---- Training Loss: 0.0377 ---- Validation Loss: 0.031583 ------0.0001\n",
            "Epoch [121/250] ---- Training Loss: 0.0377 ---- Validation Loss: 0.031337 ------0.0001\n",
            "Epoch [122/250] ---- Training Loss: 0.0377 ---- Validation Loss: 0.031436 ------0.0001\n",
            "Epoch [123/250] ---- Training Loss: 0.0376 ---- Validation Loss: 0.031305 ------0.0001\n",
            "Epoch [124/250] ---- Training Loss: 0.0376 ---- Validation Loss: 0.031238 ------0.0001\n",
            "Epoch [125/250] ---- Training Loss: 0.0376 ---- Validation Loss: 0.031222 ------0.0001\n",
            "Epoch [126/250] ---- Training Loss: 0.0375 ---- Validation Loss: 0.031220 ------0.0001\n",
            "Epoch [127/250] ---- Training Loss: 0.0375 ---- Validation Loss: 0.031150 ------0.0001\n",
            "Epoch [128/250] ---- Training Loss: 0.0375 ---- Validation Loss: 0.031136 ------0.0001\n",
            "Epoch [129/250] ---- Training Loss: 0.0375 ---- Validation Loss: 0.031126 ------0.0001\n",
            "Epoch [130/250] ---- Training Loss: 0.0374 ---- Validation Loss: 0.031073 ------0.0001\n",
            "Epoch [131/250] ---- Training Loss: 0.0374 ---- Validation Loss: 0.031141 ------0.0001\n",
            "Epoch [132/250] ---- Training Loss: 0.0373 ---- Validation Loss: 0.030997 ------0.0001\n",
            "Epoch [133/250] ---- Training Loss: 0.0373 ---- Validation Loss: 0.030941 ------0.0001\n",
            "Epoch [134/250] ---- Training Loss: 0.0373 ---- Validation Loss: 0.030912 ------0.0001\n",
            "Epoch [135/250] ---- Training Loss: 0.0373 ---- Validation Loss: 0.030882 ------0.0001\n",
            "Epoch [136/250] ---- Training Loss: 0.0372 ---- Validation Loss: 0.030874 ------0.0001\n",
            "Epoch [137/250] ---- Training Loss: 0.0372 ---- Validation Loss: 0.030993 ------0.0001\n",
            "Epoch [138/250] ---- Training Loss: 0.0372 ---- Validation Loss: 0.030814 ------0.0001\n",
            "Epoch [139/250] ---- Training Loss: 0.0371 ---- Validation Loss: 0.030842 ------0.0001\n",
            "Epoch [140/250] ---- Training Loss: 0.0371 ---- Validation Loss: 0.030705 ------0.0001\n",
            "Epoch [141/250] ---- Training Loss: 0.0371 ---- Validation Loss: 0.030703 ------0.0001\n",
            "Epoch [142/250] ---- Training Loss: 0.0370 ---- Validation Loss: 0.030751 ------0.0001\n",
            "Epoch [143/250] ---- Training Loss: 0.0370 ---- Validation Loss: 0.030603 ------0.0001\n",
            "Epoch [144/250] ---- Training Loss: 0.0370 ---- Validation Loss: 0.030604 ------0.0001\n",
            "Epoch [145/250] ---- Training Loss: 0.0369 ---- Validation Loss: 0.030599 ------0.0001\n",
            "Epoch [146/250] ---- Training Loss: 0.0369 ---- Validation Loss: 0.030560 ------0.0001\n",
            "Epoch [147/250] ---- Training Loss: 0.0369 ---- Validation Loss: 0.030463 ------0.0001\n",
            "Epoch [148/250] ---- Training Loss: 0.0369 ---- Validation Loss: 0.030457 ------0.0001\n",
            "Epoch [149/250] ---- Training Loss: 0.0368 ---- Validation Loss: 0.030392 ------0.0001\n",
            "Epoch [150/250] ---- Training Loss: 0.0368 ---- Validation Loss: 0.030325 ------0.0001\n",
            "Epoch [151/250] ---- Training Loss: 0.0368 ---- Validation Loss: 0.030681 ------0.0001\n",
            "Epoch [152/250] ---- Training Loss: 0.0367 ---- Validation Loss: 0.030357 ------0.0001\n",
            "Epoch [153/250] ---- Training Loss: 0.0367 ---- Validation Loss: 0.030353 ------0.0001\n",
            "Epoch [154/250] ---- Training Loss: 0.0366 ---- Validation Loss: 0.030174 ------5e-05\n",
            "Epoch [155/250] ---- Training Loss: 0.0366 ---- Validation Loss: 0.030191 ------5e-05\n",
            "Epoch [156/250] ---- Training Loss: 0.0366 ---- Validation Loss: 0.030142 ------5e-05\n",
            "Epoch [157/250] ---- Training Loss: 0.0366 ---- Validation Loss: 0.030160 ------5e-05\n",
            "Epoch [158/250] ---- Training Loss: 0.0366 ---- Validation Loss: 0.030140 ------5e-05\n",
            "Epoch [159/250] ---- Training Loss: 0.0366 ---- Validation Loss: 0.030099 ------5e-05\n",
            "Epoch [160/250] ---- Training Loss: 0.0365 ---- Validation Loss: 0.030186 ------5e-05\n",
            "Epoch [161/250] ---- Training Loss: 0.0365 ---- Validation Loss: 0.030032 ------5e-05\n",
            "Epoch [162/250] ---- Training Loss: 0.0365 ---- Validation Loss: 0.030074 ------5e-05\n",
            "Epoch [163/250] ---- Training Loss: 0.0365 ---- Validation Loss: 0.030047 ------5e-05\n",
            "Epoch [164/250] ---- Training Loss: 0.0365 ---- Validation Loss: 0.030015 ------5e-05\n",
            "Epoch [165/250] ---- Training Loss: 0.0365 ---- Validation Loss: 0.030112 ------5e-05\n",
            "Epoch [166/250] ---- Training Loss: 0.0365 ---- Validation Loss: 0.030067 ------5e-05\n",
            "Epoch [167/250] ---- Training Loss: 0.0364 ---- Validation Loss: 0.029973 ------5e-05\n",
            "Epoch [168/250] ---- Training Loss: 0.0364 ---- Validation Loss: 0.030007 ------5e-05\n",
            "Epoch [169/250] ---- Training Loss: 0.0364 ---- Validation Loss: 0.029946 ------5e-05\n",
            "Epoch [170/250] ---- Training Loss: 0.0364 ---- Validation Loss: 0.029941 ------5e-05\n",
            "Epoch [171/250] ---- Training Loss: 0.0364 ---- Validation Loss: 0.029956 ------5e-05\n",
            "Epoch [172/250] ---- Training Loss: 0.0364 ---- Validation Loss: 0.030002 ------5e-05\n",
            "Epoch [173/250] ---- Training Loss: 0.0363 ---- Validation Loss: 0.029863 ------5e-05\n",
            "Epoch [174/250] ---- Training Loss: 0.0363 ---- Validation Loss: 0.029841 ------5e-05\n",
            "Epoch [175/250] ---- Training Loss: 0.0363 ---- Validation Loss: 0.029860 ------5e-05\n",
            "Epoch [176/250] ---- Training Loss: 0.0363 ---- Validation Loss: 0.030050 ------5e-05\n",
            "Epoch [177/250] ---- Training Loss: 0.0363 ---- Validation Loss: 0.029838 ------5e-05\n",
            "Epoch [178/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029780 ------2.5e-05\n",
            "Epoch [179/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029786 ------2.5e-05\n",
            "Epoch [180/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029758 ------2.5e-05\n",
            "Epoch [181/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029763 ------2.5e-05\n",
            "Epoch [182/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029819 ------2.5e-05\n",
            "Epoch [183/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029792 ------2.5e-05\n",
            "Epoch [184/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029766 ------1.25e-05\n",
            "Epoch [185/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029734 ------1.25e-05\n",
            "Epoch [186/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029737 ------1.25e-05\n",
            "Epoch [187/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029709 ------1.25e-05\n",
            "Epoch [188/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029718 ------1.25e-05\n",
            "Epoch [189/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029761 ------1.25e-05\n",
            "Epoch [190/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029716 ------1.25e-05\n",
            "Epoch [191/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029695 ------6.25e-06\n",
            "Epoch [192/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029701 ------6.25e-06\n",
            "Epoch [193/250] ---- Training Loss: 0.0362 ---- Validation Loss: 0.029704 ------6.25e-06\n",
            "Epoch [194/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029697 ------6.25e-06\n",
            "Epoch [195/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029710 ------3.125e-06\n",
            "Epoch [196/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029695 ------3.125e-06\n",
            "Epoch [197/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029712 ------3.125e-06\n",
            "Epoch [198/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029687 ------1.5625e-06\n",
            "Epoch [199/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029698 ------1.5625e-06\n",
            "Epoch [200/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029688 ------1.5625e-06\n",
            "Epoch [201/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029687 ------1.5625e-06\n",
            "Epoch [202/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029688 ------7.8125e-07\n",
            "Epoch [203/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029688 ------7.8125e-07\n",
            "Epoch [204/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029691 ------7.8125e-07\n",
            "Epoch [205/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029690 ------3.90625e-07\n",
            "Epoch [206/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029688 ------3.90625e-07\n",
            "Epoch [207/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029686 ------3.90625e-07\n",
            "Epoch [208/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029688 ------1.953125e-07\n",
            "Epoch [209/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029682 ------1.953125e-07\n",
            "Epoch [210/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029687 ------1.953125e-07\n",
            "Epoch [211/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029685 ------1.953125e-07\n",
            "Epoch [212/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029691 ------1.953125e-07\n",
            "Epoch [213/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029686 ------9.765625e-08\n",
            "Epoch [214/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029685 ------9.765625e-08\n",
            "Epoch [215/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029685 ------9.765625e-08\n",
            "Epoch [216/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029685 ------4.8828125e-08\n",
            "Epoch [217/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029686 ------4.8828125e-08\n",
            "Epoch [218/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029685 ------4.8828125e-08\n",
            "Epoch [219/250] ---- Training Loss: 0.0361 ---- Validation Loss: 0.029685 ------2.44140625e-08\n",
            "Early stopping at epoch 219\n",
            "Saved model: best_fuel_consumption_model.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR  # Importing StepLR for learning rate decay\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# Assuming `FuelConsumptionModel`, `X_train_normalized`, `train_loader`, `val_loader`, `DEVICE`, and `EPOCHS` are defined\n",
        "\n",
        "# Choose a single loss function to use for all experiments\n",
        "criterion = nn.L1Loss()  # You can change this to your preferred loss function\n",
        "\n",
        "EPOCHS = 250\n",
        "# Define weight decay values and initial learning rates for decay schedules\n",
        "weight_decay_values = 1e-5\n",
        "initial_learning_rates = [1e-4]  # Two starting learning rates\n",
        "\n",
        "# Initialize variables to track the best parameters\n",
        "best_weight_decay = None\n",
        "best_initial_lr = None\n",
        "best_model_weights = None\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "ini_batches = [64]\n",
        "# Loop over all combinations of initial learning rates and weight decay values\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "# Create DataLoader for training and validation sets\n",
        "train_loader = DataLoader(TensorDataset(X_train_split, y_train_split), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_split, y_val_split), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "for init_lr in initial_learning_rates:\n",
        "    # Initialize model, criterion, and optimizer for each combination\n",
        "    model = load_and_freeze_model(model_path, input_size)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=init_lr, weight_decay=weight_decay_values)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
        "    # scheduler = StepLR(optimizer, step_size=50, gamma=0.5)  # Decay LR by 0.5 every 50 epochs\n",
        "\n",
        "    # Early stopping parameters\n",
        "    patience = 10  # Number of epochs to wait before stopping if no improvement\n",
        "    best_loss = float('inf')  # Initialize best loss to infinity\n",
        "    epochs_without_improvement = 0  # Counter for epochs without improvement\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        model.train()  # Ensure model is in training mode\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_training_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()  # Switch to evaluation mode\n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:  # Assume you have a validation DataLoader `val_loader`\n",
        "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "                outputs = model(inputs)\n",
        "                val_loss = criterion(outputs, targets)\n",
        "                val_running_loss += val_loss.item()\n",
        "\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.6f} ------{current_lr}\")\n",
        "\n",
        "        # print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.4f}    Init LR: {init_lr:.0e}  WD: {wd:.0e}\")\n",
        "\n",
        "        # Adjust the learning rate\n",
        "        scheduler.step(avg_val_loss)\n",
        "        # scheduler.step()\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Save the model for the current combination\n",
        "        model_filename = f'best_fuel_consumption_model.pth'\n",
        "        torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "\n",
        "print(f\"Saved model: {model_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT91Xk2ibldP"
      },
      "source": [
        "#Test with all saved model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rZR4FCk0i2IB",
        "outputId": "a629cb0f-cb46-4b97-f3b5-a544608899e3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Car_Dena_TC+5_26 s 513 ir 10_Data_12_07_2024, 08_23_00_to_12_08_2024, 08_23_00.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-07bd025136ea>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Read the Excel file into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# List of specific trip IDs to filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Car_Dena_TC+5_26 s 513 ir 10_Data_12_07_2024, 08_23_00_to_12_08_2024, 08_23_00.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load the Excel file\n",
        "excel_file = \"/content/Car_Dena_TC+5_26 s 513 ir 10_Data_12_07_2024, 08_23_00_to_12_08_2024, 08_23_00.xlsx\"  # Replace with the path to your Excel file\n",
        "output_folder = \"test\"  # Replace with the path where you want to save CSV files\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Read the Excel file into a DataFrame\n",
        "df = pd.read_excel(excel_file)\n",
        "\n",
        "# List of specific trip IDs to filter\n",
        "specific_trips = [2,3 , 4 , 6]\n",
        "\n",
        "# Filter the DataFrame for the specific trips\n",
        "filtered_df = df[df['trip'].isin(specific_trips)]\n",
        "\n",
        "# Group by the \"trip\" column (replace 'trip' with the actual column name for grouping)\n",
        "for trip_id, trip_data in filtered_df.groupby('trip'):\n",
        "    # Create a filename for the trip\n",
        "    csv_file = os.path.join(output_folder, f\"trip_{trip_id}.csv\")\n",
        "\n",
        "    # Save the trip data to a CSV file\n",
        "    trip_data.to_csv(csv_file, index=False)\n",
        "\n",
        "    print(f\"Saved trip {trip_id} to {csv_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SKUr0wzlkae",
        "outputId": "362df05f-38c4-45d4-b08b-608d3924bc93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing files: 100%|██████████| 4/4 [00:19<00:00,  4.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated files saved successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm  # Import tqdm for the file-level progress bar\n",
        "\n",
        "# Path to the folder containing CSV files\n",
        "folder_path = \"test\"  # Update to your folder path\n",
        "\n",
        "# Initialize last received altitude\n",
        "last_received_altitude = None\n",
        "\n",
        "# Function to get altitude\n",
        "def get_altitude(lat, lon, retries=10):\n",
        "    global last_received_altitude  # Use the last received altitude as fallback\n",
        "    url = f\"https://api.open-elevation.com/api/v1/lookup?locations={lat},{lon}\"\n",
        "    url = f'https://www.elevation-api.eu/v1/elevation?pts=[[{lat},{lon}]]'\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                elevation_data = response.json()\n",
        "                if 'elevations' in elevation_data and elevation_data['elevations']:\n",
        "                    altitude = elevation_data['elevations'][0]  # Extracting the first elevation value\n",
        "                    last_received_altitude = altitude  # Update last successful altitude\n",
        "                    return altitude\n",
        "            elif response.status_code == 504:\n",
        "                return last_received_altitude  # Use last received altitude on 504 error\n",
        "        except requests.exceptions.RequestException:\n",
        "            time.sleep(2)  # Wait for 2 seconds before retrying\n",
        "    return last_received_altitude  # Use last received altitude if all retries fail\n",
        "\n",
        "# Helper function to get altitude for a block of 100 rows\n",
        "def get_altitude_for_block(df, start_index):\n",
        "    for i in range(start_index, min(start_index + 100, len(df))):\n",
        "        lat = df.at[i, 'latitude']\n",
        "        lon = df.at[i, 'longitude']\n",
        "\n",
        "        # Skip rows with missing or invalid latitude/longitude\n",
        "        if pd.isna(lat) or pd.isna(lon) or lat == 0 or lon == 0:\n",
        "            continue\n",
        "\n",
        "        altitude = get_altitude(lat, lon)\n",
        "        if altitude is not None:\n",
        "            return altitude\n",
        "    return None\n",
        "\n",
        "# Process each CSV file in the specified folder\n",
        "for filename in tqdm(os.listdir(folder_path), desc=\"Processing files\"):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        data_df = pd.read_csv(file_path)\n",
        "\n",
        "        # Check if 'latitude' and 'longitude' columns exist in the dataframe\n",
        "        if 'latitude' not in data_df.columns or 'longitude' not in data_df.columns:\n",
        "            continue  # Skip this file if columns are missing\n",
        "\n",
        "        # Initialize the 'correct_altitude' column with None values\n",
        "        data_df['correct_altitude'] = None\n",
        "\n",
        "        # Process rows in blocks of 100\n",
        "        for i in range(0, len(data_df), 100):\n",
        "            altitude = get_altitude_for_block(data_df, i)\n",
        "\n",
        "            # Adjust the end of the range to ensure it's within bounds and handle small blocks\n",
        "            block_end = min(i + 99, len(data_df) - 1)\n",
        "\n",
        "            # If the altitude is None and the block size is 1 (e.g., last row), skip setting altitude\n",
        "            if altitude is None and (block_end == i):\n",
        "                continue\n",
        "\n",
        "            # Set the altitude for the current block\n",
        "            data_df.loc[i:block_end, 'correct_altitude'] = altitude\n",
        "\n",
        "        # Save the updated dataframe to a new CSV file, retaining the same name\n",
        "        output_file_path = os.path.join(folder_path, filename)  # Save to the same file\n",
        "        data_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Updated files saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0Q24PbfDll_P",
        "outputId": "39679e0d-395f-4a82-a252-5db38f3a8944"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-89b2d57d6610>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Process each CSV file in the specified folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm  # Import tqdm for the file-level progress bar\n",
        "# Path to the folder containing CSV files\n",
        "folder_path = \"test\"\n",
        "\n",
        "# Process each CSV file in the specified folder\n",
        "for filename in tqdm(os.listdir(folder_path), desc=\"Processing files\"):\n",
        "    if filename.endswith('.csv'):\n",
        "        print(filename)\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        print(f\"Processing file: {filename}\")\n",
        "\n",
        "        # Read the CSV file\n",
        "        data_df = pd.read_csv(file_path)\n",
        "        # data_df = data_df.sort_values(by='time')\n",
        "        data_df['correct_altitude'] = data_df['correct_altitude'].fillna(method='bfill')\n",
        "\n",
        "        # Sort the DataFrame by 'time' and 'trip'\n",
        "\n",
        "\n",
        "        # Initialize the 'slope' column with 0.0\n",
        "        data_df['slope'] = 0.0\n",
        "\n",
        "        # Group by 'trip' and calculate slope for each group\n",
        "        for trip, group in data_df.groupby('trip'):\n",
        "            # Check if the group has at least 100 rows\n",
        "            num_rows = len(group)\n",
        "            for i in range(0, num_rows - 100, 100):\n",
        "                start_altitude = group.iloc[i]['correct_altitude']\n",
        "                end_altitude = group.iloc[i + 100]['correct_altitude']\n",
        "                start_mileage = group.iloc[i]['Cumulative_mileage']\n",
        "                end_mileage = group.iloc[i + 100]['Cumulative_mileage']\n",
        "\n",
        "                if end_mileage - start_mileage != 0:\n",
        "                    slope = (end_altitude - start_altitude) / (end_mileage - start_mileage) / 10\n",
        "                    data_df.loc[group.index[i:i + 99], 'slope'] = slope\n",
        "\n",
        "            # Calculate slope for remaining rows if less than 100 remain\n",
        "            if num_rows % 100 != 0:\n",
        "                last_block_start = num_rows - (num_rows % 100)\n",
        "                if last_block_start > 0:\n",
        "                    start_altitude = group.iloc[last_block_start - 1]['correct_altitude']\n",
        "                    end_altitude = group.iloc[num_rows - 1]['correct_altitude']\n",
        "                    start_mileage = group.iloc[last_block_start - 1]['Cumulative_mileage']\n",
        "                    end_mileage = group.iloc[num_rows - 1]['Cumulative_mileage']\n",
        "\n",
        "                    if end_mileage - start_mileage != 0:\n",
        "                        slope = (end_altitude - start_altitude) / (end_mileage - start_mileage) / 10\n",
        "                        data_df.loc[group.index[last_block_start - 1:num_rows - 1], 'slope'] = slope\n",
        "\n",
        "        # Define output file path\n",
        "        # output_file_path = os.path.join(folder_path, f\"{filename[:-4]}_slope_added.csv\")\n",
        "        output_file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Save the updated DataFrame to a new CSV file\n",
        "        data_df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"All files processed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test trip cons**"
      ],
      "metadata": {
        "id": "P2yODKACvfuj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSX_AJCXOYNu",
        "outputId": "9360f147-e576-4ef4-b724-3f2ef1ab86e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_4 (1).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_49.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_112.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_6.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_48.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_50.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_46.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/Real_NEDC_testroom.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_115.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_3 (1).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-080475bcb046>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-24-080475bcb046>:107: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  trip_fuel_consp100    = (((df1['Trip_fuel_consumption'].iloc[-1] - df1['Trip_fuel_consumption'].iloc[0]) / 10000) / mileagee)\n",
            "<ipython-input-24-080475bcb046>:134: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10000) / mileagee\n",
            "<ipython-input-24-080475bcb046>:161: RuntimeWarning: invalid value encountered in scalar subtract\n",
            "  f\"Error(%) : {((abs(trip_fuel_consp100 -trip_fuel_cons_predicted_p100 ))/trip_fuel_consp100)*100:.2f}\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/best_self_att/trip_47.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "\n",
        "\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    if not df.empty :\n",
        "      df.rename(columns={\n",
        "          'Engine_speed': 'Engine speed',\n",
        "          'time': 'Time',\n",
        "          'Vehicle_Speed': 'Speed',\n",
        "          'Trip_fuel_consumption': 'Trip fuel consumption',\n",
        "          'Throttle_position': 'Throttle position',\n",
        "          'Accelerator_pedal_position': 'Accelerator pedal position',\n",
        "          'Cumulative_mileage': 'Cumulative mileage',\n",
        "          'Coolant_temp': 'Coolant_temperature'\n",
        "      }, inplace=True)\n",
        "      df['Time'] = df['Time'] - df['Time'].iloc[0]\n",
        "      df['Momentary fuel consumption1'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "      df['Momentary fuel consumption2'] = df['Trip fuel consumption'].diff().shift(-1).fillna(0)\n",
        "      df['Acceleration1'] = df['Speed'].diff().fillna(0)\n",
        "      df['Acceleration2'] = df['Speed'].diff().shift(-1).fillna(0)\n",
        "      df['Current_gear_shift_position_(Current_gear)'] = df['Current_gear_shift_position_(Current_gear)'].replace({13: 0, 14: 1})\n",
        "      # features = df[['Adjusted_gear_position', 'Speed', 'slope', 'Acceleration', 'Coolant_temperature']]\n",
        "\n",
        "\n",
        "      # df = df.iloc[590:]\n",
        "      # df = df.iloc[:-5]\n",
        "\n",
        "      # features = df[['Acceleration1','Acceleration2','Throttle position','Accelerator pedal position','Coolant_temperature','Speed','Engine speed', 'Current_gear_shift_position_(Current_gear)','correct_altitude',  'slope']]\n",
        "      features = df[['Acceleration1','Acceleration2','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "      # features = df[['Acceleration1','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      target = df['Momentary fuel consumption2']\n",
        "\n",
        "\n",
        "\n",
        "    return features, target\n",
        "\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "\n",
        "    min_val_x = [-10,-10, 0,0, -10]\n",
        "    max_val_x = [10,10,200, 5, 10]\n",
        "\n",
        "    # min_val_x = [-10, 0,0, -10]\n",
        "    # max_val_x = [10,200, 5, 10]\n",
        "\n",
        "\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "\n",
        "    df1 = pd.read_csv(input_file)\n",
        "\n",
        "    timee                 = (df1['time'].iloc[-1] - df1['time'].iloc[0]) / 60000\n",
        "    mileagee              = (df1['Cumulative_mileage'].iloc[-1] - df1['Cumulative_mileage'].iloc[0])\n",
        "    # mileagee = 11.01\n",
        "\n",
        "    trip_fuel_consp100    = (((df1['Trip_fuel_consumption'].iloc[-1] - df1['Trip_fuel_consumption'].iloc[0]) / 10000) / mileagee)\n",
        "\n",
        "    features, actual_values  = process_file(input_file)\n",
        "    rate = actual_values\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values])\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * 30000 )\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * 30000 )\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "    trip_fuel_consp100_p = np.cumsum(predictions[:len(actual_values)], axis=0)\n",
        "    trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10000) / mileagee\n",
        "\n",
        "    # Calculate error metrics\n",
        "    # mae = mean_absolute_error(actual_valuess, predictions)\n",
        "    # mse = mean_squared_error(actual_valuess, predictions)\n",
        "\n",
        "    # Handling MAPE: Ignore zero actual values to avoid NaN issues\n",
        "    # non_zero_actual = actual_valuess != 0\n",
        "    # mape = np.mean(np.abs((actual_valuess[non_zero_actual] - predictions[non_zero_actual]) / actual_valuess[non_zero_actual])) * 100\n",
        "\n",
        "    # print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "    # print(f'MSE: {mse:.4f}')\n",
        "    # print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions[:len(actual_values)], axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "    plt.legend()\n",
        "    text = (\n",
        "          f\"time(M) : {timee:.0f} \\n\"\n",
        "          f\"mileage(KM) : {mileagee:.1f} \\n\"\n",
        "          f\"Real fuel cons: {trip_fuel_consp100:.2f} \\n\"\n",
        "          f\"Pred fuel cons: {trip_fuel_cons_predicted_p100:.2f} \\n\"\n",
        "          f\"Error(%) : {((abs(trip_fuel_consp100 -trip_fuel_cons_predicted_p100 ))/trip_fuel_consp100)*100:.2f}\"\n",
        "      )\n",
        "    plt.text(\n",
        "        0.95, 0.05,  # x and y position in figure coordinates\n",
        "        text,  # Multi-line text\n",
        "        fontsize=10,\n",
        "        color='gray',\n",
        "        horizontalalignment='right',\n",
        "        verticalalignment='bottom',\n",
        "        transform=plt.gca().transAxes  # Use axes coordinates\n",
        "    )\n",
        "    # Create model-specific directory\n",
        "    model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "    # Save plot using model name in the designated directory\n",
        "    plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'Speed': features[\"Speed\"].iloc[:len(predictions)],\n",
        "        'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "        'Predicted_sum': np.cumsum(predictions[:len(actual_values)], axis=0),\n",
        "        'Predicted': predictions[:len(actual_values)] ,\n",
        "        'rate' : rate\n",
        "        # 'MAE': mae,  # Add MAE to the dataframe\n",
        "        # 'MSE': mse,  # Add MSE to the dataframe\n",
        "\n",
        "    })\n",
        "\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "\n",
        "\n",
        "\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content'  # Directory containing CSV files\n",
        "model_dir = '/content'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "# input_size = 4  # Number of features in the input data\n",
        "\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"0Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzLT4cfVOXL0"
      },
      "source": [
        "# **Raate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vfRAe8DYqq9",
        "outputId": "d374a96d-345f-4243-c3d7-6fee306b2626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-214b7dca2b01>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.716533333333334\n",
            "CSV saved as: predicted_vs_actual_plots/513_model_2slices_rate/Real_NEDC_testroom.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "\n",
        "\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    if not df.empty :\n",
        "      df.rename(columns={\n",
        "          'Engine_speed': 'Engine speed',\n",
        "          'time': 'Time',\n",
        "          'Vehicle_Speed': 'Speed',\n",
        "          'Trip_fuel_consumption': 'Trip fuel consumption',\n",
        "          'Throttle_position': 'Throttle position',\n",
        "          'Accelerator_pedal_position': 'Accelerator pedal position',\n",
        "          'Cumulative_mileage': 'Cumulative mileage',\n",
        "          'Coolant_temp': 'Coolant_temperature'\n",
        "      }, inplace=True)\n",
        "      df['Time'] = df['Time'] - df['Time'].iloc[0]\n",
        "      df['Momentary fuel consumption1'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "      df['Momentary fuel consumption2'] = df['Trip fuel consumption'].diff().shift(-1).fillna(0)\n",
        "      df['Acceleration1'] = df['Speed'].diff().fillna(0)\n",
        "      df['Acceleration2'] = df['Speed'].diff().shift(-1).fillna(0)\n",
        "      df['Current_gear_shift_position_(Current_gear)'] = df['Current_gear_shift_position_(Current_gear)'].replace({13: 0, 14: 1})\n",
        "      # features = df[['Adjusted_gear_position', 'Speed', 'slope', 'Acceleration', 'Coolant_temperature']]\n",
        "\n",
        "\n",
        "      # df = df.iloc[:-5]\n",
        "\n",
        "\n",
        "      # features = df[['Acceleration1','Acceleration2','Throttle position','Accelerator pedal position','Coolant_temperature','Speed','Engine speed', 'Current_gear_shift_position_(Current_gear)','correct_altitude',  'slope']]\n",
        "      features = df[['Acceleration1','Acceleration2','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "      # features = df[['Acceleration1','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "\n",
        "\n",
        "      target = df['Momentary fuel consumption2']\n",
        "\n",
        "      if df['Average_fuel_consumption_rate'].isnull().any():\n",
        "            # If the column has null values, delete the file\n",
        "\n",
        "            return features, target , None\n",
        "\n",
        "      target2 = df['Average_fuel_consumption_rate']\n",
        "\n",
        "\n",
        "    return features, target , target2\n",
        "\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "\n",
        "    min_val_x = [-10,-10, 0,0, -10]\n",
        "    max_val_x = [10,10,200, 5, 10]\n",
        "\n",
        "    # min_val_x = [-10, 0,0, -10]\n",
        "    # max_val_x = [10,200, 5, 10]\n",
        "\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "\n",
        "    features, actual_values , rate  = process_file(input_file)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    df1 = pd.read_csv(input_file)\n",
        "\n",
        "    timee                 = (df1['time'].iloc[-1] - df1['time'].iloc[0]) / 60000\n",
        "    print(timee)\n",
        "    mileagee              = (df1['Cumulative_mileage'].iloc[-1] - df1['Cumulative_mileage'].iloc[0])\n",
        "    # mileagee = 11.01\n",
        "    if rate is not None:\n",
        "      total_cumsum = df1['Average_fuel_consumption_rate'].cumsum().iloc[-1]\n",
        "      trip_fuel_consp100    = ((total_cumsum / 10) / mileagee)\n",
        "    else :\n",
        "      trip_fuel_consp100    = (((df1['Trip_fuel_consumption'].iloc[-1] - df1['Trip_fuel_consumption'].iloc[0]) / 10000) / mileagee)\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values])\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * 1 )\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * 1 )\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "    # Calculate error metrics\n",
        "    # mae = mean_absolute_error(actual_valuess, predictions)\n",
        "    # mse = mean_squared_error(actual_valuess, predictions)\n",
        "\n",
        "    # Handling MAPE: Ignore zero actual values to avoid NaN issues\n",
        "    # non_zero_actual = actual_valuess != 0\n",
        "    # mape = np.mean(np.abs((actual_valuess[non_zero_actual] - predictions[non_zero_actual]) / actual_valuess[non_zero_actual])) * 100\n",
        "\n",
        "    # print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "    # print(f'MSE: {mse:.4f}')\n",
        "    # print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "\n",
        "\n",
        "    if rate is not None:\n",
        "      trip_fuel_consp100_p = np.cumsum(predictions[:len(actual_values)], axis=0)\n",
        "      trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10) / mileagee\n",
        "\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      plt.plot(np.cumsum(rate.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "      plt.plot(np.cumsum(predictions[:len(rate)], axis=0), label='Predicted', color='red')\n",
        "      plt.xlabel('Index')\n",
        "      plt.ylabel('Fuel Consumption')\n",
        "      plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "      plt.legend()\n",
        "      text = (\n",
        "          f\"time(M) : {timee:.0f} \\n\"\n",
        "          f\"mileage(KM) : {mileagee:.1f} \\n\"\n",
        "          f\"Real fuel cons: {trip_fuel_consp100:.2f} \\n\"\n",
        "          f\"Pred fuel cons: {trip_fuel_cons_predicted_p100:.2f} \\n\"\n",
        "          f\"Error(%) : {((abs(trip_fuel_consp100 -trip_fuel_cons_predicted_p100 ))/trip_fuel_consp100)*100:.2f}\"\n",
        "      )\n",
        "      plt.text(\n",
        "          0.95, 0.05,  # x and y position in figure coordinates\n",
        "          text,  # Multi-line text\n",
        "          fontsize=10,\n",
        "          color='gray',\n",
        "          horizontalalignment='right',\n",
        "          verticalalignment='bottom',\n",
        "          transform=plt.gca().transAxes  # Use axes coordinates\n",
        "      )\n",
        "      # Create model-specific directory\n",
        "      model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "      os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "      # Save plot using model name in the designated directory\n",
        "      plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "      plt.savefig(plot_filename)\n",
        "      plt.close()\n",
        "\n",
        "    else:\n",
        "      trip_fuel_consp100_p = np.cumsum(predictions[:len(actual_values)], axis=0)\n",
        "      trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10) / mileagee\n",
        "\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "      plt.plot(np.cumsum(predictions[:len(actual_values)]*1000, axis=0), label='Predicted', color='red')\n",
        "      plt.xlabel('Index')\n",
        "      plt.ylabel('Fuel Consumption')\n",
        "      plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "      plt.legend()\n",
        "\n",
        "      text = (\n",
        "          f\"time(M) : {timee:.0f} \\n\"\n",
        "          f\"mileage(KM) : {mileagee:.1f} \\n\"\n",
        "          f\"Real fuel cons: {trip_fuel_consp100:.2f} \\n\"\n",
        "          f\"Pred fuel cons: {trip_fuel_cons_predicted_p100:.2f} \\n\"\n",
        "          f\"Error(%) : {((abs(trip_fuel_consp100 -trip_fuel_cons_predicted_p100 ))/trip_fuel_consp100)*100:.2f}\"\n",
        "      )\n",
        "      plt.text(\n",
        "          0.95, 0.05,  # x and y position in figure coordinates\n",
        "          text,  # Multi-line text\n",
        "          fontsize=10,\n",
        "          color='gray',\n",
        "          horizontalalignment='right',\n",
        "          verticalalignment='bottom',\n",
        "          transform=plt.gca().transAxes  # Use axes coordinates\n",
        "      )\n",
        "\n",
        "      # Create model-specific directory\n",
        "      model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "      os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "      # Save plot using model name in the designated directory\n",
        "      plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "      plt.savefig(plot_filename)\n",
        "      plt.close()\n",
        "\n",
        "    if rate is not None:\n",
        "      # Save predictions and actual values to CSV using model name in the designated directory\n",
        "      results_df = pd.DataFrame({\n",
        "          'Speed': features[\"Speed\"].iloc[:len(predictions)],\n",
        "          'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "          'Predicted_sum': np.cumsum(predictions[:len(actual_values)], axis=0),\n",
        "          'Predicted': predictions[:len(actual_values)] ,\n",
        "          'rate' : rate[:len(actual_values)]\n",
        "          # 'MAE': mae,  # Add MAE to the dataframe\n",
        "          # 'MSE': mse,  # Add MSE to the dataframe\n",
        "\n",
        "      })\n",
        "    else :\n",
        "      results_df = pd.DataFrame({\n",
        "          'Speed': features[\"Speed\"].iloc[:len(predictions)],\n",
        "          'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "          'Predicted_sum': np.cumsum(predictions[:len(actual_values)], axis=0),\n",
        "          'Predicted': predictions[:len(actual_values)] ,\n",
        "          'rate' : rate\n",
        "          # 'MAE': mae,  # Add MAE to the dataframe\n",
        "          # 'MSE': mse,  # Add MSE to the dataframe\n",
        "\n",
        "      })\n",
        "\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "\n",
        "\n",
        "\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content'  # Directory containing CSV files\n",
        "model_dir = '/content/'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "# input_size = 4  # Number of features in the input data\n",
        "\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"0Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rate new acc"
      ],
      "metadata": {
        "id": "aFHfAvpk6pGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 200  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "\n",
        "\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    if not df.empty :\n",
        "      df.rename(columns={\n",
        "          'Engine_speed': 'Engine speed',\n",
        "          'time': 'Time',\n",
        "          'Vehicle_Speed': 'Speed',\n",
        "          'Trip_fuel_consumption': 'Trip fuel consumption',\n",
        "          'Throttle_position': 'Throttle position',\n",
        "          'Accelerator_pedal_position': 'Accelerator pedal position',\n",
        "          'Cumulative_mileage': 'Cumulative mileage',\n",
        "          'Coolant_temp': 'Coolant_temperature'\n",
        "      }, inplace=True)\n",
        "      df['Time'] = df['Time'] - df['Time'].iloc[0]\n",
        "      df['Momentary fuel consumption1'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "      df['Momentary fuel consumption2'] = df['Trip fuel consumption'].diff().shift(-1).fillna(0)\n",
        "      df['Acceleration1'] = df['Speed'].diff().fillna(0)\n",
        "      df['Acceleration2'] = df['Speed'].diff().shift(-1).fillna(0)\n",
        "      df['Current_gear_shift_position_(Current_gear)'] = df['Current_gear_shift_position_(Current_gear)'].replace({13: 0, 14: 1})\n",
        "      # features = df[['Adjusted_gear_position', 'Speed', 'slope', 'Acceleration', 'Coolant_temperature']]\n",
        "\n",
        "\n",
        "      # df = df.iloc[:-20]\n",
        "      df['acc1'] = df['Speed'].diff().fillna(0)\n",
        "\n",
        "      df['acc21'] = df['Speed'].diff().shift(-1).fillna(0)\n",
        "      df['acc22'] = df['Speed'].diff().shift(-2).fillna(0)\n",
        "      df['acc23'] = df['Speed'].diff().shift(-3).fillna(0)\n",
        "      df['acc24'] = df['Speed'].diff().shift(-4).fillna(0)\n",
        "\n",
        "\n",
        "      df['acc31'] = df['Speed'].diff().shift(1).fillna(0)\n",
        "      df['acc32'] = df['Speed'].diff().shift(2).fillna(0)\n",
        "      df['acc33'] = df['Speed'].diff().shift(3).fillna(0)\n",
        "      df['acc34'] = df['Speed'].diff().shift(4).fillna(0)\n",
        "\n",
        "      df = df.iloc[:-5]\n",
        "\n",
        "\n",
        "      features = df[['acc1','acc21','acc22','acc23','acc24','acc31','acc32','acc33','acc34','Speed', 'Current_gear_shift_position_(Current_gear)', 'slope']]\n",
        "\n",
        "\n",
        "      features = df[['acc1','acc21','acc31','Speed', 'Current_gear_shift_position_(Current_gear)', 'slope']]\n",
        "\n",
        "      # features = df[['Acceleration1','Acceleration2','Throttle position','Accelerator pedal position','Coolant_temperature','Speed','Engine speed', 'Current_gear_shift_position_(Current_gear)','correct_altitude',  'slope']]\n",
        "      # features = df[['Acceleration1','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "\n",
        "\n",
        "      target = df['Momentary fuel consumption2']\n",
        "\n",
        "      if df['Average_fuel_consumption_rate'].isnull().any():\n",
        "            # If the column has null values, delete the file\n",
        "\n",
        "            return features, target , None\n",
        "\n",
        "      target2 = df['Average_fuel_consumption_rate']\n",
        "\n",
        "\n",
        "    return features, target , target2\n",
        "\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "\n",
        "    min_val_x = [-10,-10, 0,0, -10]\n",
        "    max_val_x = [10,10,200, 5, 10]\n",
        "\n",
        "    # min_val_x = [-10,-10,-10,-10,-10,-10,-10,-10,-10, 0,   0 , -10]\n",
        "    # max_val_x = [ 10, 10, 10, 10, 10, 10, 10, 10, 10, 200, 5 , 10]\n",
        "\n",
        "    # min_val_x = [-10,-10,-10, 0,   0 , -10]\n",
        "    # max_val_x = [ 10, 10, 10, 200, 5 , 10]\n",
        "    # min_val_x = [-10, 0,0, -10]\n",
        "    # max_val_x = [10,200, 5, 10]\n",
        "\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "\n",
        "    features, actual_values , rate  = process_file(input_file)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    df1 = pd.read_csv(input_file)\n",
        "\n",
        "    timee                 = (df1['time'].iloc[-1] - df1['time'].iloc[0]) / 60000\n",
        "    print(timee)\n",
        "    mileagee              = (df1['Cumulative_mileage'].iloc[-1] - df1['Cumulative_mileage'].iloc[0])\n",
        "\n",
        "    if rate is not None:\n",
        "      total_cumsum = df1['Average_fuel_consumption_rate'].cumsum().iloc[-1]\n",
        "      trip_fuel_consp100    = ((total_cumsum / 10) / mileagee)\n",
        "    else :\n",
        "      trip_fuel_consp100    = (((df1['Trip_fuel_consumption'].iloc[-1] - df1['Trip_fuel_consumption'].iloc[0]) / 10000) / mileagee)\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values])\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * 1 )\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * 1 )\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "    # Calculate error metrics\n",
        "    # mae = mean_absolute_error(actual_valuess, predictions)\n",
        "    # mse = mean_squared_error(actual_valuess, predictions)\n",
        "\n",
        "    # Handling MAPE: Ignore zero actual values to avoid NaN issues\n",
        "    # non_zero_actual = actual_valuess != 0\n",
        "    # mape = np.mean(np.abs((actual_valuess[non_zero_actual] - predictions[non_zero_actual]) / actual_valuess[non_zero_actual])) * 100\n",
        "\n",
        "    # print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "    # print(f'MSE: {mse:.4f}')\n",
        "    # print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "\n",
        "\n",
        "    if rate is not None:\n",
        "      trip_fuel_consp100_p = np.cumsum(predictions[:len(actual_values)], axis=0)\n",
        "      trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10) / mileagee\n",
        "\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      plt.plot(np.cumsum(rate.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "      plt.plot(np.cumsum(predictions[:len(rate)], axis=0), label='Predicted', color='red')\n",
        "      plt.xlabel('Index')\n",
        "      plt.ylabel('Fuel Consumption')\n",
        "      plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "      plt.legend()\n",
        "      text = (\n",
        "          f\"time(M) : {timee:.0f} \\n\"\n",
        "          f\"mileage(KM) : {mileagee:.1f} \\n\"\n",
        "          f\"Real fuel cons: {trip_fuel_consp100:.2f} \\n\"\n",
        "          f\"Pred fuel cons: {trip_fuel_cons_predicted_p100:.2f} \\n\"\n",
        "          f\"Error(%) : {((abs(trip_fuel_consp100 -trip_fuel_cons_predicted_p100 ))/trip_fuel_consp100)*100:.2f}\"\n",
        "      )\n",
        "      plt.text(\n",
        "          0.95, 0.05,  # x and y position in figure coordinates\n",
        "          text,  # Multi-line text\n",
        "          fontsize=10,\n",
        "          color='gray',\n",
        "          horizontalalignment='right',\n",
        "          verticalalignment='bottom',\n",
        "          transform=plt.gca().transAxes  # Use axes coordinates\n",
        "      )\n",
        "      # Create model-specific directory\n",
        "      model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "      os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "      # Save plot using model name in the designated directory\n",
        "      plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "      plt.savefig(plot_filename)\n",
        "      plt.close()\n",
        "\n",
        "    else:\n",
        "      trip_fuel_consp100_p = np.cumsum(predictions[:len(actual_values)], axis=0)\n",
        "      trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10) / mileagee\n",
        "\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "      plt.plot(np.cumsum(predictions[:len(actual_values)]*1000, axis=0), label='Predicted', color='red')\n",
        "      plt.xlabel('Index')\n",
        "      plt.ylabel('Fuel Consumption')\n",
        "      plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "      plt.legend()\n",
        "\n",
        "      text = (\n",
        "          f\"time(M) : {timee:.0f} \\n\"\n",
        "          f\"mileage(KM) : {mileagee:.1f} \\n\"\n",
        "          f\"Real fuel cons: {trip_fuel_consp100:.2f} \\n\"\n",
        "          f\"Pred fuel cons: {trip_fuel_cons_predicted_p100:.2f} \\n\"\n",
        "          f\"Error(%) : {((abs(trip_fuel_consp100 -trip_fuel_cons_predicted_p100 ))/trip_fuel_consp100)*100:.2f}\"\n",
        "      )\n",
        "      plt.text(\n",
        "          0.95, 0.05,  # x and y position in figure coordinates\n",
        "          text,  # Multi-line text\n",
        "          fontsize=10,\n",
        "          color='gray',\n",
        "          horizontalalignment='right',\n",
        "          verticalalignment='bottom',\n",
        "          transform=plt.gca().transAxes  # Use axes coordinates\n",
        "      )\n",
        "\n",
        "      # Create model-specific directory\n",
        "      model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "      os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "      # Save plot using model name in the designated directory\n",
        "      plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "      plt.savefig(plot_filename)\n",
        "      plt.close()\n",
        "\n",
        "    if rate is not None:\n",
        "      # Save predictions and actual values to CSV using model name in the designated directory\n",
        "      results_df = pd.DataFrame({\n",
        "          'Speed': features[\"Speed\"].iloc[:len(predictions)],\n",
        "          'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "          'Predicted_sum': np.cumsum(predictions[:len(actual_values)], axis=0),\n",
        "          'Predicted': predictions[:len(actual_values)] ,\n",
        "          'rate' : rate[:len(actual_values)]\n",
        "          # 'MAE': mae,  # Add MAE to the dataframe\n",
        "          # 'MSE': mse,  # Add MSE to the dataframe\n",
        "\n",
        "      })\n",
        "    else :\n",
        "      results_df = pd.DataFrame({\n",
        "          'Speed': features[\"Speed\"].iloc[:len(predictions)],\n",
        "          'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "          'Predicted_sum': np.cumsum(predictions[:len(actual_values)], axis=0),\n",
        "          'Predicted': predictions[:len(actual_values)] ,\n",
        "          'rate' : rate\n",
        "          # 'MAE': mae,  # Add MAE to the dataframe\n",
        "          # 'MSE': mse,  # Add MSE to the dataframe\n",
        "\n",
        "      })\n",
        "\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "\n",
        "\n",
        "\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content'  # Directory containing CSV files\n",
        "model_dir = '/content/'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "# input_size = 4  # Number of features in the input data\n",
        "\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"0Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "iaT0H5ds6o8g",
        "outputId": "e15ad0a3-0d80-497b-f9a5-537a47b7a359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4ddf0d849732>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['correct_altitude'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4ddf0d849732>\u001b[0m in \u001b[0;36m<cell line: 297>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mplot_predicted_vs_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4ddf0d849732>\u001b[0m in \u001b[0;36mplot_predicted_vs_real\u001b[0;34m(input_file, model, model_name)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_predicted_vs_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_values\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0mnum_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4ddf0d849732>\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'acc21'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'acc31'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Speed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Current_gear_shift_position_(Current_gear)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'slope'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Acceleration1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Acceleration2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Throttle position'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Accelerator pedal position'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Coolant_temperature'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Speed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Engine speed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Current_gear_shift_position_(Current_gear)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'correct_altitude'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'slope'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m       \u001b[0;31m# features = df[['Acceleration1','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['correct_altitude'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs3MzorIVZjb",
        "outputId": "ec1f8e69-e2a0-4a02-b3e5-c23b4deca325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predicted_vs_actual_plots/ (stored 0%)\n",
            "  adding: predicted_vs_actual_plots/best_con_matt.pth (deflated 8%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/ (stored 0%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_47_all.png (deflated 10%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_4 (1).csv (deflated 60%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_49.csv (deflated 57%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_50_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_112.csv (deflated 62%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_4 (1)_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_115_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_49_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_6.csv (deflated 59%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_48.csv (deflated 62%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_50.csv (deflated 62%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_46.csv (deflated 58%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_112_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/Real_NEDC_testroom.csv (deflated 60%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_115.csv (deflated 61%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_6_all.png (deflated 10%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_48_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_3 (1).csv (deflated 59%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/Real_NEDC_testroom_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_3 (1)_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_47.csv (deflated 60%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att/trip_46_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_self_att.pth (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/ (stored 0%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_47_all.png (deflated 10%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_4 (1).csv (deflated 60%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_49.csv (deflated 57%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_50_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_112.csv (deflated 62%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_4 (1)_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_115_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_49_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_6.csv (deflated 59%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_48.csv (deflated 63%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_50.csv (deflated 63%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_46.csv (deflated 59%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_112_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/Real_NEDC_testroom.csv (deflated 60%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_115.csv (deflated 62%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_6_all.png (deflated 10%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_48_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_3 (1).csv (deflated 59%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/Real_NEDC_testroom_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_3 (1)_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_47.csv (deflated 61%)\n",
            "  adding: predicted_vs_actual_plots/best_consatt/trip_46_all.png (deflated 9%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r predicted_vs_actual_plots.zip predicted_vs_actual_plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_RbJrMiP7Ih"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtj56jZxoe-n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Di5BXgUofdY"
      },
      "source": [
        "# **`NEDC Trip cons`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgfTW0Gnob9i",
        "outputId": "671c9d4e-1f79-4ac9-8d46-77d4e3eafad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-8862d037e2aa>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/513_200_3slices_rate_farda_/NEDC_xup.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-8862d037e2aa>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-8862d037e2aa>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error\n",
            "error\n",
            "error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-8862d037e2aa>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-41-8862d037e2aa>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 200  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "\n",
        "\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    if not df.empty :\n",
        "      df.rename(columns={\n",
        "          'Engine_speed': 'Engine speed',\n",
        "          'time': 'Time',\n",
        "          'Vehicle_Speed': 'Speed'\n",
        "      }, inplace=True)\n",
        "\n",
        "      df['Time'] = df['Time'] - df['Time'].iloc[0]\n",
        "      df['Acceleration1'] = df['Speed'].diff().fillna(0)\n",
        "      df['Acceleration2'] = df['Speed'].diff().shift(-1).fillna(0)\n",
        "      df['Current_gear_shift_position_(Current_gear)'] = df['Current_gear_shift_position_(Current_gear)'].replace({13: 0, 14: 1})\n",
        "      # features = df[['Adjusted_gear_position', 'Speed', 'slope', 'Acceleration', 'Coolant_temperature']]\n",
        "\n",
        "\n",
        "      # df = df.iloc[:-20]\n",
        "\n",
        "\n",
        "      # features = df[['Acceleration1','Acceleration2','Throttle position','Accelerator pedal position','Coolant_temperature','Speed','Engine speed', 'Current_gear_shift_position_(Current_gear)','correct_altitude',  'slope']]\n",
        "      features = df[['Acceleration1','Acceleration2','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "      # features = df[['Acceleration1','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # target = df['Momentary fuel consumption2']\n",
        "\n",
        "\n",
        "\n",
        "    return features, None\n",
        "\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "\n",
        "    min_val_x = [-10,-10, 0,0, -10]\n",
        "    max_val_x = [10,10,200, 5, 10]\n",
        "\n",
        "    # min_val_x = [-10, 0,0, -10]\n",
        "    # max_val_x = [10,200, 5, 10]\n",
        "\n",
        "\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "  try :\n",
        "      df1 = pd.read_csv(input_file)\n",
        "\n",
        "      timee                 = (df1['time'].iloc[-1] - df1['time'].iloc[0]) / 60000\n",
        "      # mileagee              = (df1['Cumulative_mileage'].iloc[-1] - df1['Cumulative_mileage'].iloc[0])\n",
        "      # trip_fuel_consp100    = (((df1['Trip_fuel_consumption'].iloc[-1] - df1['Trip_fuel_consumption'].iloc[0]) / 10000) / mileagee)\n",
        "      mileagee  = 11.175\n",
        "      features, actual_values  = process_file(input_file)\n",
        "      rate = actual_values\n",
        "      num_segments = len(features) // SEQUENCE_LENGTH\n",
        "      predictions = []\n",
        "\n",
        "      for i in range(num_segments):\n",
        "          segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "          segment_normalized = pad_and_normalize([segment.values])\n",
        "          with torch.no_grad():\n",
        "              segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "          # predictions.extend(segment_predictions.flatten() * 30000 )\n",
        "          predictions.extend(segment_predictions.flatten()  )\n",
        "\n",
        "\n",
        "      # Handle any remaining data\n",
        "      remainder = len(features) % SEQUENCE_LENGTH\n",
        "      if remainder != 0:\n",
        "          last_segment = features.iloc[-remainder:]\n",
        "          last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "          with torch.no_grad():\n",
        "              last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "          # predictions.extend(last_segment_predictions.flatten() * 30000 )\n",
        "          predictions.extend(last_segment_predictions.flatten() )\n",
        "\n",
        "\n",
        "      predictions = np.array(predictions)\n",
        "      # actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "      trip_fuel_consp100_p = np.cumsum(predictions[:len(predictions)], axis=0)\n",
        "      # trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10000) / 23.26\n",
        "      trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10) / mileagee\n",
        "\n",
        "\n",
        "      # Calculate error metrics\n",
        "      # mae = mean_absolute_error(actual_valuess, predictions)\n",
        "      # mse = mean_squared_error(actual_valuess, predictions)\n",
        "\n",
        "      # Handling MAPE: Ignore zero actual values to avoid NaN issues\n",
        "      # non_zero_actual = actual_valuess != 0\n",
        "      # mape = np.mean(np.abs((actual_valuess[non_zero_actual] - predictions[non_zero_actual]) / actual_valuess[non_zero_actual])) * 100\n",
        "\n",
        "      # print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "      # print(f'MSE: {mse:.4f}')\n",
        "      # print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      # plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "      plt.plot(np.cumsum(predictions[:len(predictions)], axis=0), label='Predicted', color='red')\n",
        "      plt.xlabel('Index')\n",
        "      plt.ylabel('Fuel Consumption')\n",
        "      plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "      plt.legend()\n",
        "\n",
        "\n",
        "      text = (\n",
        "            f\"time(M) : {timee:.0f} \\n\"\n",
        "            f\"mileage(KM) : {mileagee} \\n\"\n",
        "            f\"Pred fuel cons: {trip_fuel_cons_predicted_p100:.2f} \\n\"\n",
        "        )\n",
        "\n",
        "      plt.text(\n",
        "          0.95, 0.05,  # x and y position in figure coordinates\n",
        "          text,  # Multi-line text\n",
        "          fontsize=10,\n",
        "          color='gray',\n",
        "          horizontalalignment='right',\n",
        "          verticalalignment='bottom',\n",
        "          transform=plt.gca().transAxes  # Use axes coordinates\n",
        "      )\n",
        "\n",
        "      # Create model-specific directory\n",
        "      model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "      os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "      # Save plot using model name in the designated directory\n",
        "      plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "      plt.savefig(plot_filename)\n",
        "      plt.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      results_df = pd.DataFrame({\n",
        "          'Speed': features[\"Speed\"].iloc[:len(predictions)],\n",
        "          'gear' : features[\"Current_gear_shift_position_(Current_gear)\"].iloc[:len(predictions)],\n",
        "          'Predicted_sum': np.cumsum(predictions[:len(predictions)], axis=0),\n",
        "          'Predicted': predictions[:len(predictions)]\n",
        "\n",
        "      })\n",
        "\n",
        "      csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "      results_df.to_csv(csv_filename, index=False)\n",
        "      print(f\"CSV saved as: {csv_filename}\")\n",
        "  except :\n",
        "      print('error')\n",
        "\n",
        "\n",
        "\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content/sample_data'  # Directory containing CSV files\n",
        "model_dir = '/content'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "# input_size = 4  # Number of features in the input data\n",
        "\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"0Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Offline Data\n"
      ],
      "metadata": {
        "id": "zdYQ03nfGs9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 200  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "\n",
        "\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    if not df.empty :\n",
        "      df.rename(columns={\n",
        "          'Engine_speed': 'Engine speed',\n",
        "          'time': 'Time',\n",
        "          'Vehicle_Speed': 'Speed'\n",
        "      }, inplace=True)\n",
        "\n",
        "      df['Time'] = df['Time'] - df['Time'].iloc[0]\n",
        "      df['Acceleration1'] = df['Speed'].diff().fillna(0)\n",
        "      df['Acceleration2'] = df['Speed'].diff().shift(-1).fillna(0)\n",
        "      df['Current_gear_shift_position_(Current_gear)'] = df['Current_gear_shift_position_(Current_gear)'].replace({13: 0, 14: 1})\n",
        "      # features = df[['Adjusted_gear_position', 'Speed', 'slope', 'Acceleration', 'Coolant_temperature']]\n",
        "\n",
        "\n",
        "      # df = df.iloc[:-20]\n",
        "\n",
        "\n",
        "      # features = df[['Acceleration1','Acceleration2','Throttle position','Accelerator pedal position','Coolant_temperature','Speed','Engine speed', 'Current_gear_shift_position_(Current_gear)','correct_altitude',  'slope']]\n",
        "      features = df[['Acceleration1','Acceleration2','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "      # features = df[['Acceleration1','Speed', 'Current_gear_shift_position_(Current_gear)','slope']]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # target = df['Momentary fuel consumption2']\n",
        "\n",
        "\n",
        "\n",
        "    return features, None\n",
        "\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "\n",
        "    min_val_x = [-10,-10, 0,0, -10]\n",
        "    max_val_x = [10,10,200, 5, 10]\n",
        "\n",
        "    # min_val_x = [-10, 0,0, -10]\n",
        "    # max_val_x = [10,200, 5, 10]\n",
        "\n",
        "\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "  try :\n",
        "      df1 = pd.read_csv(input_file)\n",
        "\n",
        "      timee                 = (df1['time'].iloc[-1] - df1['time'].iloc[0]) / 60000\n",
        "      mileagee              = (df1['Cumulative_mileage'].iloc[-1] - df1['Cumulative_mileage'].iloc[0])\n",
        "      # trip_fuel_consp100    = (((df1['Trip_fuel_consumption'].iloc[-1] - df1['Trip_fuel_consumption'].iloc[0]) / 10000) / mileagee)\n",
        "      # mileagee  = 11.175\n",
        "      features, actual_values  = process_file(input_file)\n",
        "      rate = actual_values\n",
        "      num_segments = len(features) // SEQUENCE_LENGTH\n",
        "      predictions = []\n",
        "\n",
        "      for i in range(num_segments):\n",
        "          segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "          segment_normalized = pad_and_normalize([segment.values])\n",
        "          with torch.no_grad():\n",
        "              segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "          # predictions.extend(segment_predictions.flatten() * 30000 )\n",
        "          predictions.extend(segment_predictions.flatten()  )\n",
        "\n",
        "\n",
        "      # Handle any remaining data\n",
        "      remainder = len(features) % SEQUENCE_LENGTH\n",
        "      if remainder != 0:\n",
        "          last_segment = features.iloc[-remainder:]\n",
        "          last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "          with torch.no_grad():\n",
        "              last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "          # predictions.extend(last_segment_predictions.flatten() * 30000 )\n",
        "          predictions.extend(last_segment_predictions.flatten() )\n",
        "\n",
        "\n",
        "      predictions = np.array(predictions)\n",
        "      # actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "      trip_fuel_consp100_p = np.cumsum(predictions[:len(predictions)], axis=0)\n",
        "      # trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10000) / 23.26\n",
        "      trip_fuel_cons_predicted_p100 = (trip_fuel_consp100_p[-1] /10) / mileagee\n",
        "\n",
        "\n",
        "      # Calculate error metrics\n",
        "      # mae = mean_absolute_error(actual_valuess, predictions)\n",
        "      # mse = mean_squared_error(actual_valuess, predictions)\n",
        "\n",
        "      # Handling MAPE: Ignore zero actual values to avoid NaN issues\n",
        "      # non_zero_actual = actual_valuess != 0\n",
        "      # mape = np.mean(np.abs((actual_valuess[non_zero_actual] - predictions[non_zero_actual]) / actual_valuess[non_zero_actual])) * 100\n",
        "\n",
        "      # print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "      # print(f'MSE: {mse:.4f}')\n",
        "      # print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      # plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "      plt.plot(np.cumsum(predictions[:len(predictions)], axis=0), label='Predicted', color='red')\n",
        "      plt.xlabel('Index')\n",
        "      plt.ylabel('Fuel Consumption')\n",
        "      plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "      plt.legend()\n",
        "\n",
        "\n",
        "      text = (\n",
        "            f\"time(M) : {timee:.0f} \\n\"\n",
        "            f\"mileage(KM) : {mileagee} \\n\"\n",
        "            f\"Pred fuel cons: {trip_fuel_cons_predicted_p100:.2f} \\n\"\n",
        "        )\n",
        "\n",
        "      plt.text(\n",
        "          0.95, 0.05,  # x and y position in figure coordinates\n",
        "          text,  # Multi-line text\n",
        "          fontsize=10,\n",
        "          color='gray',\n",
        "          horizontalalignment='right',\n",
        "          verticalalignment='bottom',\n",
        "          transform=plt.gca().transAxes  # Use axes coordinates\n",
        "      )\n",
        "\n",
        "      # Create model-specific directory\n",
        "      model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "      os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "      # Save plot using model name in the designated directory\n",
        "      plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "      plt.savefig(plot_filename)\n",
        "      plt.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      results_df = pd.DataFrame({\n",
        "          'Speed': features[\"Speed\"].iloc[:len(predictions)],\n",
        "          'gear' : features[\"Current_gear_shift_position_(Current_gear)\"].iloc[:len(predictions)],\n",
        "          'Predicted_sum': np.cumsum(predictions[:len(predictions)], axis=0),\n",
        "          'Predicted': predictions[:len(predictions)]\n",
        "\n",
        "      })\n",
        "\n",
        "      csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "      results_df.to_csv(csv_filename, index=False)\n",
        "      print(f\"CSV saved as: {csv_filename}\")\n",
        "  except :\n",
        "      print('error')\n",
        "\n",
        "\n",
        "\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content/'  # Directory containing CSV files\n",
        "model_dir = '/content/'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "# input_size = 4  # Number of features in the input data\n",
        "\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"0Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3pf-NvPGsdK",
        "outputId": "123fbc35-15e9-42f8-a1d7-954c15d2419e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-60d37f4d11c5>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/513_model_2slices_tripcons/MyCar_LOG_2023-06-25_11-17-43_refined.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-60d37f4d11c5>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/513_model_2slices_tripcons/MyCar_LOG_2023-06-27_14-34-39_refined.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "k7M2r7PuQASF",
        "rGvLDIFEo3yV",
        "o9D0YvUOqw2D"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}