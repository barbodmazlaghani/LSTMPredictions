{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X_RQgrvEbkfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eef95dc-9f8a-4c52-f407-7695089a795b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3PDshfYSS1BB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from multiprocessing import Pool\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import joblib\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from multiprocessing import Pool\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import joblib\n",
        "\n",
        "SEQUENCE_LENGTH = 600\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 250\n",
        "LEARNING_RATE = 1e-5\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2VsgPt5JVSs"
      },
      "source": [
        "#Load file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HzRBHKopJXR7"
      },
      "outputs": [],
      "source": [
        "# Loading from npz file\n",
        "data = np.load('/content/gdrive/MyDrive/new_aug_qani_data600.npz')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_original = data['X_original']\n",
        "y_original = data['y_original']\n",
        "X_augmented = data['X_augmented']\n",
        "y_augmented = data['y_augmented']"
      ],
      "metadata": {
        "id": "MCYDVO9rdUBw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_augmented"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9tIfvSFQVHc",
        "outputId": "e15b7aee-caa2-4961-b49e-7b8e1c267058"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.00000000e+00,  0.00000000e+00, -6.75675676e-02,\n",
              "          0.00000000e+00,  9.60000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00, -6.75675676e-02,\n",
              "          0.00000000e+00,  9.60000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00, -6.75675676e-02,\n",
              "          0.00000000e+00,  9.60000000e+01],\n",
              "        ...,\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  8.90000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.00000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.00000000e+01]],\n",
              "\n",
              "       [[ 0.00000000e+00,  0.00000000e+00,  1.06382979e+00,\n",
              "          0.00000000e+00,  4.60000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  1.06382979e+00,\n",
              "          0.00000000e+00,  4.60000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  1.06382979e+00,\n",
              "          0.00000000e+00,  4.60000000e+01],\n",
              "        ...,\n",
              "        [ 1.00000000e+00,  1.50000000e+01, -1.15015974e+00,\n",
              "          1.00000000e+00,  8.20000000e+01],\n",
              "        [ 1.00000000e+00,  1.50000000e+01, -1.15015974e+00,\n",
              "          0.00000000e+00,  8.10000000e+01],\n",
              "        [ 1.00000000e+00,  1.70000000e+01,  0.00000000e+00,\n",
              "          2.00000000e+00,  8.10000000e+01]],\n",
              "\n",
              "       [[ 0.00000000e+00,  0.00000000e+00,  3.29268293e+00,\n",
              "          0.00000000e+00,  8.40000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  3.29268293e+00,\n",
              "          0.00000000e+00,  8.30000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  3.29268293e+00,\n",
              "          0.00000000e+00,  8.40000000e+01],\n",
              "        ...,\n",
              "        [ 4.00000000e+00,  7.10000000e+01,  7.02598653e-01,\n",
              "          0.00000000e+00,  8.40000000e+01],\n",
              "        [ 4.00000000e+00,  7.10000000e+01,  7.02598653e-01,\n",
              "          0.00000000e+00,  8.40000000e+01],\n",
              "        [ 4.00000000e+00,  6.90000000e+01,  7.02598653e-01,\n",
              "         -2.00000000e+00,  8.40000000e+01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.10000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.10000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.10000000e+01],\n",
              "        ...,\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.20000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.20000000e+01]],\n",
              "\n",
              "       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.20000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.20000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.20000000e+01],\n",
              "        ...,\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01]],\n",
              "\n",
              "       [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01],\n",
              "        ...,\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01],\n",
              "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  9.30000000e+01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_augmented[:, :, -1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tMzXR7SQbXU",
        "outputId": "2b5320e3-3dd0-4412-8763-2030d191d1dd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last = X_augmented[:, :, -1]\n",
        "mapped = np.where(last>75,0,1)\n",
        "X_augmented[:, :, -1] = mapped"
      ],
      "metadata": {
        "id": "ZgD_4JLjQaWM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eTGExYs0enuV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert data to PyTorch tensors\n",
        "try:\n",
        "    X_original = torch.tensor(np.array(X_original), dtype=torch.float32).to(DEVICE)\n",
        "    y_original = torch.tensor(np.array(y_original), dtype=torch.float32).to(DEVICE)\n",
        "    X_augmented = torch.tensor(np.array(X_augmented), dtype=torch.float32).to(DEVICE)\n",
        "    y_augmented = torch.tensor(np.array(y_augmented), dtype=torch.float32).to(DEVICE)\n",
        "except Exception as e:\n",
        "    print(f\"Error during tensor conversion: {e}\")\n",
        "    print(f\"Shapes: X_original - {np.array(X_original).shape}, y_original - {np.array(y_original).shape}\")\n",
        "    print(f\"Shapes: X_augmented - {np.array(X_augmented).shape}, y_augmented - {np.array(y_augmented).shape}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DN9TrizAeqPk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split into training and test sets\n",
        "# num_test = int(0.2 * len(X_original))\n",
        "# X_test = X_original[:num_test]\n",
        "# y_test = y_original[:num_test]\n",
        "# X_train = torch.cat([X_original[num_test:], X_augmented])\n",
        "# y_train = torch.cat([y_original[num_test:], y_augmented])\n",
        "\n",
        "\n",
        "X_train = torch.cat([X_original, X_augmented])\n",
        "y_train = torch.cat([y_original, y_augmented])\n",
        "# X_train = X_original[num_test:]\n",
        "# y_train = y_original[num_test:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVRyCkvZ3Zi-",
        "outputId": "5f15657c-d888-4df9-fe36-6a8ed22a9ede"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000e+00,  0.0000e+00, -6.7568e-02,  0.0000e+00,  9.6000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00, -6.7568e-02,  0.0000e+00,  9.6000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00, -6.7568e-02,  0.0000e+00,  9.6000e+01],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  8.9000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0000e+01]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  1.0638e+00,  0.0000e+00,  4.6000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  1.0638e+00,  0.0000e+00,  4.6000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  1.0638e+00,  0.0000e+00,  4.6000e+01],\n",
              "         ...,\n",
              "         [ 1.0000e+00,  1.5000e+01, -1.1502e+00,  1.0000e+00,  8.2000e+01],\n",
              "         [ 1.0000e+00,  1.5000e+01, -1.1502e+00,  0.0000e+00,  8.1000e+01],\n",
              "         [ 1.0000e+00,  1.7000e+01,  0.0000e+00,  2.0000e+00,  8.1000e+01]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  3.2927e+00,  0.0000e+00,  8.4000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  3.2927e+00,  0.0000e+00,  8.3000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  3.2927e+00,  0.0000e+00,  8.4000e+01],\n",
              "         ...,\n",
              "         [ 4.0000e+00,  7.1000e+01,  7.0260e-01,  0.0000e+00,  8.4000e+01],\n",
              "         [ 4.0000e+00,  7.1000e+01,  7.0260e-01,  0.0000e+00,  8.4000e+01],\n",
              "         [ 4.0000e+00,  6.9000e+01,  7.0260e-01, -2.0000e+00,  8.4000e+01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.1000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.1000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.1000e+01],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.2000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.2000e+01]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.2000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.2000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.2000e+01],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3000e+01]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell for delete coolant temp from data\n",
        "X_train = X_train[:, :, -1]  # Slicing to exclude the last column\n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9egpbQy6dEtA",
        "outputId": "34499669-f160-442e-a2cf-0fdad58543f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000e+00,  0.0000e+00, -6.7568e-02,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00, -6.7568e-02,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00, -6.7568e-02,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  1.0638e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  1.0638e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  1.0638e+00,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 1.0000e+00,  1.5000e+01, -1.1502e+00,  1.0000e+00],\n",
              "         [ 1.0000e+00,  1.5000e+01, -1.1502e+00,  0.0000e+00],\n",
              "         [ 1.0000e+00,  1.7000e+01,  0.0000e+00,  2.0000e+00]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  3.2927e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  3.2927e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  3.2927e+00,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 4.0000e+00,  7.1000e+01,  7.0260e-01,  0.0000e+00],\n",
              "         [ 4.0000e+00,  7.1000e+01,  7.0260e-01,  0.0000e+00],\n",
              "         [ 4.0000e+00,  6.9000e+01,  7.0260e-01, -2.0000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
              "\n",
              "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         ...,\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1 = X_train.clone()\n",
        "y_train1 = y_train.clone()"
      ],
      "metadata": {
        "id": "ztY69wlpRa10"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if X_train1.is_cuda:\n",
        "    X_train1 = X_train1.cpu()\n",
        "\n",
        "# First, compute min/max along the batch dimension (dim=0)\n",
        "min_vals = torch.min(X_train1, dim=0).values\n",
        "max_vals = torch.max(X_train1, dim=0).values\n",
        "\n",
        "# Then, compute min/max along the sequence length dimension (dim=0)\n",
        "min_vals = torch.min(min_vals, dim=0).values\n",
        "max_vals = torch.max(max_vals, dim=0).values\n",
        "\n",
        "# Print the results\n",
        "print(f\"Min values for each column: {min_vals}\")\n",
        "print(f\"Max values for each column: {max_vals}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TsyDUYLPZdh",
        "outputId": "b59bc4a9-de15-4def-e151-243881c1a3fe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min values for each column: tensor([   0.0000,    0.0000, -132.5000, -103.0000,    0.0000])\n",
            "Max values for each column: tensor([  6., 131., 165., 103.,   1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if y_train1.is_cuda:\n",
        "    y_train1 = y_train1.cpu()\n",
        "\n",
        "# First, compute min/max along the batch dimension (dim=0)\n",
        "min_vals = torch.min(y_train1, dim=0).values\n",
        "max_vals = torch.max(y_train1, dim=0).values\n",
        "\n",
        "# Then, compute min/max along the sequence length dimension (dim=0)\n",
        "min_vals = torch.min(min_vals, dim=0).values\n",
        "max_vals = torch.max(max_vals, dim=0).values\n",
        "\n",
        "# Print the results\n",
        "print(f\"Min values for each column: {min_vals}\")\n",
        "print(f\"Max values for each column: {max_vals}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQTxELo-djky",
        "outputId": "547a3338-1b48-4074-e4bf-83878ff43957"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min values for each column: tensor([0.])\n",
            "Max values for each column: tensor([7586.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if X_train1.is_cuda:\n",
        "    X_train1 = X_train1.cpu()\n",
        "\n",
        "# Compute mean along batch and sequence dimensions (dim=0 and dim=1)\n",
        "mean_vals = torch.mean(X_train1, dim=(0, 1))\n",
        "# median_vals = torch.median(X_train1, dim=(0, 1)).values\n",
        "std_vals = torch.std(X_train1, dim=(0, 1))\n",
        "\n",
        "# Print the results\n",
        "print(f\"Mean values for each column: {mean_vals}\")\n",
        "# print(f\"Median values for each column: {median_vals}\")\n",
        "print(f\"Standard deviation for each column: {std_vals}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2ySgTLlP03h",
        "outputId": "7af1bcdb-6275-4af2-f1f7-f06442874e1e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean values for each column: tensor([ 2.7163e+00,  4.0335e+01, -3.9031e-02,  1.1825e-02,  1.1726e-01])\n",
            "Standard deviation for each column: tensor([ 1.7171, 31.3841,  3.3277,  1.6731,  0.3217])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if y_train1.is_cuda:\n",
        "    y_train1 = y_train1.cpu()\n",
        "\n",
        "# Compute mean along batch and sequence dimensions (dim=0 and dim=1)\n",
        "mean_vals = torch.mean(y_train1, dim=(0, 1))\n",
        "# median_vals = torch.median(y_train1, dim=(0, 1)).values\n",
        "std_vals = torch.std(y_train1, dim=(0, 1))\n",
        "\n",
        "# Print the results\n",
        "print(f\"Mean values for each column: {mean_vals}\")\n",
        "# print(f\"Median values for each column: {median_vals}\")\n",
        "print(f\"Standard deviation for each column: {std_vals}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFGCcpaXnMEY",
        "outputId": "8a9851ff-3d47-43fe-9cf7-4aa5d75b1d20"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean values for each column: tensor([502.7414])\n",
            "Standard deviation for each column: tensor([605.8156])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if X_train1.is_cuda:\n",
        "    X_train1 = X_train1.cpu()\n",
        "\n",
        "# Flatten the batch and sequence dimensions to create a 2D tensor (rows: samples, columns: features)\n",
        "flattened_tensor = X_train1.view(-1, X_train1.size(2)).numpy()\n",
        "\n"
      ],
      "metadata": {
        "id": "U-OSMgXqQNs8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "num_features = flattened_tensor.shape[1]  # Number of features\n",
        "\n",
        "# Create a subplot for each feature\n",
        "for i in range(num_features):\n",
        "    plt.subplot(3, 2, i+1)\n",
        "    plt.boxplot(flattened_tensor[:, i], vert=False, patch_artist=True)\n",
        "    plt.title(f'Boxplot for Feature {i+1}')\n",
        "    plt.xlabel('Value')\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "28JAnnuPQbU6",
        "outputId": "486622bb-5311-49a9-b532-35efd8c16aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p-b2QAFVP0vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalize**"
      ],
      "metadata": {
        "id": "cTt1HLi24WQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YSaA3VdOes7k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert the min and max values to tensors\n",
        "min_val_x = torch.tensor([0, 0, -10, -10,0], dtype=torch.float32).to(DEVICE)\n",
        "max_val_x = torch.tensor([6, 150, 10, 10,1], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "#for without coolant\n",
        "# min_val_x = torch.tensor([0, 0, -10, -10], dtype=torch.float32).to(DEVICE)\n",
        "# max_val_x = torch.tensor([6, 150, 10, 10], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "min_val_y = torch.tensor([0], dtype=torch.float32).to(DEVICE)\n",
        "max_val_y = torch.tensor([10000], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "# Custom normalization function for X\n",
        "def custom_normalize_X(data, min_vals, max_vals):\n",
        "    for i in range(data.shape[-1]):\n",
        "        data[:, :, i] = (data[:, :, i] - min_vals[i]) / (max_vals[i] - min_vals[i])\n",
        "    return data\n",
        "\n",
        "# Custom normalization function for y\n",
        "def custom_normalize_y(data, min_val, max_val):\n",
        "    return (data - min_val) / (max_val - min_val)\n",
        "\n",
        "# Normalize X_train and X_test\n",
        "X_train_normalized = custom_normalize_X(X_train, min_val_x, max_val_x)\n",
        "# X_test_normalized = custom_normalize_X(X_test, min_val_x, max_val_x)\n",
        "\n",
        "# Normalize y_train and y_test\n",
        "y_train_normalized = custom_normalize_y(y_train, min_val_y, max_val_y)\n",
        "# y_test_normalized = custom_normalize_y(y_test, min_val_y, max_val_y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Standard**"
      ],
      "metadata": {
        "id": "rGvLDIFEo3yV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean and standard deviation for X and y from the training set\n",
        "mean_x = torch.mean(X_train, dim=(0, 1)).to(DEVICE)\n",
        "std_x = torch.std(X_train, dim=(0, 1)).to(DEVICE)\n",
        "\n",
        "mean_y = torch.mean(y_train).to(DEVICE)\n",
        "std_y = torch.std(y_train).to(DEVICE)\n",
        "\n",
        "# Custom standardization function for X\n",
        "def custom_standardize_X(data, mean_vals, std_vals):\n",
        "    for i in range(data.shape[-1]):\n",
        "        data[:, :, i] = (data[:, :, i] - mean_vals[i]) / std_vals[i]\n",
        "    return data\n",
        "\n",
        "# Custom standardization function for y\n",
        "def custom_standardize_y(data, mean_val, std_val):\n",
        "    return (data - mean_val) / std_val\n",
        "\n",
        "# Standardize X_train and y_train\n",
        "X_train_normalized = custom_standardize_X(X_train, mean_x, std_x)\n",
        "y_train_normalized = custom_standardize_y(y_train, mean_y, std_y)\n",
        "\n",
        "# # Standardize X_test and y_test using the same mean and std as training data\n",
        "# X_test_standardized = custom_standardize_X(X_test, mean_x, std_x)\n",
        "# y_test_standardized = custom_standardize_y(y_test, mean_y, std_y)\n"
      ],
      "metadata": {
        "id": "G_j7q5t85DUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Convert tensors to lists to make them serializable\n",
        "mean_x_list = mean_x.cpu().tolist()\n",
        "std_x_list = std_x.cpu().tolist()\n",
        "mean_y_list = mean_y.cpu().tolist()\n",
        "std_y_list = std_y.cpu().tolist()\n",
        "\n",
        "# Save the mean and std values in a JSON file\n",
        "normalization_params = {\n",
        "    'mean_x': mean_x_list,\n",
        "    'std_x': std_x_list,\n",
        "    'mean_y': mean_y_list,\n",
        "    'std_y': std_y_list\n",
        "}\n",
        "\n",
        "# Write the normalization parameters to a JSON file\n",
        "with open('normalization_params.json', 'w') as f:\n",
        "    json.dump(normalization_params, f)\n"
      ],
      "metadata": {
        "id": "YqLwXqQFo3qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7jlVSjGn5WWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TF_8ygVJ5WUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9Yp0pliB5WRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the mean and std values from the JSON file\n",
        "with open('normalization_params.json', 'r') as f:\n",
        "    normalization_params = json.load(f)\n",
        "\n",
        "# Convert back to tensors\n",
        "mean_x = torch.tensor(normalization_params['mean_x'], dtype=torch.float32).to(DEVICE)\n",
        "std_x = torch.tensor(normalization_params['std_x'], dtype=torch.float32).to(DEVICE)\n",
        "mean_y = torch.tensor(normalization_params['mean_y'], dtype=torch.float32).to(DEVICE)\n",
        "std_y = torch.tensor(normalization_params['std_y'], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "# Now standardize the new test data\n",
        "X_new_test_standardized = custom_standardize_X(X_new_test, mean_x, std_x)\n",
        "y_new_test_standardized = custom_standardize_y(y_new_test, mean_y, std_y)\n"
      ],
      "metadata": {
        "id": "amPtOkQo40s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VgmqnxF05WFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8nEkP74q5WDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BFuJjz1E5WA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1 = X_train_normalized.clone()\n"
      ],
      "metadata": {
        "id": "Yw4fygvpRLT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN4p04pb-jHV",
        "outputId": "1d1b9879-1957-4105-8bb8-df01807a8759"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.5819, -1.2852, -0.0086, -0.0071,  1.5278],\n",
              "         [-1.5819, -1.2852, -0.0086, -0.0071,  1.5278],\n",
              "         [-1.5819, -1.2852, -0.0086, -0.0071,  1.5278],\n",
              "         ...,\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  0.8170],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  0.9185],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  0.9185]],\n",
              "\n",
              "        [[-1.5819, -1.2852,  0.3314, -0.0071, -3.5491],\n",
              "         [-1.5819, -1.2852,  0.3314, -0.0071, -3.5491],\n",
              "         [-1.5819, -1.2852,  0.3314, -0.0071, -3.5491],\n",
              "         ...,\n",
              "         [-0.9995, -0.8073, -0.3339,  0.5906,  0.1063],\n",
              "         [-0.9995, -0.8073, -0.3339, -0.0071,  0.0047],\n",
              "         [-0.9995, -0.7435,  0.0117,  1.1883,  0.0047]],\n",
              "\n",
              "        [[-1.5819, -1.2852,  1.0012, -0.0071,  0.3093],\n",
              "         [-1.5819, -1.2852,  1.0012, -0.0071,  0.2078],\n",
              "         [-1.5819, -1.2852,  1.0012, -0.0071,  0.3093],\n",
              "         ...,\n",
              "         [ 0.7476,  0.9771,  0.2229, -0.0071,  0.3093],\n",
              "         [ 0.7476,  0.9771,  0.2229, -0.0071,  0.3093],\n",
              "         [ 0.7476,  0.9134,  0.2229, -1.2025,  0.3093]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.5819, -1.2852,  0.0117, -0.0071,  1.0201],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.0201],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.0201],\n",
              "         ...,\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.1216],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.1216]],\n",
              "\n",
              "        [[-1.5819, -1.2852,  0.0117, -0.0071,  1.1216],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.1216],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.1216],\n",
              "         ...,\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232]],\n",
              "\n",
              "        [[-1.5819, -1.2852,  0.0117, -0.0071,  1.2232],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232],\n",
              "         ...,\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232],\n",
              "         [-1.5819, -1.2852,  0.0117, -0.0071,  1.2232]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "X_train_normalized =X_train_standardized"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **model**"
      ],
      "metadata": {
        "id": "WZ1tv5iCo54o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MwYKbOq_Zcr7"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class FuelConsumptionModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(FuelConsumptionModel, self).__init__()\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size, 32, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Layer Normalization after each LSTM\n",
        "        self.layer_norm1 = nn.LayerNorm(64)\n",
        "        self.layer_norm2 = nn.LayerNorm(64)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        # Dense output layer\n",
        "        self.dense = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM 1 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.layer_norm1(x)  # Apply layer normalization after LSTM1\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # LSTM 2 + Layer Normalization + Dropout\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.layer_norm2(x)  # Apply layer normalization after LSTM2\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Dense layer for final output\n",
        "        x = self.dense(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NrURTgcFgyYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ba28e1-6fd5-45dd-d1eb-0db693cf2c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_normalized shape: torch.Size([42821, 600, 5])\n",
            "y_train_normalized shape: torch.Size([42821, 600, 1])\n",
            "Train size: 34256, Validation size: 8565\n"
          ]
        }
      ],
      "source": [
        "# Check if X_train_normalized and y_train_normalized have the same number of samples\n",
        "print(f\"X_train_normalized shape: {X_train_normalized.shape}\")\n",
        "print(f\"y_train_normalized shape: {y_train_normalized.shape}\")\n",
        "\n",
        "# Ensure they have the same length in the first dimension\n",
        "if len(X_train_normalized) != len(y_train_normalized):\n",
        "    raise ValueError(f\"Mismatch in number of samples: {len(X_train_normalized)} in X vs {len(y_train_normalized)} in y\")\n",
        "\n",
        "# Calculate train size\n",
        "train_size = int(0.8 * len(X_train_normalized))\n",
        "\n",
        "# Split the data while preserving the order\n",
        "X_train_split = X_train_normalized[:train_size]\n",
        "y_train_split = y_train_normalized[:train_size]\n",
        "\n",
        "X_val_split = X_train_normalized[train_size:]\n",
        "y_val_split = y_train_normalized[train_size:]\n",
        "\n",
        "print(f\"Train size: {train_size}, Validation size: {len(X_val_split)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "csLAJyD43kt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **train with coolant**"
      ],
      "metadata": {
        "id": "o9D0YvUOqw2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z0wpMf9gK-h",
        "outputId": "c3643f35-6f49-4692-9906-43b9fe1f76fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500] ---- Training Loss: 0.0790 ---- Validation Loss: 0.031079 ------0.0001\n",
            "Epoch [2/500] ---- Training Loss: 0.0337 ---- Validation Loss: 0.029324 ------0.0001\n",
            "Epoch [3/500] ---- Training Loss: 0.0300 ---- Validation Loss: 0.024998 ------0.0001\n",
            "Epoch [4/500] ---- Training Loss: 0.0264 ---- Validation Loss: 0.022126 ------0.0001\n",
            "Epoch [5/500] ---- Training Loss: 0.0238 ---- Validation Loss: 0.019786 ------0.0001\n",
            "Epoch [6/500] ---- Training Loss: 0.0215 ---- Validation Loss: 0.018454 ------0.0001\n",
            "Epoch [7/500] ---- Training Loss: 0.0197 ---- Validation Loss: 0.017010 ------0.0001\n",
            "Epoch [8/500] ---- Training Loss: 0.0185 ---- Validation Loss: 0.016381 ------0.0001\n",
            "Epoch [9/500] ---- Training Loss: 0.0176 ---- Validation Loss: 0.015666 ------0.0001\n",
            "Epoch [10/500] ---- Training Loss: 0.0170 ---- Validation Loss: 0.015391 ------0.0001\n",
            "Epoch [11/500] ---- Training Loss: 0.0166 ---- Validation Loss: 0.015158 ------0.0001\n",
            "Epoch [12/500] ---- Training Loss: 0.0163 ---- Validation Loss: 0.015138 ------0.0001\n",
            "Epoch [13/500] ---- Training Loss: 0.0160 ---- Validation Loss: 0.014972 ------0.0001\n",
            "Epoch [14/500] ---- Training Loss: 0.0158 ---- Validation Loss: 0.014951 ------0.0001\n",
            "Epoch [15/500] ---- Training Loss: 0.0156 ---- Validation Loss: 0.014705 ------0.0001\n",
            "Epoch [16/500] ---- Training Loss: 0.0155 ---- Validation Loss: 0.014611 ------0.0001\n",
            "Epoch [17/500] ---- Training Loss: 0.0154 ---- Validation Loss: 0.014509 ------0.0001\n",
            "Epoch [18/500] ---- Training Loss: 0.0152 ---- Validation Loss: 0.014484 ------0.0001\n",
            "Epoch [19/500] ---- Training Loss: 0.0151 ---- Validation Loss: 0.014355 ------0.0001\n",
            "Epoch [20/500] ---- Training Loss: 0.0150 ---- Validation Loss: 0.014367 ------0.0001\n",
            "Epoch [21/500] ---- Training Loss: 0.0149 ---- Validation Loss: 0.014362 ------0.0001\n",
            "Epoch [22/500] ---- Training Loss: 0.0148 ---- Validation Loss: 0.014211 ------0.0001\n",
            "Epoch [23/500] ---- Training Loss: 0.0148 ---- Validation Loss: 0.014138 ------0.0001\n",
            "Epoch [24/500] ---- Training Loss: 0.0147 ---- Validation Loss: 0.014198 ------0.0001\n",
            "Epoch [25/500] ---- Training Loss: 0.0146 ---- Validation Loss: 0.014017 ------0.0001\n",
            "Epoch [26/500] ---- Training Loss: 0.0146 ---- Validation Loss: 0.013950 ------0.0001\n",
            "Epoch [27/500] ---- Training Loss: 0.0145 ---- Validation Loss: 0.013910 ------0.0001\n",
            "Epoch [28/500] ---- Training Loss: 0.0145 ---- Validation Loss: 0.013955 ------0.0001\n",
            "Epoch [29/500] ---- Training Loss: 0.0144 ---- Validation Loss: 0.013806 ------0.0001\n",
            "Epoch [30/500] ---- Training Loss: 0.0144 ---- Validation Loss: 0.013816 ------0.0001\n",
            "Epoch [31/500] ---- Training Loss: 0.0143 ---- Validation Loss: 0.013763 ------0.0001\n",
            "Epoch [32/500] ---- Training Loss: 0.0143 ---- Validation Loss: 0.013703 ------0.0001\n",
            "Epoch [33/500] ---- Training Loss: 0.0143 ---- Validation Loss: 0.013690 ------0.0001\n",
            "Epoch [34/500] ---- Training Loss: 0.0142 ---- Validation Loss: 0.013691 ------0.0001\n",
            "Epoch [35/500] ---- Training Loss: 0.0142 ---- Validation Loss: 0.013570 ------0.0001\n",
            "Epoch [36/500] ---- Training Loss: 0.0141 ---- Validation Loss: 0.013573 ------0.0001\n",
            "Epoch [37/500] ---- Training Loss: 0.0141 ---- Validation Loss: 0.013540 ------0.0001\n",
            "Epoch [38/500] ---- Training Loss: 0.0141 ---- Validation Loss: 0.013545 ------0.0001\n",
            "Epoch [39/500] ---- Training Loss: 0.0141 ---- Validation Loss: 0.013471 ------0.0001\n",
            "Epoch [40/500] ---- Training Loss: 0.0140 ---- Validation Loss: 0.013400 ------0.0001\n",
            "Epoch [41/500] ---- Training Loss: 0.0140 ---- Validation Loss: 0.013522 ------0.0001\n",
            "Epoch [42/500] ---- Training Loss: 0.0139 ---- Validation Loss: 0.013414 ------0.0001\n",
            "Epoch [43/500] ---- Training Loss: 0.0139 ---- Validation Loss: 0.013304 ------0.0001\n",
            "Epoch [44/500] ---- Training Loss: 0.0139 ---- Validation Loss: 0.013293 ------0.0001\n",
            "Epoch [45/500] ---- Training Loss: 0.0139 ---- Validation Loss: 0.013249 ------0.0001\n",
            "Epoch [46/500] ---- Training Loss: 0.0138 ---- Validation Loss: 0.013247 ------0.0001\n",
            "Epoch [47/500] ---- Training Loss: 0.0138 ---- Validation Loss: 0.013310 ------0.0001\n",
            "Epoch [48/500] ---- Training Loss: 0.0138 ---- Validation Loss: 0.013163 ------0.0001\n",
            "Epoch [49/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013154 ------0.0001\n",
            "Epoch [50/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013127 ------0.0001\n",
            "Epoch [51/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013117 ------0.0001\n",
            "Epoch [52/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013085 ------0.0001\n",
            "Epoch [53/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013126 ------0.0001\n",
            "Epoch [54/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.013035 ------0.0001\n",
            "Epoch [55/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.013027 ------0.0001\n",
            "Epoch [56/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.012978 ------0.0001\n",
            "Epoch [57/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.013038 ------0.0001\n",
            "Epoch [58/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012977 ------0.0001\n",
            "Epoch [59/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012960 ------0.0001\n",
            "Epoch [60/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012946 ------0.0001\n",
            "Epoch [61/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012901 ------0.0001\n",
            "Epoch [62/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012930 ------0.0001\n",
            "Epoch [63/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012881 ------0.0001\n",
            "Epoch [64/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012909 ------0.0001\n",
            "Epoch [65/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012855 ------0.0001\n",
            "Epoch [66/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012837 ------0.0001\n",
            "Epoch [67/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012819 ------0.0001\n",
            "Epoch [68/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012801 ------0.0001\n",
            "Epoch [69/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012928 ------0.0001\n",
            "Epoch [70/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012791 ------0.0001\n",
            "Epoch [71/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012778 ------0.0001\n",
            "Epoch [72/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012753 ------0.0001\n",
            "Epoch [73/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012767 ------0.0001\n",
            "Epoch [74/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012736 ------0.0001\n",
            "Epoch [75/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012713 ------0.0001\n",
            "Epoch [76/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012782 ------0.0001\n",
            "Epoch [77/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012692 ------0.0001\n",
            "Epoch [78/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012697 ------0.0001\n",
            "Epoch [79/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012786 ------0.0001\n",
            "Epoch [80/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012667 ------0.0001\n",
            "Epoch [81/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012671 ------0.0001\n",
            "Epoch [82/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012647 ------0.0001\n",
            "Epoch [83/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012628 ------0.0001\n",
            "Epoch [84/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012665 ------0.0001\n",
            "Epoch [85/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012597 ------0.0001\n",
            "Epoch [86/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012665 ------0.0001\n",
            "Epoch [87/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012592 ------0.0001\n",
            "Epoch [88/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012604 ------0.0001\n",
            "Epoch [89/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012607 ------0.0001\n",
            "Epoch [90/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012577 ------0.0001\n",
            "Epoch [91/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012546 ------0.0001\n",
            "Epoch [92/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012583 ------0.0001\n",
            "Epoch [93/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012545 ------0.0001\n",
            "Epoch [94/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012506 ------0.0001\n",
            "Epoch [95/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012509 ------0.0001\n",
            "Epoch [96/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012585 ------0.0001\n",
            "Epoch [97/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012526 ------0.0001\n",
            "Epoch [98/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012516 ------0.0001\n",
            "Epoch [99/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012503 ------0.0001\n",
            "Epoch [100/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012481 ------0.0001\n",
            "Epoch [101/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012557 ------0.0001\n",
            "Epoch [102/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012487 ------0.0001\n",
            "Epoch [103/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012457 ------0.0001\n",
            "Epoch [104/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012435 ------0.0001\n",
            "Epoch [105/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012481 ------0.0001\n",
            "Epoch [106/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012446 ------0.0001\n",
            "Epoch [107/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012403 ------0.0001\n",
            "Epoch [108/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012428 ------0.0001\n",
            "Epoch [109/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012384 ------0.0001\n",
            "Epoch [110/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012475 ------0.0001\n",
            "Epoch [111/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012399 ------0.0001\n",
            "Epoch [112/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012362 ------0.0001\n",
            "Epoch [113/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012354 ------0.0001\n",
            "Epoch [114/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012466 ------0.0001\n",
            "Epoch [115/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012458 ------0.0001\n",
            "Epoch [116/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012341 ------0.0001\n",
            "Epoch [117/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012427 ------0.0001\n",
            "Epoch [118/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012363 ------0.0001\n",
            "Epoch [119/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012299 ------0.0001\n",
            "Epoch [120/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012330 ------0.0001\n",
            "Epoch [121/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012322 ------0.0001\n",
            "Epoch [122/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012295 ------0.0001\n",
            "Epoch [123/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012268 ------0.0001\n",
            "Epoch [124/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012287 ------0.0001\n",
            "Epoch [125/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012283 ------0.0001\n",
            "Epoch [126/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012332 ------0.0001\n",
            "Epoch [127/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012350 ------0.0001\n",
            "Epoch [128/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012262 ------0.0001\n",
            "Epoch [129/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012267 ------0.0001\n",
            "Epoch [130/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012379 ------0.0001\n",
            "Epoch [131/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012214 ------0.0001\n",
            "Epoch [132/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012219 ------0.0001\n",
            "Epoch [133/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012212 ------0.0001\n",
            "Epoch [134/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012190 ------0.0001\n",
            "Epoch [135/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012290 ------0.0001\n",
            "Epoch [136/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012252 ------0.0001\n",
            "Epoch [137/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012176 ------0.0001\n",
            "Epoch [138/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012195 ------0.0001\n",
            "Epoch [139/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012190 ------0.0001\n",
            "Epoch [140/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012147 ------0.0001\n",
            "Epoch [141/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012164 ------0.0001\n",
            "Epoch [142/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012180 ------0.0001\n",
            "Epoch [143/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012155 ------0.0001\n",
            "Epoch [144/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012116 ------0.0001\n",
            "Epoch [145/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012127 ------0.0001\n",
            "Epoch [146/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012131 ------0.0001\n",
            "Epoch [147/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012121 ------0.0001\n",
            "Epoch [148/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012106 ------0.0001\n",
            "Epoch [149/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012077 ------0.0001\n",
            "Epoch [150/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012121 ------0.0001\n",
            "Epoch [151/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012097 ------0.0001\n",
            "Epoch [152/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012105 ------0.0001\n",
            "Epoch [153/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012080 ------0.0001\n",
            "Epoch [154/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012141 ------0.0001\n",
            "Epoch [155/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012059 ------0.0001\n",
            "Epoch [156/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012046 ------0.0001\n",
            "Epoch [157/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012113 ------0.0001\n",
            "Epoch [158/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012076 ------0.0001\n",
            "Epoch [159/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012126 ------0.0001\n",
            "Epoch [160/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012197 ------0.0001\n",
            "Epoch [161/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012073 ------0.0001\n",
            "Epoch [162/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012084 ------0.0001\n",
            "Epoch [163/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012018 ------5e-05\n",
            "Epoch [164/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012039 ------5e-05\n",
            "Epoch [165/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012006 ------5e-05\n",
            "Epoch [166/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011998 ------5e-05\n",
            "Epoch [167/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.012021 ------5e-05\n",
            "Epoch [168/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011989 ------5e-05\n",
            "Epoch [169/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011980 ------5e-05\n",
            "Epoch [170/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011999 ------5e-05\n",
            "Epoch [171/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011979 ------5e-05\n",
            "Epoch [172/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011982 ------5e-05\n",
            "Epoch [173/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011983 ------5e-05\n",
            "Epoch [174/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011976 ------5e-05\n",
            "Epoch [175/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011985 ------5e-05\n",
            "Epoch [176/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011964 ------5e-05\n",
            "Epoch [177/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011958 ------5e-05\n",
            "Epoch [178/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011993 ------5e-05\n",
            "Epoch [179/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011943 ------5e-05\n",
            "Epoch [180/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011956 ------5e-05\n",
            "Epoch [181/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011951 ------5e-05\n",
            "Epoch [182/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011950 ------5e-05\n",
            "Epoch [183/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.012002 ------5e-05\n",
            "Epoch [184/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011952 ------5e-05\n",
            "Epoch [185/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011999 ------5e-05\n",
            "Epoch [186/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011927 ------2.5e-05\n",
            "Epoch [187/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011929 ------2.5e-05\n",
            "Epoch [188/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011945 ------2.5e-05\n",
            "Epoch [189/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011923 ------2.5e-05\n",
            "Epoch [190/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011966 ------2.5e-05\n",
            "Epoch [191/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011931 ------2.5e-05\n",
            "Epoch [192/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011922 ------2.5e-05\n",
            "Epoch [193/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011938 ------2.5e-05\n",
            "Epoch [194/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011923 ------2.5e-05\n",
            "Epoch [195/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011926 ------2.5e-05\n",
            "Epoch [196/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011903 ------1.25e-05\n",
            "Epoch [197/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011916 ------1.25e-05\n",
            "Epoch [198/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011941 ------1.25e-05\n",
            "Epoch [199/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011921 ------1.25e-05\n",
            "Epoch [200/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011929 ------1.25e-05\n",
            "Epoch [201/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011894 ------1.25e-05\n",
            "Epoch [202/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011918 ------1.25e-05\n",
            "Epoch [203/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011907 ------1.25e-05\n",
            "Epoch [204/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011903 ------1.25e-05\n",
            "Epoch [205/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011892 ------1.25e-05\n",
            "Epoch [206/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011904 ------1.25e-05\n",
            "Epoch [207/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011917 ------1.25e-05\n",
            "Epoch [208/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011904 ------1.25e-05\n",
            "Epoch [209/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011928 ------1.25e-05\n",
            "Epoch [210/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011894 ------1.25e-05\n",
            "Epoch [211/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011903 ------1.25e-05\n",
            "Epoch [212/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011885 ------6.25e-06\n",
            "Epoch [213/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011905 ------6.25e-06\n",
            "Epoch [214/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011890 ------6.25e-06\n",
            "Epoch [215/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011893 ------6.25e-06\n",
            "Epoch [216/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011895 ------6.25e-06\n",
            "Epoch [217/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011892 ------6.25e-06\n",
            "Epoch [218/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011888 ------6.25e-06\n",
            "Epoch [219/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011886 ------3.125e-06\n",
            "Epoch [220/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011893 ------3.125e-06\n",
            "Epoch [221/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011891 ------3.125e-06\n",
            "Epoch [222/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011883 ------3.125e-06\n",
            "Epoch [223/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011882 ------3.125e-06\n",
            "Epoch [224/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011891 ------3.125e-06\n",
            "Epoch [225/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011890 ------3.125e-06\n",
            "Epoch [226/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011887 ------3.125e-06\n",
            "Epoch [227/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011883 ------3.125e-06\n",
            "Epoch [228/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011888 ------3.125e-06\n",
            "Epoch [229/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011888 ------1.5625e-06\n",
            "Epoch [230/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011890 ------1.5625e-06\n",
            "Epoch [231/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011889 ------1.5625e-06\n",
            "Epoch [232/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011884 ------1.5625e-06\n",
            "Epoch [233/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011888 ------1.5625e-06\n",
            "Early stopping at epoch 233\n",
            "Saved model: best_fuel_consumption_model.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR  # Importing StepLR for learning rate decay\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# Assuming `FuelConsumptionModel`, `X_train_normalized`, `train_loader`, `val_loader`, `DEVICE`, and `EPOCHS` are defined\n",
        "\n",
        "# Choose a single loss function to use for all experiments\n",
        "criterion = nn.L1Loss()  # You can change this to your preferred loss function\n",
        "\n",
        "EPOCHS = 500\n",
        "# Define weight decay values and initial learning rates for decay schedules\n",
        "weight_decay_values = 1e-6\n",
        "initial_learning_rates = [1e-4]  # Two starting learning rates\n",
        "\n",
        "# Initialize variables to track the best parameters\n",
        "best_weight_decay = None\n",
        "best_initial_lr = None\n",
        "best_model_weights = None\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "ini_batches = [64]\n",
        "# Loop over all combinations of initial learning rates and weight decay values\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "# Create DataLoader for training and validation sets\n",
        "train_loader = DataLoader(TensorDataset(X_train_split, y_train_split), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_split, y_val_split), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "for init_lr in initial_learning_rates:\n",
        "    # Initialize model, criterion, and optimizer for each combination\n",
        "    model = FuelConsumptionModel(input_size=X_train_normalized.shape[-1]).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=init_lr, weight_decay=weight_decay_values)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "    # Early stopping parameters\n",
        "    patience = 10  # Number of epochs to wait before stopping if no improvement\n",
        "    best_loss = float('inf')  # Initialize best loss to infinity\n",
        "    epochs_without_improvement = 0  # Counter for epochs without improvement\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        model.train()  # Ensure model is in training mode\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_training_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()  # Switch to evaluation mode\n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:  # Assume you have a validation DataLoader `val_loader`\n",
        "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "                outputs = model(inputs)\n",
        "                val_loss = criterion(outputs, targets)\n",
        "                val_running_loss += val_loss.item()\n",
        "\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.6f} ------{current_lr}\")\n",
        "\n",
        "        # print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.4f}    Init LR: {init_lr:.0e}  WD: {wd:.0e}\")\n",
        "\n",
        "        # Adjust the learning rate\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Save the model for the current combination\n",
        "        model_filename = f'best_fuel_consumption_model.pth'\n",
        "        torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "\n",
        "print(f\"Saved model: {model_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **train without coolant**"
      ],
      "metadata": {
        "id": "_AsqnD9lqzQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR  # Importing StepLR for learning rate decay\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# Assuming `FuelConsumptionModel`, `X_train_normalized`, `train_loader`, `val_loader`, `DEVICE`, and `EPOCHS` are defined\n",
        "\n",
        "# Choose a single loss function to use for all experiments\n",
        "criterion = nn.L1Loss()  # You can change this to your preferred loss function\n",
        "\n",
        "EPOCHS = 500\n",
        "# Define weight decay values and initial learning rates for decay schedules\n",
        "weight_decay_values = 1e-6\n",
        "initial_learning_rates = [1e-4]  # Two starting learning rates\n",
        "\n",
        "# Initialize variables to track the best parameters\n",
        "best_weight_decay = None\n",
        "best_initial_lr = None\n",
        "best_model_weights = None\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "ini_batches = [64]\n",
        "# Loop over all combinations of initial learning rates and weight decay values\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "# Create DataLoader for training and validation sets\n",
        "train_loader = DataLoader(TensorDataset(X_train_split, y_train_split), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_split, y_val_split), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "for init_lr in initial_learning_rates:\n",
        "    # Initialize model, criterion, and optimizer for each combination\n",
        "    model = FuelConsumptionModel(input_size=X_train_normalized.shape[-1]).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=init_lr, weight_decay=weight_decay_values)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "    # Early stopping parameters\n",
        "    patience = 20  # Number of epochs to wait before stopping if no improvement\n",
        "    best_loss = float('inf')  # Initialize best loss to infinity\n",
        "    epochs_without_improvement = 0  # Counter for epochs without improvement\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        model.train()  # Ensure model is in training mode\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_training_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()  # Switch to evaluation mode\n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:  # Assume you have a validation DataLoader `val_loader`\n",
        "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)  # Ensure data is on the correct device\n",
        "                outputs = model(inputs)\n",
        "                val_loss = criterion(outputs, targets)\n",
        "                val_running_loss += val_loss.item()\n",
        "\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.6f} ------{current_lr}\")\n",
        "\n",
        "        # print(f\"Epoch [{epoch+1}/{EPOCHS}] ---- Training Loss: {avg_training_loss:.4f} ---- Validation Loss: {avg_val_loss:.4f}    Init LR: {init_lr:.0e}  WD: {wd:.0e}\")\n",
        "\n",
        "        # Adjust the learning rate\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Save the model for the current combination\n",
        "        model_filename = f'mode_without_coolant_qani.pth'\n",
        "        torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "\n",
        "print(f\"Saved model: {model_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEubC6Fyd9LI",
        "outputId": "143a08a1-0e46-4165-9b10-a19ef905555a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500] ---- Training Loss: 0.0782 ---- Validation Loss: 0.027671 ------0.0001\n",
            "Epoch [2/500] ---- Training Loss: 0.0281 ---- Validation Loss: 0.023100 ------0.0001\n",
            "Epoch [3/500] ---- Training Loss: 0.0233 ---- Validation Loss: 0.019051 ------0.0001\n",
            "Epoch [4/500] ---- Training Loss: 0.0201 ---- Validation Loss: 0.016721 ------0.0001\n",
            "Epoch [5/500] ---- Training Loss: 0.0182 ---- Validation Loss: 0.015666 ------0.0001\n",
            "Epoch [6/500] ---- Training Loss: 0.0172 ---- Validation Loss: 0.015233 ------0.0001\n",
            "Epoch [7/500] ---- Training Loss: 0.0166 ---- Validation Loss: 0.014904 ------0.0001\n",
            "Epoch [8/500] ---- Training Loss: 0.0161 ---- Validation Loss: 0.014731 ------0.0001\n",
            "Epoch [9/500] ---- Training Loss: 0.0158 ---- Validation Loss: 0.014515 ------0.0001\n",
            "Epoch [10/500] ---- Training Loss: 0.0155 ---- Validation Loss: 0.014424 ------0.0001\n",
            "Epoch [11/500] ---- Training Loss: 0.0153 ---- Validation Loss: 0.014314 ------0.0001\n",
            "Epoch [12/500] ---- Training Loss: 0.0151 ---- Validation Loss: 0.014212 ------0.0001\n",
            "Epoch [13/500] ---- Training Loss: 0.0149 ---- Validation Loss: 0.014019 ------0.0001\n",
            "Epoch [14/500] ---- Training Loss: 0.0147 ---- Validation Loss: 0.013983 ------0.0001\n",
            "Epoch [15/500] ---- Training Loss: 0.0146 ---- Validation Loss: 0.013870 ------0.0001\n",
            "Epoch [16/500] ---- Training Loss: 0.0145 ---- Validation Loss: 0.013747 ------0.0001\n",
            "Epoch [17/500] ---- Training Loss: 0.0144 ---- Validation Loss: 0.013680 ------0.0001\n",
            "Epoch [18/500] ---- Training Loss: 0.0143 ---- Validation Loss: 0.013643 ------0.0001\n",
            "Epoch [19/500] ---- Training Loss: 0.0142 ---- Validation Loss: 0.013606 ------0.0001\n",
            "Epoch [20/500] ---- Training Loss: 0.0142 ---- Validation Loss: 0.013598 ------0.0001\n",
            "Epoch [21/500] ---- Training Loss: 0.0141 ---- Validation Loss: 0.013493 ------0.0001\n",
            "Epoch [22/500] ---- Training Loss: 0.0141 ---- Validation Loss: 0.013566 ------0.0001\n",
            "Epoch [23/500] ---- Training Loss: 0.0140 ---- Validation Loss: 0.013478 ------0.0001\n",
            "Epoch [24/500] ---- Training Loss: 0.0140 ---- Validation Loss: 0.013399 ------0.0001\n",
            "Epoch [25/500] ---- Training Loss: 0.0139 ---- Validation Loss: 0.013535 ------0.0001\n",
            "Epoch [26/500] ---- Training Loss: 0.0139 ---- Validation Loss: 0.013346 ------0.0001\n",
            "Epoch [27/500] ---- Training Loss: 0.0139 ---- Validation Loss: 0.013295 ------0.0001\n",
            "Epoch [28/500] ---- Training Loss: 0.0138 ---- Validation Loss: 0.013308 ------0.0001\n",
            "Epoch [29/500] ---- Training Loss: 0.0138 ---- Validation Loss: 0.013276 ------0.0001\n",
            "Epoch [30/500] ---- Training Loss: 0.0138 ---- Validation Loss: 0.013186 ------0.0001\n",
            "Epoch [31/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013200 ------0.0001\n",
            "Epoch [32/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013127 ------0.0001\n",
            "Epoch [33/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013129 ------0.0001\n",
            "Epoch [34/500] ---- Training Loss: 0.0137 ---- Validation Loss: 0.013156 ------0.0001\n",
            "Epoch [35/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.013078 ------0.0001\n",
            "Epoch [36/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.013044 ------0.0001\n",
            "Epoch [37/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.013017 ------0.0001\n",
            "Epoch [38/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.012978 ------0.0001\n",
            "Epoch [39/500] ---- Training Loss: 0.0136 ---- Validation Loss: 0.012960 ------0.0001\n",
            "Epoch [40/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012953 ------0.0001\n",
            "Epoch [41/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012938 ------0.0001\n",
            "Epoch [42/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012906 ------0.0001\n",
            "Epoch [43/500] ---- Training Loss: 0.0135 ---- Validation Loss: 0.012871 ------0.0001\n",
            "Epoch [44/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012862 ------0.0001\n",
            "Epoch [45/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012880 ------0.0001\n",
            "Epoch [46/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012834 ------0.0001\n",
            "Epoch [47/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012854 ------0.0001\n",
            "Epoch [48/500] ---- Training Loss: 0.0134 ---- Validation Loss: 0.012779 ------0.0001\n",
            "Epoch [49/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012757 ------0.0001\n",
            "Epoch [50/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012744 ------0.0001\n",
            "Epoch [51/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012720 ------0.0001\n",
            "Epoch [52/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012739 ------0.0001\n",
            "Epoch [53/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012677 ------0.0001\n",
            "Epoch [54/500] ---- Training Loss: 0.0133 ---- Validation Loss: 0.012674 ------0.0001\n",
            "Epoch [55/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012662 ------0.0001\n",
            "Epoch [56/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012673 ------0.0001\n",
            "Epoch [57/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012651 ------0.0001\n",
            "Epoch [58/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012760 ------0.0001\n",
            "Epoch [59/500] ---- Training Loss: 0.0132 ---- Validation Loss: 0.012576 ------0.0001\n",
            "Epoch [60/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012552 ------0.0001\n",
            "Epoch [61/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012530 ------0.0001\n",
            "Epoch [62/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012536 ------0.0001\n",
            "Epoch [63/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012486 ------0.0001\n",
            "Epoch [64/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012480 ------0.0001\n",
            "Epoch [65/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.012594 ------0.0001\n",
            "Epoch [66/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012425 ------0.0001\n",
            "Epoch [67/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012411 ------0.0001\n",
            "Epoch [68/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012436 ------0.0001\n",
            "Epoch [69/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012424 ------0.0001\n",
            "Epoch [70/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012371 ------0.0001\n",
            "Epoch [71/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012389 ------0.0001\n",
            "Epoch [72/500] ---- Training Loss: 0.0130 ---- Validation Loss: 0.012358 ------0.0001\n",
            "Epoch [73/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012337 ------0.0001\n",
            "Epoch [74/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012313 ------0.0001\n",
            "Epoch [75/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012294 ------0.0001\n",
            "Epoch [76/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012353 ------0.0001\n",
            "Epoch [77/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012301 ------0.0001\n",
            "Epoch [78/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012248 ------0.0001\n",
            "Epoch [79/500] ---- Training Loss: 0.0129 ---- Validation Loss: 0.012244 ------0.0001\n",
            "Epoch [80/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012223 ------0.0001\n",
            "Epoch [81/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012214 ------0.0001\n",
            "Epoch [82/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012193 ------0.0001\n",
            "Epoch [83/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012198 ------0.0001\n",
            "Epoch [84/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012162 ------0.0001\n",
            "Epoch [85/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012165 ------0.0001\n",
            "Epoch [86/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012165 ------0.0001\n",
            "Epoch [87/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012120 ------0.0001\n",
            "Epoch [88/500] ---- Training Loss: 0.0128 ---- Validation Loss: 0.012108 ------0.0001\n",
            "Epoch [89/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012149 ------0.0001\n",
            "Epoch [90/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012128 ------0.0001\n",
            "Epoch [91/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012080 ------0.0001\n",
            "Epoch [92/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012079 ------0.0001\n",
            "Epoch [93/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012068 ------0.0001\n",
            "Epoch [94/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012039 ------0.0001\n",
            "Epoch [95/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012076 ------0.0001\n",
            "Epoch [96/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012038 ------0.0001\n",
            "Epoch [97/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012047 ------0.0001\n",
            "Epoch [98/500] ---- Training Loss: 0.0127 ---- Validation Loss: 0.012029 ------0.0001\n",
            "Epoch [99/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011974 ------0.0001\n",
            "Epoch [100/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011982 ------0.0001\n",
            "Epoch [101/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011977 ------0.0001\n",
            "Epoch [102/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011951 ------0.0001\n",
            "Epoch [103/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011931 ------0.0001\n",
            "Epoch [104/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011920 ------0.0001\n",
            "Epoch [105/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011900 ------0.0001\n",
            "Epoch [106/500] ---- Training Loss: 0.0126 ---- Validation Loss: 0.011920 ------0.0001\n",
            "Epoch [107/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011946 ------0.0001\n",
            "Epoch [108/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011912 ------0.0001\n",
            "Epoch [109/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011889 ------0.0001\n",
            "Epoch [110/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011859 ------0.0001\n",
            "Epoch [111/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011916 ------0.0001\n",
            "Epoch [112/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011855 ------0.0001\n",
            "Epoch [113/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011831 ------0.0001\n",
            "Epoch [114/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011841 ------0.0001\n",
            "Epoch [115/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011806 ------0.0001\n",
            "Epoch [116/500] ---- Training Loss: 0.0125 ---- Validation Loss: 0.011789 ------0.0001\n",
            "Epoch [117/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011784 ------0.0001\n",
            "Epoch [118/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011754 ------0.0001\n",
            "Epoch [119/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011752 ------0.0001\n",
            "Epoch [120/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011765 ------0.0001\n",
            "Epoch [121/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011782 ------0.0001\n",
            "Epoch [122/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011732 ------0.0001\n",
            "Epoch [123/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011749 ------0.0001\n",
            "Epoch [124/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011804 ------0.0001\n",
            "Epoch [125/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011700 ------0.0001\n",
            "Epoch [126/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011835 ------0.0001\n",
            "Epoch [127/500] ---- Training Loss: 0.0124 ---- Validation Loss: 0.011681 ------0.0001\n",
            "Epoch [128/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011678 ------0.0001\n",
            "Epoch [129/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011663 ------0.0001\n",
            "Epoch [130/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011661 ------0.0001\n",
            "Epoch [131/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011609 ------0.0001\n",
            "Epoch [132/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011610 ------0.0001\n",
            "Epoch [133/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011599 ------0.0001\n",
            "Epoch [134/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011599 ------0.0001\n",
            "Epoch [135/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011567 ------0.0001\n",
            "Epoch [136/500] ---- Training Loss: 0.0123 ---- Validation Loss: 0.011563 ------0.0001\n",
            "Epoch [137/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011541 ------0.0001\n",
            "Epoch [138/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011556 ------0.0001\n",
            "Epoch [139/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011526 ------0.0001\n",
            "Epoch [140/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011515 ------0.0001\n",
            "Epoch [141/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011505 ------0.0001\n",
            "Epoch [142/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011576 ------0.0001\n",
            "Epoch [143/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011498 ------0.0001\n",
            "Epoch [144/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011461 ------0.0001\n",
            "Epoch [145/500] ---- Training Loss: 0.0122 ---- Validation Loss: 0.011460 ------0.0001\n",
            "Epoch [146/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011453 ------0.0001\n",
            "Epoch [147/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011440 ------0.0001\n",
            "Epoch [148/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011479 ------0.0001\n",
            "Epoch [149/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011431 ------0.0001\n",
            "Epoch [150/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011444 ------0.0001\n",
            "Epoch [151/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011408 ------0.0001\n",
            "Epoch [152/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011411 ------0.0001\n",
            "Epoch [153/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011378 ------0.0001\n",
            "Epoch [154/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011384 ------0.0001\n",
            "Epoch [155/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011365 ------0.0001\n",
            "Epoch [156/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011352 ------0.0001\n",
            "Epoch [157/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011353 ------0.0001\n",
            "Epoch [158/500] ---- Training Loss: 0.0121 ---- Validation Loss: 0.011372 ------0.0001\n",
            "Epoch [159/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011393 ------0.0001\n",
            "Epoch [160/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011401 ------0.0001\n",
            "Epoch [161/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011314 ------0.0001\n",
            "Epoch [162/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011326 ------0.0001\n",
            "Epoch [163/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011308 ------0.0001\n",
            "Epoch [164/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011294 ------0.0001\n",
            "Epoch [165/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011304 ------0.0001\n",
            "Epoch [166/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011331 ------0.0001\n",
            "Epoch [167/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011272 ------0.0001\n",
            "Epoch [168/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011250 ------0.0001\n",
            "Epoch [169/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011250 ------0.0001\n",
            "Epoch [170/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011312 ------0.0001\n",
            "Epoch [171/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011253 ------0.0001\n",
            "Epoch [172/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011241 ------0.0001\n",
            "Epoch [173/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011228 ------0.0001\n",
            "Epoch [174/500] ---- Training Loss: 0.0120 ---- Validation Loss: 0.011253 ------0.0001\n",
            "Epoch [175/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011236 ------0.0001\n",
            "Epoch [176/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011220 ------0.0001\n",
            "Epoch [177/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011214 ------0.0001\n",
            "Epoch [178/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011195 ------0.0001\n",
            "Epoch [179/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011197 ------0.0001\n",
            "Epoch [180/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011179 ------0.0001\n",
            "Epoch [181/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011202 ------0.0001\n",
            "Epoch [182/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011170 ------0.0001\n",
            "Epoch [183/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011179 ------0.0001\n",
            "Epoch [184/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011153 ------0.0001\n",
            "Epoch [185/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011145 ------0.0001\n",
            "Epoch [186/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011171 ------0.0001\n",
            "Epoch [187/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011151 ------0.0001\n",
            "Epoch [188/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011136 ------0.0001\n",
            "Epoch [189/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011141 ------0.0001\n",
            "Epoch [190/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011175 ------0.0001\n",
            "Epoch [191/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.011142 ------0.0001\n",
            "Epoch [192/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011100 ------0.0001\n",
            "Epoch [193/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011134 ------0.0001\n",
            "Epoch [194/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011084 ------0.0001\n",
            "Epoch [195/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011127 ------0.0001\n",
            "Epoch [196/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011092 ------0.0001\n",
            "Epoch [197/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011100 ------0.0001\n",
            "Epoch [198/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011102 ------0.0001\n",
            "Epoch [199/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011068 ------0.0001\n",
            "Epoch [200/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011137 ------0.0001\n",
            "Epoch [201/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011055 ------0.0001\n",
            "Epoch [202/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011081 ------0.0001\n",
            "Epoch [203/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011063 ------0.0001\n",
            "Epoch [204/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011043 ------0.0001\n",
            "Epoch [205/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011055 ------0.0001\n",
            "Epoch [206/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011036 ------0.0001\n",
            "Epoch [207/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011031 ------0.0001\n",
            "Epoch [208/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011027 ------0.0001\n",
            "Epoch [209/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011040 ------0.0001\n",
            "Epoch [210/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011042 ------0.0001\n",
            "Epoch [212/500] ---- Training Loss: 0.0118 ---- Validation Loss: 0.011010 ------0.0001\n",
            "Epoch [213/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011003 ------0.0001\n",
            "Epoch [214/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011006 ------0.0001\n",
            "Epoch [215/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011002 ------0.0001\n",
            "Epoch [216/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010996 ------0.0001\n",
            "Epoch [217/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010987 ------0.0001\n",
            "Epoch [218/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011019 ------0.0001\n",
            "Epoch [219/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.011035 ------0.0001\n",
            "Epoch [220/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010961 ------0.0001\n",
            "Epoch [221/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010975 ------0.0001\n",
            "Epoch [222/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010980 ------0.0001\n",
            "Epoch [223/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010953 ------0.0001\n",
            "Epoch [224/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010951 ------0.0001\n",
            "Epoch [225/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010963 ------0.0001\n",
            "Epoch [226/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010959 ------0.0001\n",
            "Epoch [227/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010946 ------0.0001\n",
            "Epoch [228/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010945 ------0.0001\n",
            "Epoch [229/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010927 ------0.0001\n",
            "Epoch [230/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010953 ------0.0001\n",
            "Epoch [231/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010951 ------0.0001\n",
            "Epoch [232/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010935 ------0.0001\n",
            "Epoch [233/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010900 ------0.0001\n",
            "Epoch [234/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010905 ------0.0001\n",
            "Epoch [235/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010905 ------0.0001\n",
            "Epoch [236/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010897 ------0.0001\n",
            "Epoch [237/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010979 ------0.0001\n",
            "Epoch [238/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010890 ------0.0001\n",
            "Epoch [239/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010880 ------0.0001\n",
            "Epoch [240/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010885 ------0.0001\n",
            "Epoch [241/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010880 ------0.0001\n",
            "Epoch [242/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010877 ------0.0001\n",
            "Epoch [243/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010909 ------0.0001\n",
            "Epoch [244/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010884 ------0.0001\n",
            "Epoch [245/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010872 ------0.0001\n",
            "Epoch [246/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010858 ------0.0001\n",
            "Epoch [247/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010850 ------0.0001\n",
            "Epoch [248/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010843 ------0.0001\n",
            "Epoch [249/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010845 ------0.0001\n",
            "Epoch [250/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010834 ------0.0001\n",
            "Epoch [251/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010841 ------0.0001\n",
            "Epoch [252/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010873 ------0.0001\n",
            "Epoch [253/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010828 ------0.0001\n",
            "Epoch [254/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010834 ------0.0001\n",
            "Epoch [255/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010831 ------0.0001\n",
            "Epoch [257/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010840 ------0.0001\n",
            "Epoch [258/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010819 ------0.0001\n",
            "Epoch [259/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010831 ------0.0001\n",
            "Epoch [260/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010788 ------0.0001\n",
            "Epoch [261/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010799 ------0.0001\n",
            "Epoch [262/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010876 ------0.0001\n",
            "Epoch [263/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010793 ------0.0001\n",
            "Epoch [264/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010775 ------0.0001\n",
            "Epoch [265/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010824 ------0.0001\n",
            "Epoch [266/500] ---- Training Loss: 0.0131 ---- Validation Loss: 0.011440 ------0.0001\n",
            "Epoch [267/500] ---- Training Loss: 0.0119 ---- Validation Loss: 0.010970 ------0.0001\n",
            "Epoch [268/500] ---- Training Loss: 0.0117 ---- Validation Loss: 0.010916 ------0.0001\n",
            "Epoch [269/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010862 ------0.0001\n",
            "Epoch [270/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010817 ------0.0001\n",
            "Epoch [271/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010774 ------5e-05\n",
            "Epoch [272/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010782 ------5e-05\n",
            "Epoch [273/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010780 ------5e-05\n",
            "Epoch [274/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010764 ------5e-05\n",
            "Epoch [275/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010738 ------5e-05\n",
            "Epoch [276/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010758 ------5e-05\n",
            "Epoch [277/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010758 ------5e-05\n",
            "Epoch [278/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010751 ------5e-05\n",
            "Epoch [279/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010733 ------5e-05\n",
            "Epoch [280/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010732 ------5e-05\n",
            "Epoch [281/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010751 ------5e-05\n",
            "Epoch [282/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010730 ------5e-05\n",
            "Epoch [283/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010728 ------5e-05\n",
            "Epoch [284/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010754 ------5e-05\n",
            "Epoch [285/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010726 ------5e-05\n",
            "Epoch [286/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010721 ------5e-05\n",
            "Epoch [287/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010733 ------5e-05\n",
            "Epoch [288/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010719 ------5e-05\n",
            "Epoch [289/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010716 ------5e-05\n",
            "Epoch [290/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010722 ------5e-05\n",
            "Epoch [291/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010729 ------5e-05\n",
            "Epoch [292/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010719 ------5e-05\n",
            "Epoch [293/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010695 ------5e-05\n",
            "Epoch [294/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010707 ------5e-05\n",
            "Epoch [295/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010704 ------5e-05\n",
            "Epoch [296/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010690 ------5e-05\n",
            "Epoch [297/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010692 ------5e-05\n",
            "Epoch [298/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010705 ------5e-05\n",
            "Epoch [299/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010701 ------5e-05\n",
            "Epoch [300/500] ---- Training Loss: 0.0116 ---- Validation Loss: 0.010805 ------5e-05\n",
            "Epoch [301/500] ---- Training Loss: 0.0115 ---- Validation Loss: 0.010731 ------5e-05\n",
            "Epoch [303/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010676 ------2.5e-05\n",
            "Epoch [304/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010674 ------2.5e-05\n",
            "Epoch [305/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010693 ------2.5e-05\n",
            "Epoch [306/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010669 ------2.5e-05\n",
            "Epoch [307/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010682 ------2.5e-05\n",
            "Epoch [308/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010673 ------2.5e-05\n",
            "Epoch [309/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010687 ------2.5e-05\n",
            "Epoch [310/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010676 ------2.5e-05\n",
            "Epoch [311/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010674 ------2.5e-05\n",
            "Epoch [312/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010674 ------2.5e-05\n",
            "Epoch [313/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010673 ------1.25e-05\n",
            "Epoch [314/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010664 ------1.25e-05\n",
            "Epoch [315/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010668 ------1.25e-05\n",
            "Epoch [316/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010657 ------1.25e-05\n",
            "Epoch [317/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010660 ------1.25e-05\n",
            "Epoch [318/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010659 ------1.25e-05\n",
            "Epoch [319/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010654 ------1.25e-05\n",
            "Epoch [320/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010656 ------1.25e-05\n",
            "Epoch [321/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010656 ------1.25e-05\n",
            "Epoch [322/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010652 ------1.25e-05\n",
            "Epoch [323/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010656 ------1.25e-05\n",
            "Epoch [324/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010662 ------1.25e-05\n",
            "Epoch [325/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010653 ------1.25e-05\n",
            "Epoch [326/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010657 ------1.25e-05\n",
            "Epoch [327/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010652 ------1.25e-05\n",
            "Epoch [328/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010653 ------1.25e-05\n",
            "Epoch [329/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010650 ------6.25e-06\n",
            "Epoch [330/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010651 ------6.25e-06\n",
            "Epoch [331/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010647 ------6.25e-06\n",
            "Epoch [332/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010646 ------6.25e-06\n",
            "Epoch [333/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010643 ------6.25e-06\n",
            "Epoch [334/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010646 ------6.25e-06\n",
            "Epoch [335/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010646 ------6.25e-06\n",
            "Epoch [336/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010647 ------6.25e-06\n",
            "Epoch [337/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010643 ------6.25e-06\n",
            "Epoch [338/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010643 ------6.25e-06\n",
            "Epoch [339/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010642 ------6.25e-06\n",
            "Epoch [340/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010642 ------3.125e-06\n",
            "Epoch [341/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010642 ------3.125e-06\n",
            "Epoch [342/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010645 ------3.125e-06\n",
            "Epoch [343/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010643 ------3.125e-06\n",
            "Epoch [344/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010643 ------3.125e-06\n",
            "Epoch [345/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010640 ------3.125e-06\n",
            "Epoch [346/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010642 ------3.125e-06\n",
            "Epoch [347/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010641 ------3.125e-06\n",
            "Epoch [349/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010644 ------3.125e-06\n",
            "Epoch [350/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010642 ------3.125e-06\n",
            "Epoch [351/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010642 ------3.125e-06\n",
            "Epoch [352/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010639 ------1.5625e-06\n",
            "Epoch [353/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010640 ------1.5625e-06\n",
            "Epoch [354/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010639 ------1.5625e-06\n",
            "Epoch [355/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010639 ------1.5625e-06\n",
            "Epoch [356/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010643 ------1.5625e-06\n",
            "Epoch [357/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010640 ------1.5625e-06\n",
            "Epoch [358/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------1.5625e-06\n",
            "Epoch [359/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010639 ------1.5625e-06\n",
            "Epoch [360/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010641 ------1.5625e-06\n",
            "Epoch [361/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010640 ------1.5625e-06\n",
            "Epoch [362/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------1.5625e-06\n",
            "Epoch [363/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------1.5625e-06\n",
            "Epoch [364/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------1.5625e-06\n",
            "Epoch [365/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------7.8125e-07\n",
            "Epoch [366/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------7.8125e-07\n",
            "Epoch [367/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------7.8125e-07\n",
            "Epoch [368/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------7.8125e-07\n",
            "Epoch [369/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------7.8125e-07\n",
            "Epoch [370/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------7.8125e-07\n",
            "Epoch [371/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------3.90625e-07\n",
            "Epoch [372/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------3.90625e-07\n",
            "Epoch [373/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------3.90625e-07\n",
            "Epoch [374/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------3.90625e-07\n",
            "Epoch [375/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------3.90625e-07\n",
            "Epoch [376/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------3.90625e-07\n",
            "Epoch [377/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------1.953125e-07\n",
            "Epoch [378/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------1.953125e-07\n",
            "Epoch [379/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------1.953125e-07\n",
            "Epoch [380/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------1.953125e-07\n",
            "Epoch [381/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------1.953125e-07\n",
            "Epoch [382/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------1.953125e-07\n",
            "Epoch [383/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------9.765625e-08\n",
            "Epoch [384/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------9.765625e-08\n",
            "Epoch [385/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------9.765625e-08\n",
            "Epoch [386/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------9.765625e-08\n",
            "Epoch [387/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------9.765625e-08\n",
            "Epoch [388/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------9.765625e-08\n",
            "Epoch [389/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010637 ------4.8828125e-08\n",
            "Epoch [390/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------4.8828125e-08\n",
            "Epoch [391/500] ---- Training Loss: 0.0114 ---- Validation Loss: 0.010638 ------4.8828125e-08\n",
            "Early stopping at epoch 391\n",
            "Saved model: mode_without_coolant_qani.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgiHLL31mUEE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg9vSugumUBg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o2xWWKvmT67"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7RXfsU_mNR8"
      },
      "source": [
        "#test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL109hS0blFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWKVbu6QblCQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT91Xk2ibldP"
      },
      "source": [
        "#Test with all saved model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vfRAe8DYqq9",
        "outputId": "4a9e6e9f-e3b5-4290-fd04-bfac942c0857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5cd25837113a>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 137.3655---------------/content/Trip_6.csv\n",
            "MSE: 38201.5778\n",
            "MAPE: 39.4800% ---------------------\n",
            "CSV saved as: predicted_vs_actual_plots/normal_cool_label/Trip_6.csv\n",
            "MAE: 125.2293---------------/content/Trip_10.csv\n",
            "MSE: 34540.3212\n",
            "MAPE: 43.0371% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5cd25837113a>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/normal_cool_label/Trip_10.csv\n",
            "MAE: 83.9051---------------/content/Trip_14.csv\n",
            "MSE: 18517.5993\n",
            "MAPE: 34.9249% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5cd25837113a>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/normal_cool_label/Trip_14.csv\n",
            "MAE: 127.0445---------------/content/Trip_9.csv\n",
            "MSE: 37333.3420\n",
            "MAPE: 32.9476% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5cd25837113a>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/normal_cool_label/Trip_9.csv\n",
            "MAE: 120.2167---------------/content/Trip_7.csv\n",
            "MSE: 32960.3006\n",
            "MAPE: 39.9720% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5cd25837113a>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/normal_cool_label/Trip_7.csv\n",
            "MAE: 123.5145---------------/content/Trip_11.csv\n",
            "MSE: 31435.2974\n",
            "MAPE: 37.3559% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5cd25837113a>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/normal_cool_label/Trip_11.csv\n",
            "MAE: 123.7641---------------/content/Trip_1.csv\n",
            "MSE: 31012.5023\n",
            "MAPE: 36.1342% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5cd25837113a>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/normal_cool_label/Trip_1.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # df = df.iloc[::2].reset_index(drop=True)\n",
        "    df['Time'] = df['time'] - df['time'].iloc[0]\n",
        "    df['Trip fuel consumption'] = df['Trip_fuel_consumption'] - df['Trip_fuel_consumption'].iloc[0]\n",
        "    df['Acceleration'] = df['Vehicle_Speed'].diff().fillna(0)\n",
        "    df['Momentary fuel consumption'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "\n",
        "    df['Adjusted_gear_position'] = df['Current_gear_shift_position_(Current_gear)'].replace({13: 0, 14: 1})\n",
        "\n",
        "    # Selecting features and target\n",
        "    features = df[['Adjusted_gear_position', 'Vehicle_Speed', 'slope', 'Acceleration','Coolant_temperature']]\n",
        "    target = df['Momentary fuel consumption']\n",
        "    target = df['Momentary fuel consumption']\n",
        "    return features, target\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "    min_val_x = [0, 0, -10, -10,0]\n",
        "    max_val_x = [6, 150, 10, 10,130]\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "    features, actual_values = process_file(input_file)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values])\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * 10000)\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * 10000)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "    # Calculate error metrics\n",
        "    mae = mean_absolute_error(actual_valuess, predictions)\n",
        "    mse = mean_squared_error(actual_valuess, predictions)\n",
        "\n",
        "    # Handling MAPE: Ignore zero actual values to avoid NaN issues\n",
        "    non_zero_actual = actual_valuess != 0\n",
        "    mape = np.mean(np.abs((actual_valuess[non_zero_actual] - predictions[non_zero_actual]) / actual_valuess[non_zero_actual])) * 100\n",
        "\n",
        "    print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions[:len(actual_values)], axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Create model-specific directory\n",
        "    model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "    # Save plot using model name in the designated directory\n",
        "    plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "    # Save predictions and actual values to CSV using model name in the designated directory\n",
        "    results_df = pd.DataFrame({\n",
        "        'Speed': features[\"Vehicle_Speed\"].iloc[:len(predictions)],\n",
        "        'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "        'Predicted': np.cumsum(predictions[:len(actual_values)], axis=0),\n",
        "        'MAE': mae,  # Add MAE to the dataframe\n",
        "        'MSE': mse,  # Add MSE to the dataframe\n",
        "        'MAPE': mape  # Add MAPE to the dataframe\n",
        "    })\n",
        "\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "\n",
        "\n",
        "\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content/'  # Directory containing CSV files\n",
        "model_dir = '/content/'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **test with standard**"
      ],
      "metadata": {
        "id": "CQ60DFcE6J9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load standardization parameters from JSON\n",
        "def load_normalization_params(json_file):\n",
        "    with open(json_file, 'r') as f:\n",
        "        params = json.load(f)\n",
        "    mean_x = torch.tensor(params['mean_x'], dtype=torch.float32).to(DEVICE)\n",
        "    std_x = torch.tensor(params['std_x'], dtype=torch.float32).to(DEVICE)\n",
        "    mean_y = torch.tensor(params['mean_y'], dtype=torch.float32).to(DEVICE)\n",
        "    std_y = torch.tensor(params['std_y'], dtype=torch.float32).to(DEVICE)\n",
        "    return mean_x, std_x, mean_y, std_y\n",
        "\n",
        "# Custom standardization function for X\n",
        "def custom_standardize_X(data, mean_vals, std_vals):\n",
        "    for i in range(data.shape[-1]):\n",
        "        data[:, :, i] = (data[:, :, i] - mean_vals[i]) / std_vals[i]\n",
        "    return data\n",
        "\n",
        "# Custom standardization function for y\n",
        "def custom_standardize_y(data, mean_val, std_val):\n",
        "    return (data - mean_val) / std_val\n",
        "\n",
        "# Process the file and standardize the data\n",
        "def process_file(file_path, mean_x, std_x, mean_y, std_y):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['Time'] = df['time'] - df['time'].iloc[0]\n",
        "    df['Trip fuel consumption'] = df['Trip_fuel_consumption'] - df['Trip_fuel_consumption'].iloc[0]\n",
        "    df['Acceleration'] = df['Vehicle_Speed'].diff().fillna(0)\n",
        "    df['Momentary fuel consumption'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "    df['Adjusted_gear_position'] = df['Current_gear_shift_position_(Current_gear)'].replace({13: 0, 14: 1})\n",
        "\n",
        "    # Selecting features and target\n",
        "    features = df[['Adjusted_gear_position', 'Vehicle_Speed', 'slope', 'Acceleration','Coolant_temperature']]\n",
        "    target = df['Momentary fuel consumption']\n",
        "\n",
        "    # Convert features and target to tensors\n",
        "    features = torch.tensor(features.values, dtype=torch.float32).to(DEVICE)\n",
        "    target = torch.tensor(target.values, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "    # Apply standardization\n",
        "    features = custom_standardize_X(features.unsqueeze(0), mean_x, std_x).squeeze(0)\n",
        "    # target = custom_standardize_y(target, mean_y, std_y)\n",
        "\n",
        "    return features, target\n",
        "\n",
        "# Plot and predict function updated to handle standardization\n",
        "def plot_predicted_vs_real(input_file, model, model_name, mean_x, std_x, mean_y, std_y):\n",
        "    features, actual_values = process_file(input_file, mean_x, std_x, mean_y, std_y)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment = segment.unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * std_y.cpu().numpy() + mean_y.cpu().numpy())  # De-standardize\n",
        "\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features[-remainder:]\n",
        "        last_segment = last_segment.unsqueeze(0).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * std_y.cpu().numpy() + mean_y.cpu().numpy())  # De-standardize\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_values = actual_values.cpu().numpy()\n",
        "\n",
        "    # Calculate error metrics\n",
        "    mae = mean_absolute_error(actual_values[:len(predictions)], predictions)\n",
        "    mse = mean_squared_error(actual_values[:len(predictions)], predictions)\n",
        "    mape = np.mean(np.abs((actual_values[actual_values != 0] - predictions[actual_values != 0]) / actual_values[actual_values != 0])) * 100\n",
        "\n",
        "    print(f'MAE: {mae:.4f}')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAPE: {mape:.4f}%')\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions, axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Save plot and CSV\n",
        "    model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "    plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "    # Save predictions and actual values to CSV\n",
        "    results_df = pd.DataFrame({\n",
        "        'Actual': np.cumsum(actual_values[:len(predictions)], axis=0),\n",
        "        'Predicted': np.cumsum(predictions, axis=0),\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'MAPE': mape\n",
        "    })\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "\n",
        "# Load normalization parameters\n",
        "mean_x, std_x, mean_y, std_y = load_normalization_params('normalization_params.json')\n",
        "\n",
        "# Directory containing models and CSV files\n",
        "csv_dir = '/content/'  # Directory containing CSV files\n",
        "model_dir = '/content/'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name, mean_x, std_x, mean_y, std_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTSBP7ro59SJ",
        "outputId": "fcc9854f-97a1-4d35-bb62-21192d1132c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4a07419542e7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 99.6755\n",
            "MSE: 22994.7266\n",
            "MAPE: 27.3571%\n",
            "CSV saved as: predicted_vs_actual_plots/standard/Trip_6.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4a07419542e7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 114.7762\n",
            "MSE: 29097.2461\n",
            "MAPE: 38.0841%\n",
            "CSV saved as: predicted_vs_actual_plots/standard/Trip_10.csv\n",
            "MAE: 89.0312\n",
            "MSE: 19630.9121\n",
            "MAPE: 33.8231%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4a07419542e7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/standard/Trip_14.csv\n",
            "MAE: 101.0770\n",
            "MSE: 23146.1484\n",
            "MAPE: 27.2206%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4a07419542e7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/standard/Trip_9.csv\n",
            "MAE: 108.2769\n",
            "MSE: 28300.8262\n",
            "MAPE: 34.8556%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4a07419542e7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/standard/Trip_7.csv\n",
            "MAE: 115.1765\n",
            "MSE: 28360.5820\n",
            "MAPE: 34.3892%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4a07419542e7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/standard/Trip_11.csv\n",
            "MAE: 105.1960\n",
            "MSE: 24824.9082\n",
            "MAPE: 29.8032%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4a07419542e7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/standard/Trip_1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # df = df.iloc[::2].reset_index(drop=True)\n",
        "    df['Time'] = df['time'] - df['time'].iloc[0]\n",
        "    df['Trip fuel consumption'] = df['Trip_fuel_consumption'] - df['Trip_fuel_consumption'].iloc[0]\n",
        "    df['Acceleration'] = df['Vehicle_Speed'].diff().fillna(0)\n",
        "    df['Momentary fuel consumption'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "\n",
        "    df['Adjusted_gear_position'] = df['Current_gear_shift_position_(Current_gear)'].replace({13: 0, 14: 1})\n",
        "\n",
        "    # Selecting features and target\n",
        "    features = df[['Adjusted_gear_position', 'Vehicle_Speed', 'slope', 'Acceleration']]\n",
        "    target = df['Momentary fuel consumption']\n",
        "    target = df['Momentary fuel consumption']\n",
        "    return features, target\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "    min_val_x = [0, 0, -10, -10]\n",
        "    max_val_x = [6, 150, 10, 10]\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "    features, actual_values = process_file(input_file)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values])\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * 10000)\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * 10000)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "    # Calculate error metrics\n",
        "    mae = mean_absolute_error(actual_valuess, predictions)\n",
        "    mse = mean_squared_error(actual_valuess, predictions)\n",
        "    mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n",
        "\n",
        "    print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions[:len(actual_values)], axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Create model-specific directory\n",
        "    model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "    # Save plot using model name in the designated directory\n",
        "    plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "    # print(f\"Plot saved as: {plot_filename}\")\n",
        "\n",
        "    # Save predictions and actual values to CSV using model name in the designated directory\n",
        "    results_df = pd.DataFrame({\n",
        "        'Speed': features[\"Vehicle_Speed\"].iloc[:len(predictions)],\n",
        "        'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "        'Predicted': np.cumsum(predictions[:len(actual_values)], axis=0)\n",
        "    })\n",
        "\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content/'  # Directory containing CSV files\n",
        "model_dir = '/content/sample_data'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 4  # Number of features in the input data\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O7rIrdKqwen",
        "outputId": "b994573e-6a71-4e2f-cb20-e4e537901ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-182cf7f1c968>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-4-182cf7f1c968>:92: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 113.0766---------------/content/Trip_6.csv\n",
            "MSE: 35633.3350\n",
            "MAPE: inf% ---------------------\n",
            "CSV saved as: predicted_vs_actual_plots/mode_without_coolant_qani/Trip_6.csv\n",
            "MAE: 83.1384---------------/content/Trip_14.csv\n",
            "MSE: 18288.2864\n",
            "MAPE: inf% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-182cf7f1c968>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-4-182cf7f1c968>:92: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/mode_without_coolant_qani/Trip_14.csv\n",
            "MAE: 115.1571---------------/content/Trip_1.csv\n",
            "MSE: 28171.8981\n",
            "MAPE: inf% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-182cf7f1c968>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-4-182cf7f1c968>:92: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/mode_without_coolant_qani/Trip_1.csv\n",
            "MAE: 108.3970---------------/content/Trip_11.csv\n",
            "MSE: 31005.8215\n",
            "MAPE: inf% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-182cf7f1c968>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-4-182cf7f1c968>:92: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/mode_without_coolant_qani/Trip_11.csv\n",
            "MAE: 121.8157---------------/content/Trip_10.csv\n",
            "MSE: 36707.0167\n",
            "MAPE: inf% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-182cf7f1c968>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-4-182cf7f1c968>:92: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/mode_without_coolant_qani/Trip_10.csv\n",
            "MAE: 110.9029---------------/content/Trip_9.csv\n",
            "MSE: 30403.2715\n",
            "MAPE: inf% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-182cf7f1c968>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-4-182cf7f1c968>:92: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/mode_without_coolant_qani/Trip_9.csv\n",
            "MAE: 110.2581---------------/content/Trip_7.csv\n",
            "MSE: 37758.2352\n",
            "MAPE: inf% ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-182cf7f1c968>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-4-182cf7f1c968>:92: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV saved as: predicted_vs_actual_plots/mode_without_coolant_qani/Trip_7.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypRXnIRHZK15"
      },
      "outputs": [],
      "source": [
        "!rm -r '/content/predicted_vs_actual_plots'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld0z9cg9-Fth",
        "outputId": "78bdaffb-b2a9-4248-c725-f9b9bd15ffcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: predicted_vs_actual_plots/ (stored 0%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/ (stored 0%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_6.csv (deflated 85%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_10.csv (deflated 85%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_14.csv (deflated 85%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_9_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_9.csv (deflated 86%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_7_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_14_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_10_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_1_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_11_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_7.csv (deflated 85%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_6_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/DENA_TC+_MT_BARBOD_clean_0.5_all.png (deflated 9%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_11.csv (deflated 86%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/DENA_TC+_MT_BARBOD_clean_0.5.csv (deflated 82%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label/Trip_1.csv (deflated 85%)\n",
            "  adding: predicted_vs_actual_plots/normal_cool_label.pth (deflated 9%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r predicted_vs_actual_plots.zip predicted_vs_actual_plots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # df = df.iloc[::2].reset_index(drop=True)\n",
        "    df['Time'] = df['time'] - df['time'].iloc[0]\n",
        "    df['Trip fuel consumption'] = df['sys_trip_fc\\CCP:1'] - df['sys_trip_fc\\CCP:1'].iloc[0]\n",
        "    df['Acceleration'] = df['sys_veh_spd\\CCP:1'].diff().fillna(0)\n",
        "    df['Momentary fuel consumption'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "    df['slope'] = 0\n",
        "\n",
        "\n",
        "\n",
        "    # Selecting features and target\n",
        "    features = df[['trs_mt_gr_st\\CCP:1', 'sys_veh_spd\\CCP:1', 'slope', 'Acceleration','sys_ect\\CCP:1']]\n",
        "    target = df['Momentary fuel consumption']\n",
        "    target = df['Momentary fuel consumption']\n",
        "    return features, target\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "    min_val_x = [0, 0, -10, -10,0]\n",
        "    max_val_x = [6, 150, 10, 10,130]\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "    features, actual_values = process_file(input_file)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values])\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * 10000)\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * 10000)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "    # Calculate error metrics\n",
        "    mae = mean_absolute_error(actual_valuess, predictions)\n",
        "    mse = mean_squared_error(actual_valuess, predictions)\n",
        "    mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n",
        "\n",
        "    print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions[:len(actual_values)], axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Create model-specific directory\n",
        "    model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "    # Save plot using model name in the designated directory\n",
        "    plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "    # print(f\"Plot saved as: {plot_filename}\")\n",
        "\n",
        "    # Save predictions and actual values to CSV using model name in the designated directory\n",
        "    results_df = pd.DataFrame({\n",
        "        'Speed': features[\"sys_veh_spd\\CCP:1\"].iloc[:len(predictions)],\n",
        "        'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "        'Predicted': np.cumsum(predictions[:len(actual_values)], axis=0)\n",
        "    })\n",
        "\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content/nedc'  # Directory containing CSV files\n",
        "model_dir = '/content/'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKzjj0r_n5db",
        "outputId": "5d33502c-a07c-4127-bc6b-4bf99b2bbfb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b7c5130fe602>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-3-b7c5130fe602>:93: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 122.8158---------------/content/nedc/DENA_TC+_MT_BARBOD_clean_0.5.csv\n",
            "MSE: 51781.1435\n",
            "MAPE: inf% ---------------------\n",
            "CSV saved as: predicted_vs_actual_plots/mode_with_coolant_qani/DENA_TC+_MT_BARBOD_clean_0.5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # df = df.iloc[::2].reset_index(drop=True)\n",
        "    df['Time'] = df['time'] - df['time'].iloc[0]\n",
        "    df['Trip fuel consumption'] = df['sys_trip_fc\\CCP:1'] - df['sys_trip_fc\\CCP:1'].iloc[0]\n",
        "    df['Acceleration'] = df['sys_veh_spd\\CCP:1'].diff().fillna(0)\n",
        "    df['Momentary fuel consumption'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "    df['slope'] = 0\n",
        "\n",
        "\n",
        "\n",
        "    # Selecting features and target\n",
        "    features = df[['trs_mt_gr_st\\CCP:1', 'sys_veh_spd\\CCP:1', 'slope', 'Acceleration']]\n",
        "    target = df['Momentary fuel consumption']\n",
        "    target = df['Momentary fuel consumption']\n",
        "    return features, target\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "    min_val_x = [0, 0, -10, -10]\n",
        "    max_val_x = [6, 150, 10, 10]\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "    features, actual_values = process_file(input_file)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values])\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * 10000)\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * 10000)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "    # Calculate error metrics\n",
        "    mae = mean_absolute_error(actual_valuess, predictions)\n",
        "    mse = mean_squared_error(actual_valuess, predictions)\n",
        "    mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n",
        "\n",
        "    print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions[:len(actual_values)], axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Create model-specific directory\n",
        "    model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "    # Save plot using model name in the designated directory\n",
        "    plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "    # print(f\"Plot saved as: {plot_filename}\")\n",
        "\n",
        "    # Save predictions and actual values to CSV using model name in the designated directory\n",
        "    results_df = pd.DataFrame({\n",
        "        'Speed': features[\"sys_veh_spd\\CCP:1\"].iloc[:len(predictions)],\n",
        "        'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "        'Predicted': np.cumsum(predictions[:len(actual_values)], axis=0)\n",
        "    })\n",
        "\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content/nedc'  # Directory containing CSV files\n",
        "model_dir = '/content/sample_data'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 4  # Number of features in the input data\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu64c1AYrXW6",
        "outputId": "a23d8be9-dc27-416d-e591-6594852f480f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-517358e916c3>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
            "<ipython-input-5-517358e916c3>:93: RuntimeWarning: divide by zero encountered in divide\n",
            "  mape = np.mean(np.abs((actual_valuess - predictions) / actual_valuess)) * 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 211.5234---------------/content/nedc/DENA_TC+_MT_BARBOD_clean_0.5.csv\n",
            "MSE: 149690.9398\n",
            "MAPE: inf% ---------------------\n",
            "CSV saved as: predicted_vs_actual_plots/mode_without_coolant_qani/DENA_TC+_MT_BARBOD_clean_0.5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **nedc normal**"
      ],
      "metadata": {
        "id": "dgGaKYLhRIFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Process the file and prepare segments\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # df = df.iloc[::2].reset_index(drop=True)\n",
        "    df['Trip fuel consumption'] = df['sys_trip_fc\\CCP:1'] - df['sys_trip_fc\\CCP:1'].iloc[0]\n",
        "    df['Acceleration'] = df['sys_veh_spd\\CCP:1'].diff().fillna(0)\n",
        "    df['Momentary fuel consumption'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "    df['slope'] = 0\n",
        "    # Selecting features and target\n",
        "    features = df[['trs_mt_gr_st\\CCP:1', 'sys_veh_spd\\CCP:1', 'slope', 'Acceleration','sys_ect\\CCP:1']]\n",
        "    target = df['Momentary fuel consumption']\n",
        "    target = df['Momentary fuel consumption']\n",
        "    return features, target\n",
        "\n",
        "# Pad and normalize the data\n",
        "def pad_and_normalize(data, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = np.zeros((len(data), sequence_length, data[0].shape[1]))\n",
        "    for i, seq in enumerate(data):\n",
        "        length = min(len(seq), sequence_length)\n",
        "        padded_data[i, :length] = seq[:length]\n",
        "\n",
        "    # Normalization (same as in your script)\n",
        "    min_val_x = [0, 0, -10, -10,0]\n",
        "    max_val_x = [6, 150, 10, 10,130]\n",
        "    for i in range(padded_data.shape[-1]):\n",
        "        padded_data[:, :, i] = (padded_data[:, :, i] - min_val_x[i]) / (max_val_x[i] - min_val_x[i])\n",
        "\n",
        "    return torch.tensor(padded_data, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Predict and plot the results\n",
        "def plot_predicted_vs_real(input_file, model, model_name):\n",
        "    features, actual_values = process_file(input_file)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features.iloc[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment_normalized = pad_and_normalize([segment.values])\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment_normalized).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * 10000)\n",
        "\n",
        "    # Handle any remaining data\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features.iloc[-remainder:]\n",
        "        last_segment_normalized = pad_and_normalize([last_segment.values], sequence_length=remainder)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment_normalized).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * 10000)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_valuess = actual_values.values[:len(predictions)]  # Ensure lengths match\n",
        "\n",
        "    # Calculate error metrics\n",
        "    mae = mean_absolute_error(actual_valuess, predictions)\n",
        "    mse = mean_squared_error(actual_valuess, predictions)\n",
        "\n",
        "    # Handling MAPE: Ignore zero actual values to avoid NaN issues\n",
        "    non_zero_actual = actual_valuess != 0\n",
        "    mape = np.mean(np.abs((actual_valuess[non_zero_actual] - predictions[non_zero_actual]) / actual_valuess[non_zero_actual])) * 100\n",
        "\n",
        "    print(f'MAE: {mae:.4f}---------------{input_file}')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAPE: {mape:.4f}% ---------------------')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values.values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions[:len(actual_values)], axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Create model-specific directory\n",
        "    model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "    # Save plot using model name in the designated directory\n",
        "    plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "    # Save predictions and actual values to CSV using model name in the designated directory\n",
        "    results_df = pd.DataFrame({\n",
        "        'Speed': features[\"sys_veh_spd\\CCP:1\"].iloc[:len(predictions)],\n",
        "        'Actual': np.cumsum(actual_values.values[:len(predictions)], axis=0),\n",
        "        'Predicted': np.cumsum(predictions[:len(actual_values)], axis=0),\n",
        "        'MAE': mae,  # Add MAE to the dataframe\n",
        "        'MSE': mse,  # Add MSE to the dataframe\n",
        "        'MAPE': mape  # Add MAPE to the dataframe\n",
        "    })\n",
        "\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "\n",
        "\n",
        "\n",
        "# Directory containing all saved models and CSV files\n",
        "csv_dir = '/content/sample_data'  # Directory containing CSV files\n",
        "model_dir = '/content/'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    # print(f\"Processing CSV file: {csv_file}\")\n",
        "\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]  # Get the base name of the model file\n",
        "        # print(f\"Testing model: {model_name} on {csv_file}\")\n",
        "\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "E1NcivzxRJfD",
        "outputId": "29ead6af-c1f7-4231-fc60-413dd11c7bf5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-132c72367bff>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 129.1715---------------/content/sample_data/DENA_TC+_MT_BARBOD_clean_0.5.csv\n",
            "MSE: 29526.8297\n",
            "MAPE: 59.5253% ---------------------\n",
            "CSV saved as: predicted_vs_actual_plots/normal_cool_label/DENA_TC+_MT_BARBOD_clean_0.5.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-132c72367bff>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'sys_trip_fc\\\\CCP:1'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sys_trip_fc\\\\CCP:1'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-132c72367bff>\u001b[0m in \u001b[0;36m<cell line: 146>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mplot_predicted_vs_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-132c72367bff>\u001b[0m in \u001b[0;36mplot_predicted_vs_real\u001b[0;34m(input_file, model, model_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Predict and plot the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_predicted_vs_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mnum_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-132c72367bff>\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# df = df.iloc[::2].reset_index(drop=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trip fuel consumption'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sys_trip_fc\\CCP:1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sys_trip_fc\\CCP:1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Acceleration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sys_veh_spd\\CCP:1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Momentary fuel consumption'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trip fuel consumption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sys_trip_fc\\\\CCP:1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/DENA_TC+_MT_BARBOD_clean_0.5.csv')"
      ],
      "metadata": {
        "id": "Pa2UprUUSDpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08qckm7xSHUk",
        "outputId": "5052c3b7-8413-44c1-8c9c-a28f2d3a526b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['time', 'sys_ect\\CCP:1', 'hw_bat_vlt\\CCP:1', 'sys_bst_t\\CCP:1',\n",
              "       'trs_mt_gr_st\\CCP:1', 'sys_veh_spd\\CCP:1', 'fmsp_af_sp\\CCP:1',\n",
              "       'sys_map\\CCP:1', 'sys_pps_pct\\CCP:1', 'tq_clch_torq\\CCP:1',\n",
              "       'sys_tps_pct\\CCP:1', 'sys_bst_p\\CCP:1', 'afm_stk_flw\\CCP:1',\n",
              "       'afm_stk_flw_pct\\CCP:1', 'tq_imep_ref\\CCP:1', 'sys_fc_avg_rate\\CCP:1',\n",
              "       'sys_eng_spd\\CCP:1', 'sys_trip_fc\\CCP:1', 'knck_ron_fac\\CCP:1',\n",
              "       'sys_iat\\CCP:1'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test standard**"
      ],
      "metadata": {
        "id": "xxD9Z6uTS15N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Constants\n",
        "SEQUENCE_LENGTH = 600  # Updated sequence length\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots'  # Base directory to save plots and CSVs\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure the base save directory exists\n",
        "os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the PyTorch model structure (same as the one used for training)\n",
        "\n",
        "\n",
        "# Load the trained model\n",
        "def load_trained_model(model_path, input_size):\n",
        "    model = FuelConsumptionModel(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load standardization parameters from JSON\n",
        "def load_normalization_params(json_file):\n",
        "    with open(json_file, 'r') as f:\n",
        "        params = json.load(f)\n",
        "    mean_x = torch.tensor(params['mean_x'], dtype=torch.float32).to(DEVICE)\n",
        "    std_x = torch.tensor(params['std_x'], dtype=torch.float32).to(DEVICE)\n",
        "    mean_y = torch.tensor(params['mean_y'], dtype=torch.float32).to(DEVICE)\n",
        "    std_y = torch.tensor(params['std_y'], dtype=torch.float32).to(DEVICE)\n",
        "    return mean_x, std_x, mean_y, std_y\n",
        "\n",
        "# Custom standardization function for X\n",
        "def custom_standardize_X(data, mean_vals, std_vals):\n",
        "    for i in range(data.shape[-1]):\n",
        "        data[:, :, i] = (data[:, :, i] - mean_vals[i]) / std_vals[i]\n",
        "    return data\n",
        "\n",
        "# Custom standardization function for y\n",
        "def custom_standardize_y(data, mean_val, std_val):\n",
        "    return (data - mean_val) / std_val\n",
        "\n",
        "# Process the file and standardize the data\n",
        "def process_file(file_path, mean_x, std_x, mean_y, std_y):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df['Trip fuel consumption'] = df['sys_trip_fc\\CCP:1'] - df['sys_trip_fc\\CCP:1'].iloc[0]\n",
        "    df['Acceleration'] = df['sys_veh_spd\\CCP:1'].diff().fillna(0)\n",
        "    df['Momentary fuel consumption'] = df['Trip fuel consumption'].diff().fillna(0)\n",
        "    df['slope'] = 0\n",
        "    # Selecting features and target\n",
        "    features = df[['trs_mt_gr_st\\CCP:1', 'sys_veh_spd\\CCP:1', 'slope', 'Acceleration','sys_ect\\CCP:1']]\n",
        "    target = df['Momentary fuel consumption']\n",
        "    target = df['Momentary fuel consumption']\n",
        "\n",
        "    # Convert features and target to tensors\n",
        "    features = torch.tensor(features.values, dtype=torch.float32).to(DEVICE)\n",
        "    target = torch.tensor(target.values, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "    # Apply standardization\n",
        "    features = custom_standardize_X(features.unsqueeze(0), mean_x, std_x).squeeze(0)\n",
        "    # target = custom_standardize_y(target, mean_y, std_y)\n",
        "\n",
        "    return features, target\n",
        "\n",
        "# Plot and predict function updated to handle standardization\n",
        "def plot_predicted_vs_real(input_file, model, model_name, mean_x, std_x, mean_y, std_y):\n",
        "    features, actual_values = process_file(input_file, mean_x, std_x, mean_y, std_y)\n",
        "    num_segments = len(features) // SEQUENCE_LENGTH\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        segment = features[i * SEQUENCE_LENGTH:(i + 1) * SEQUENCE_LENGTH]\n",
        "        segment = segment.unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
        "        with torch.no_grad():\n",
        "            segment_predictions = model(segment).cpu().numpy()\n",
        "        predictions.extend(segment_predictions.flatten() * std_y.cpu().numpy() + mean_y.cpu().numpy())  # De-standardize\n",
        "\n",
        "    remainder = len(features) % SEQUENCE_LENGTH\n",
        "    if remainder != 0:\n",
        "        last_segment = features[-remainder:]\n",
        "        last_segment = last_segment.unsqueeze(0).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            last_segment_predictions = model(last_segment).cpu().numpy()\n",
        "        predictions.extend(last_segment_predictions.flatten() * std_y.cpu().numpy() + mean_y.cpu().numpy())  # De-standardize\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    actual_values = actual_values.cpu().numpy()\n",
        "\n",
        "    # Calculate error metrics\n",
        "    mae = mean_absolute_error(actual_values[:len(predictions)], predictions)\n",
        "    mse = mean_squared_error(actual_values[:len(predictions)], predictions)\n",
        "    mape = np.mean(np.abs((actual_values[actual_values != 0] - predictions[actual_values != 0]) / actual_values[actual_values != 0])) * 100\n",
        "\n",
        "    print(f'MAE: {mae:.4f}')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAPE: {mape:.4f}%')\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(np.cumsum(actual_values[:len(predictions)], axis=0), label='Real', color='blue')\n",
        "    plt.plot(np.cumsum(predictions, axis=0), label='Predicted', color='red')\n",
        "    plt.xlabel('Index')\n",
        "    plt.ylabel('Fuel Consumption')\n",
        "    plt.title(f'Predicted vs Real Fuel Consumption ({model_name})')\n",
        "    plt.legend()\n",
        "\n",
        "    # Save plot and CSV\n",
        "    model_save_dir = os.path.join(PLOT_SAVE_DIR, model_name)\n",
        "    os.makedirs(model_save_dir, exist_ok=True)\n",
        "    plot_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}_all.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()\n",
        "\n",
        "    # Save predictions and actual values to CSV\n",
        "    results_df = pd.DataFrame({\n",
        "        'Actual': np.cumsum(actual_values[:len(predictions)], axis=0),\n",
        "        'Predicted': np.cumsum(predictions, axis=0),\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'MAPE': mape\n",
        "    })\n",
        "    csv_filename = os.path.join(model_save_dir, f'{os.path.splitext(os.path.basename(input_file))[0]}.csv')\n",
        "    results_df.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV saved as: {csv_filename}\")\n",
        "\n",
        "# Load normalization parameters\n",
        "mean_x, std_x, mean_y, std_y = load_normalization_params('normalization_params.json')\n",
        "\n",
        "# Directory containing models and CSV files\n",
        "csv_dir = '/content/sample_data'  # Directory containing CSV files\n",
        "model_dir = '/content/sample_data'  # Directory containing model files\n",
        "\n",
        "# List all model files in the directory\n",
        "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "# Load and test each model on each CSV file\n",
        "input_size = 5  # Number of features in the input data\n",
        "for csv_file in csv_files:\n",
        "    csv_file_path = os.path.join(csv_dir, csv_file)\n",
        "    for model_file in model_files:\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model_name = os.path.splitext(model_file)[0]\n",
        "        model = load_trained_model(model_path, input_size)\n",
        "        plot_predicted_vs_real(csv_file_path, model, model_name, mean_x, std_x, mean_y, std_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "4oV0rXF5S4AE",
        "outputId": "bbf545ff-4a4d-40bb-a791-91163984f936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-d51fec5a400f>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 147.2049\n",
            "MSE: 69204.6328\n",
            "MAPE: 61.9060%\n",
            "CSV saved as: predicted_vs_actual_plots/standard/DENA_TC+_MT_BARBOD_clean_0.5.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-d51fec5a400f>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'sys_trip_fc\\\\CCP:1'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sys_trip_fc\\\\CCP:1'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-d51fec5a400f>\u001b[0m in \u001b[0;36m<cell line: 148>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mplot_predicted_vs_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-d51fec5a400f>\u001b[0m in \u001b[0;36mplot_predicted_vs_real\u001b[0;34m(input_file, model, model_name, mean_x, std_x, mean_y, std_y)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Plot and predict function updated to handle standardization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_predicted_vs_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mnum_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-d51fec5a400f>\u001b[0m in \u001b[0;36mprocess_file\u001b[0;34m(file_path, mean_x, std_x, mean_y, std_y)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trip fuel consumption'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sys_trip_fc\\CCP:1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sys_trip_fc\\CCP:1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Acceleration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sys_veh_spd\\CCP:1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Momentary fuel consumption'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trip fuel consumption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sys_trip_fc\\\\CCP:1'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}